{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive  # Importing the library to mount Google Drive\n",
        "drive.mount('/content/drive')  # Mounting Google Drive in Colab environment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71FJxLKc1343",
        "outputId": "9979fce3-6ff2-4360-9d9f-841c4188861d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pandas numpy scikit-learn nltk"
      ],
      "metadata": {
        "id": "6_awAc1Nf_yt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXAm488r1DJw",
        "outputId": "5cea6bbe-0086-44f9-c62d-c36b1d6c56e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       domain    family   label\n",
            "0         nailconsiderable.ru  suppobox     dga\n",
            "1            stilldelight.net  suppobox     dga\n",
            "2       kimberleekatheryn.net  suppobox     dga\n",
            "3                soilbeen.net  suppobox     dga\n",
            "4               visitform.net  suppobox     dga\n",
            "...                       ...       ...     ...\n",
            "159995             dhuhaa.com     legit  notdga\n",
            "159996        sdmetalcrew.org     legit  notdga\n",
            "159997  melbcampcontuligol.ga     legit  notdga\n",
            "159998      pl-enthusiast.net     legit  notdga\n",
            "159999            rd-forum.ru     legit  notdga\n",
            "\n",
            "[160000 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# File paths\n",
        "train_df_file = \"/content/drive/My Drive/MOE_DGA/train_wl.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_df_file)\n",
        "\n",
        "#train_df = train_df.rename(columns={\"label\": \"Label\"})\n",
        "\n",
        "\n",
        "print(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import nltk\n",
        "from nltk.corpus import words, wordnet\n",
        "from collections import defaultdict\n",
        "\n",
        "# Descargar recursos de NLTK si no están disponibles\n",
        "try:\n",
        "    nltk.data.find('corpora/words')\n",
        "except LookupError:\n",
        "    nltk.download('words')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "# Construir diccionarios más completos\n",
        "def build_comprehensive_dictionaries():\n",
        "    \"\"\"\n",
        "    Construye diccionarios más completos basados en NLTK y listas comunes\n",
        "    \"\"\"\n",
        "    # Diccionario inglés completo (equivalente a los 58k palabras mencionadas)\n",
        "    english_words = set(words.words())\n",
        "    english_dict = {word.lower() for word in english_words if len(word) >= 2}\n",
        "\n",
        "    # Palabras comunes más frecuentes para sustantivos, verbos y adjetivos\n",
        "    common_nouns = {\n",
        "        \"time\", \"year\", \"people\", \"way\", \"day\", \"man\", \"thing\", \"woman\", \"life\",\n",
        "        \"child\", \"world\", \"school\", \"state\", \"family\", \"student\", \"group\", \"country\",\n",
        "        \"problem\", \"hand\", \"part\", \"place\", \"case\", \"week\", \"company\", \"system\",\n",
        "        \"program\", \"question\", \"work\", \"government\", \"number\", \"night\", \"point\",\n",
        "        \"home\", \"water\", \"room\", \"mother\", \"area\", \"money\", \"story\", \"fact\",\n",
        "        \"month\", \"lot\", \"right\", \"study\", \"book\", \"eye\", \"job\", \"word\", \"business\",\n",
        "        \"issue\", \"side\", \"kind\", \"head\", \"house\", \"service\", \"friend\", \"father\",\n",
        "        \"power\", \"hour\", \"game\", \"line\", \"end\", \"member\", \"law\", \"car\", \"city\",\n",
        "        \"community\", \"name\", \"president\", \"team\", \"minute\", \"idea\", \"kid\", \"body\",\n",
        "        \"information\", \"back\", \"parent\", \"face\", \"others\", \"level\", \"office\",\n",
        "        \"door\", \"health\", \"person\", \"art\", \"war\", \"history\", \"party\", \"result\",\n",
        "        \"change\", \"morning\", \"reason\", \"research\", \"girl\", \"guy\", \"moment\", \"air\",\n",
        "        \"teacher\", \"force\", \"education\"\n",
        "    }\n",
        "\n",
        "    common_verbs = {\n",
        "        \"be\", \"have\", \"do\", \"say\", \"get\", \"make\", \"go\", \"know\", \"take\", \"see\",\n",
        "        \"come\", \"think\", \"look\", \"want\", \"give\", \"use\", \"find\", \"tell\", \"ask\",\n",
        "        \"work\", \"seem\", \"feel\", \"try\", \"leave\", \"call\", \"need\", \"move\", \"would\",\n",
        "        \"could\", \"should\", \"might\", \"will\", \"can\", \"must\", \"shall\", \"may\",\n",
        "        \"put\", \"mean\", \"keep\", \"let\", \"begin\", \"seem\", \"help\", \"talk\", \"turn\",\n",
        "        \"start\", \"show\", \"hear\", \"play\", \"run\", \"move\", \"like\", \"live\", \"believe\",\n",
        "        \"hold\", \"bring\", \"happen\", \"write\", \"provide\", \"sit\", \"stand\", \"lose\",\n",
        "        \"pay\", \"meet\", \"include\", \"continue\", \"set\", \"learn\", \"change\", \"lead\",\n",
        "        \"understand\", \"watch\", \"follow\", \"stop\", \"create\", \"speak\", \"read\",\n",
        "        \"allow\", \"add\", \"spend\", \"grow\", \"open\", \"walk\", \"win\", \"offer\",\n",
        "        \"remember\", \"love\", \"consider\", \"appear\", \"buy\", \"wait\", \"serve\",\n",
        "        \"die\", \"send\", \"expect\", \"build\", \"stay\", \"fall\", \"cut\", \"reach\", \"kill\",\n",
        "        \"remain\", \"suggest\", \"raise\", \"pass\", \"sell\", \"require\", \"report\"\n",
        "    }\n",
        "\n",
        "    common_adjectives = {\n",
        "        \"good\", \"new\", \"first\", \"last\", \"long\", \"great\", \"little\", \"own\", \"other\",\n",
        "        \"old\", \"right\", \"big\", \"high\", \"different\", \"small\", \"large\", \"next\",\n",
        "        \"early\", \"young\", \"important\", \"few\", \"public\", \"bad\", \"same\", \"able\",\n",
        "        \"local\", \"sure\", \"united\", \"real\", \"best\", \"better\", \"less\", \"far\",\n",
        "        \"much\", \"water\", \"very\", \"social\", \"only\", \"national\", \"political\",\n",
        "        \"special\", \"hard\", \"international\", \"health\", \"human\", \"common\", \"short\",\n",
        "        \"general\", \"strong\", \"particular\", \"community\", \"whole\", \"private\",\n",
        "        \"recent\", \"available\", \"major\", \"personal\", \"current\", \"left\", \"least\",\n",
        "        \"possible\", \"business\", \"economic\", \"white\", \"late\", \"difficult\", \"red\",\n",
        "        \"close\", \"fine\", \"higher\", \"western\", \"financial\", \"certain\", \"free\",\n",
        "        \"military\", \"original\", \"successful\", \"low\", \"activity\", \"critical\",\n",
        "        \"environmental\", \"global\", \"eastern\", \"hard\", \"popular\", \"traditional\",\n",
        "        \"main\", \"simple\", \"physical\", \"medical\", \"full\", \"federal\", \"blue\",\n",
        "        \"democratic\", \"dark\", \"various\", \"entire\", \"close\", \"legal\", \"religious\",\n",
        "        \"cold\", \"final\", \"main\", \"green\", \"nice\", \"huge\", \"popular\", \"serious\",\n",
        "        \"ready\", \"easy\", \"official\", \"foreign\", \"fine\", \"civil\", \"lower\"\n",
        "    }\n",
        "\n",
        "    return english_dict, common_nouns, common_verbs, common_adjectives\n",
        "\n",
        "# Construir diccionarios DGA y privados desde dominios DGA\n",
        "def build_dga_dicts(df, english_dict):\n",
        "    \"\"\"\n",
        "    Construye diccionarios DGA y privados a partir de los dominios DGA del dataset\n",
        "    \"\"\"\n",
        "    if 'label' not in df.columns or 'domain' not in df.columns:\n",
        "        raise ValueError(\"DataFrame debe tener columnas 'label' y 'domain'\")\n",
        "\n",
        "    dga_domains = df[df['label'] == 'dga']['domain']\n",
        "    dga_words = set()\n",
        "    private_words = set()\n",
        "\n",
        "    for domain in dga_domains:\n",
        "        # Separar por puntos y guiones\n",
        "        parts = re.split(r'[-.]', domain.lower())\n",
        "        for word in parts:\n",
        "            if word and len(word) >= 2:  # Ignorar partes muy cortas\n",
        "                dga_words.add(word)\n",
        "                # Si la palabra no está en el diccionario inglés, es \"privada\"\n",
        "                if word not in english_dict:\n",
        "                    private_words.add(word)\n",
        "\n",
        "    return dga_words, private_words\n",
        "\n",
        "# Extraer características mejoradas del dominio\n",
        "def extract_features(domain, dga_dict, private_dict, english_dict, noun_dict, verb_dict, adj_dict):\n",
        "    \"\"\"\n",
        "    Extrae las 16 características mencionadas en el paper\n",
        "    \"\"\"\n",
        "    domain = domain.lower()\n",
        "    vowels = \"aeiou\"\n",
        "    digits_and_dash = string.digits + \"-\"\n",
        "\n",
        "    # f1: Longitud del dominio\n",
        "    domain_len = len(domain)\n",
        "\n",
        "    # f2: Suma ASCII de todos los caracteres\n",
        "    ascii_sum = sum(ord(c) for c in domain)\n",
        "\n",
        "    # f3: Número de vocales\n",
        "    vowel_count = sum(1 for c in domain if c in vowels)\n",
        "\n",
        "    # f4: Distribución de vocales\n",
        "    vowel_dist = vowel_count / domain_len if domain_len > 0 else 0\n",
        "\n",
        "    # f5: Número de dígitos y guiones\n",
        "    digit_dash_count = sum(1 for c in domain if c in digits_and_dash)\n",
        "\n",
        "    # f6: Distribución de dígitos y guiones\n",
        "    digit_dash_dist = digit_dash_count / domain_len if domain_len > 0 else 0\n",
        "\n",
        "    # Extraer palabras del dominio (separadas por . y -)\n",
        "    parts = re.split(r'[-.]', domain)\n",
        "    words = [w for w in parts if w and len(w) >= 2]\n",
        "\n",
        "    # f7: Palabras en diccionario inglés\n",
        "    word_norm = sum(1 for w in words if w in english_dict)\n",
        "\n",
        "    # f8: Palabras en diccionario DGA\n",
        "    word_dga = sum(1 for w in words if w in dga_dict)\n",
        "\n",
        "    # f9: Sustantivos\n",
        "    noun_count = sum(1 for w in words if w in noun_dict)\n",
        "\n",
        "    # f10: Verbos\n",
        "    verb_count = sum(1 for w in words if w in verb_dict)\n",
        "\n",
        "    # f11: Adjetivos\n",
        "    adj_count = sum(1 for w in words if w in adj_dict)\n",
        "\n",
        "    # f12: Palabras privadas (DGA que no están en inglés)\n",
        "    private_count = sum(1 for w in words if w in private_dict)\n",
        "\n",
        "    # f13: Ratio entre palabras DGA y palabras normales\n",
        "    ratio_dga_norm = word_dga / word_norm if word_norm > 0 else (word_dga if word_dga > 0 else 0)\n",
        "\n",
        "    # f14: Longitud de la palabra más larga\n",
        "    word_lengths = [len(w) for w in words]\n",
        "    max_len_word = max(word_lengths) if word_lengths else 0\n",
        "\n",
        "    # f15: Longitud de la palabra más corta\n",
        "    min_len_word = min(word_lengths) if word_lengths else 0\n",
        "\n",
        "    # f16: Ratio entre caracteres de palabras y longitud total\n",
        "    total_word_chars = sum(word_lengths)\n",
        "    word_char_ratio = total_word_chars / domain_len if domain_len > 0 else 0\n",
        "\n",
        "    return [\n",
        "        domain_len, ascii_sum, vowel_count, vowel_dist,\n",
        "        digit_dash_count, digit_dash_dist, word_norm, word_dga,\n",
        "        noun_count, verb_count, adj_count, private_count,\n",
        "        ratio_dga_norm, max_len_word, min_len_word, word_char_ratio\n",
        "    ]\n",
        "\n",
        "def train_dga_classifier(df, test_size=0.01, random_state=42):\n",
        "    \"\"\"\n",
        "    Función principal para entrenar el clasificador DGA\n",
        "    \"\"\"\n",
        "    print(\"Construyendo diccionarios...\")\n",
        "    english_dict, noun_dict, verb_dict, adj_dict = build_comprehensive_dictionaries()\n",
        "\n",
        "    print(f\"Diccionario inglés: {len(english_dict)} palabras\")\n",
        "    print(f\"Sustantivos: {len(noun_dict)} palabras\")\n",
        "    print(f\"Verbos: {len(verb_dict)} palabras\")\n",
        "    print(f\"Adjetivos: {len(adj_dict)} palabras\")\n",
        "\n",
        "    print(\"Construyendo diccionarios DGA...\")\n",
        "    dga_dict, private_dict = build_dga_dicts(df, english_dict)\n",
        "\n",
        "    print(f\"Palabras DGA: {len(dga_dict)}\")\n",
        "    print(f\"Palabras privadas: {len(private_dict)}\")\n",
        "\n",
        "    print(\"Extrayendo características...\")\n",
        "    # Extraer características\n",
        "    features = df['domain'].apply(\n",
        "        lambda d: extract_features(d, dga_dict, private_dict, english_dict,\n",
        "                                 noun_dict, verb_dict, adj_dict)\n",
        "    )\n",
        "\n",
        "    X = np.array(features.tolist())\n",
        "    y = df['label'].map({'notdga': 0, 'dga': 1}).values\n",
        "\n",
        "    print(f\"Forma de X: {X.shape}\")\n",
        "    print(f\"Distribución de clases: {np.bincount(y)}\")\n",
        "\n",
        "    # División train/test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "    )\n",
        "\n",
        "    print(\"Entrenando modelo Random Forest...\")\n",
        "    # Entrenar modelo Random Forest (como en el paper)\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,  # Aumentado para mejor rendimiento\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=random_state,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predicción y evaluación\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "    print(\"\\nReporte de clasificación:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=[\"notdga\", \"dga\"]))\n",
        "\n",
        "    print(\"\\nMatriz de confusión:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # Importancia de características\n",
        "    feature_names = [\n",
        "        'domain_len', 'ascii_sum', 'vowel_count', 'vowel_dist',\n",
        "        'digit_dash_count', 'digit_dash_dist', 'word_norm', 'word_dga',\n",
        "        'noun_count', 'verb_count', 'adj_count', 'private_count',\n",
        "        'ratio_dga_norm', 'max_len_word', 'min_len_word', 'word_char_ratio'\n",
        "    ]\n",
        "\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    print(\"\\nImportancia de características:\")\n",
        "    print(feature_importance)\n",
        "\n",
        "    return model, (dga_dict, private_dict, english_dict, noun_dict, verb_dict, adj_dict)\n",
        "\n",
        "# Función para clasificar nuevos dominios\n",
        "def classify_domain(domain, model, dictionaries):\n",
        "    \"\"\"\n",
        "    Clasifica un dominio individual\n",
        "    \"\"\"\n",
        "    dga_dict, private_dict, english_dict, noun_dict, verb_dict, adj_dict = dictionaries\n",
        "\n",
        "    features = extract_features(domain, dga_dict, private_dict, english_dict,\n",
        "                              noun_dict, verb_dict, adj_dict)\n",
        "    features_array = np.array([features])\n",
        "\n",
        "    prediction = model.predict(features_array)[0]\n",
        "    probability = model.predict_proba(features_array)[0]\n",
        "\n",
        "    return {\n",
        "        'domain': domain,\n",
        "        'prediction': 'dga' if prediction == 1 else 'notdga',\n",
        "        'dga_probability': probability[1],\n",
        "        'notdga_probability': probability[0]\n",
        "    }\n",
        "\n",
        "# === EJEMPLO DE USO ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Ejemplo de cómo usar el código\n",
        "    # Asume que tienes un DataFrame 'df' con columnas 'domain' y 'label'\n",
        "\n",
        "    # Crear datos de ejemplo si no tienes un dataset\n",
        "    sample_data = {\n",
        "        'domain': [\n",
        "            'google.com', 'facebook.com', 'microsoft.com', 'amazon.com',\n",
        "            'xkvbpqr.com', 'mnbvcxz.net', 'qwertyuiop.org', 'asdfghjkl.info',\n",
        "            'randomstring123.com', 'anotherfakedom.net'\n",
        "        ],\n",
        "        'label': [\n",
        "            'notdga', 'notdga', 'notdga', 'notdga',\n",
        "            'dga', 'dga', 'dga', 'dga', 'dga', 'dga'\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    df_example = pd.DataFrame(sample_data)\n",
        "\n",
        "    print(\"Ejemplo con datos sintéticos:\")\n",
        "    print(\"Para usar con tus datos reales, carga tu DataFrame con columnas 'domain' y 'label'\")\n",
        "    print(\"Donde 'label' contiene 'dga' o 'notdga'\")\n",
        "\n",
        "    model, dictionaries = train_dga_classifier(train_df)\n",
        "\n",
        "    # Ejemplo de clasificación de un dominio individual\n",
        "    # result = classify_domain('suspicious-domain.com', model, dictionaries)\n",
        "    # print(f\"\\nResultado para 'suspicious-domain.com': {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0DoyDMKf-cg",
        "outputId": "7af1ea70-c625-4236-fc97-1d6167371d8e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo con datos sintéticos:\n",
            "Para usar con tus datos reales, carga tu DataFrame con columnas 'domain' y 'label'\n",
            "Donde 'label' contiene 'dga' o 'notdga'\n",
            "Construyendo diccionarios...\n",
            "Diccionario inglés: 234351 palabras\n",
            "Sustantivos: 100 palabras\n",
            "Verbos: 106 palabras\n",
            "Adjetivos: 110 palabras\n",
            "Construyendo diccionarios DGA...\n",
            "Palabras DGA: 77834\n",
            "Palabras privadas: 74121\n",
            "Extrayendo características...\n",
            "Forma de X: (160000, 16)\n",
            "Distribución de clases: [80000 80000]\n",
            "Entrenando modelo Random Forest...\n",
            "\n",
            "Accuracy: 0.9900\n",
            "\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      notdga       0.99      0.99      0.99       800\n",
            "         dga       0.99      0.99      0.99       800\n",
            "\n",
            "    accuracy                           0.99      1600\n",
            "   macro avg       0.99      0.99      0.99      1600\n",
            "weighted avg       0.99      0.99      0.99      1600\n",
            "\n",
            "\n",
            "Matriz de confusión:\n",
            "[[790  10]\n",
            " [  6 794]]\n",
            "\n",
            "Importancia de características:\n",
            "             feature  importance\n",
            "12    ratio_dga_norm    0.293593\n",
            "7           word_dga    0.216847\n",
            "15   word_char_ratio    0.192850\n",
            "14      min_len_word    0.096504\n",
            "11     private_count    0.069625\n",
            "13      max_len_word    0.031296\n",
            "0         domain_len    0.026095\n",
            "6          word_norm    0.026045\n",
            "1          ascii_sum    0.021799\n",
            "5    digit_dash_dist    0.009823\n",
            "4   digit_dash_count    0.007024\n",
            "2        vowel_count    0.004815\n",
            "3         vowel_dist    0.003124\n",
            "8         noun_count    0.000232\n",
            "10         adj_count    0.000166\n",
            "9         verb_count    0.000162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = classify_domain('suspicious-domain.com', model, dictionaries)\n",
        "print(f\"\\nResultado para 'suspicious-domain.com': {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRARV6zHgG8p",
        "outputId": "9df6e5ce-b727-4f03-eb6a-d929f93d1c3d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resultado para 'suspicious-domain.com': {'domain': 'suspicious-domain.com', 'prediction': 'notdga', 'dga_probability': np.float64(0.019480393789305103), 'notdga_probability': np.float64(0.980519606210695)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['prediction']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wXTk9mqvgG_2",
        "outputId": "b34c6a2b-9a48-4d15-ec59-b00632a961b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'notdga'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "import gzip\n",
        "\n",
        "# Importar las funciones del modelo DGA que creamos anteriormente\n",
        "# (Asume que ya tienes entrenado el modelo y las funciones disponibles)\n",
        "\n",
        "def classify_domains_batch(domains, model, dictionaries):\n",
        "    \"\"\"\n",
        "    Clasifica múltiples dominios y mide el tiempo de procesamiento\n",
        "\n",
        "    Args:\n",
        "        domains: Lista o array de dominios\n",
        "        model: Modelo entrenado\n",
        "        dictionaries: Tupla con los diccionarios necesarios\n",
        "\n",
        "    Returns:\n",
        "        dict con predicciones, probabilidades y tiempos\n",
        "    \"\"\"\n",
        "    dga_dict, private_dict, english_dict, noun_dict, verb_dict, adj_dict = dictionaries\n",
        "\n",
        "    predictions = []\n",
        "    probabilities_dga = []\n",
        "    probabilities_notdga = []\n",
        "    processing_times = []\n",
        "\n",
        "    for domain in domains:\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Extraer características\n",
        "        features = extract_features(domain, dga_dict, private_dict, english_dict,\n",
        "                                  noun_dict, verb_dict, adj_dict)\n",
        "        features_array = np.array([features])\n",
        "\n",
        "        # Hacer predicción\n",
        "        prediction = model.predict(features_array)[0]\n",
        "        probability = model.predict_proba(features_array)[0]\n",
        "\n",
        "        end_time = time.time()\n",
        "        query_time = end_time - start_time\n",
        "\n",
        "        predictions.append('dga' if prediction == 1 else 'notdga')\n",
        "        probabilities_dga.append(probability[1])\n",
        "        probabilities_notdga.append(probability[0])\n",
        "        processing_times.append(query_time)\n",
        "\n",
        "    return {\n",
        "        'predictions': predictions,\n",
        "        'probabilities_dga': probabilities_dga,\n",
        "        'probabilities_notdga': probabilities_notdga,\n",
        "        'processing_times': processing_times\n",
        "    }\n",
        "\n",
        "def evaluate_dga_families(model, dictionaries, base_path='/content/drive/My Drive/Familias_Test/',\n",
        "                         results_path='/content/drive/My Drive/results/', runs=30, chunk_size=50):\n",
        "    \"\"\"\n",
        "    Evalúa el modelo DGA con diferentes familias de malware\n",
        "\n",
        "    Args:\n",
        "        model: Modelo entrenado\n",
        "        dictionaries: Diccionarios del modelo\n",
        "        base_path: Ruta base donde están los archivos de familias\n",
        "        results_path: Ruta donde guardar los resultados\n",
        "        runs: Número de ejecuciones por familia\n",
        "        chunk_size: Tamaño del chunk para procesar\n",
        "    \"\"\"\n",
        "\n",
        "    families = [\n",
        "        'matsnu.gz',\n",
        "        'suppobox.gz',\n",
        "        'charbot.gz',\n",
        "        'gozi.gz',\n",
        "        'manuelita.gz',\n",
        "        'rovnix.gz',\n",
        "        'deception.gz',\n",
        "        'nymaim.gz'\n",
        "    ]\n",
        "\n",
        "    # Crear directorio de resultados si no existe\n",
        "    Path(results_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Verificar que el archivo legit existe\n",
        "    legit_file = os.path.join(base_path, 'legit.gz')\n",
        "    if not os.path.exists(legit_file):\n",
        "        raise FileNotFoundError(f\"Archivo legit no encontrado: {legit_file}\")\n",
        "\n",
        "    # Procesar cada familia\n",
        "    for family in families:\n",
        "        print(f\"🔍 Procesando familia: {family}\")\n",
        "\n",
        "        family_file = os.path.join(base_path, family)\n",
        "        if not os.path.exists(family_file):\n",
        "            print(f\"❌ Archivo no encontrado: {family_file}\")\n",
        "            continue\n",
        "\n",
        "        # Estadísticas para la familia\n",
        "        family_stats = {\n",
        "            'total_domains': 0,\n",
        "            'total_time': 0,\n",
        "            'avg_time_per_domain': 0,\n",
        "            'runs_completed': 0\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Crear lectores de chunks\n",
        "            dga_reader = pd.read_csv(family_file, chunksize=chunk_size)\n",
        "\n",
        "            for run in range(runs):\n",
        "                print(f\" ▶️ Run {run+1}/{runs}\", end=\"\\r\")\n",
        "\n",
        "                try:\n",
        "                    # Leer chunks\n",
        "                    dga_chunk = next(dga_reader)\n",
        "\n",
        "                    # Reiniciar el lector de legit para cada run\n",
        "                    legit_reader = pd.read_csv(legit_file, chunksize=chunk_size)\n",
        "                    legit_chunk = next(legit_reader)\n",
        "\n",
        "                    # Combinar chunks\n",
        "                    df_chunk = pd.concat([dga_chunk, legit_chunk]).reset_index(drop=True)\n",
        "\n",
        "                    # Asegurar que la columna domain existe\n",
        "                    if 'domain' not in df_chunk.columns:\n",
        "                        # Si no existe, asumir que la primera columna son los dominios\n",
        "                        df_chunk.columns = ['domain'] + list(df_chunk.columns[1:])\n",
        "\n",
        "                    # Crear etiquetas si no existen\n",
        "                    if 'label' not in df_chunk.columns:\n",
        "                        # Primeros len(dga_chunk) son DGA, el resto son legit\n",
        "                        labels = ['dga'] * len(dga_chunk) + ['notdga'] * len(legit_chunk)\n",
        "                        df_chunk['label'] = labels\n",
        "\n",
        "                    # Medir tiempo total para el batch\n",
        "                    batch_start_time = time.time()\n",
        "\n",
        "                    # Obtener predicciones y tiempos individuales\n",
        "                    results = classify_domains_batch(df_chunk[\"domain\"].values, model, dictionaries)\n",
        "\n",
        "                    batch_end_time = time.time()\n",
        "                    batch_total_time = batch_end_time - batch_start_time\n",
        "\n",
        "                    # Agregar resultados al DataFrame\n",
        "                    df_chunk[\"pred\"] = results['predictions']\n",
        "                    df_chunk[\"prob_dga\"] = results['probabilities_dga']\n",
        "                    df_chunk[\"prob_notdga\"] = results['probabilities_notdga']\n",
        "                    df_chunk[\"query_time\"] = results['processing_times']\n",
        "                    df_chunk[\"batch_time\"] = batch_total_time\n",
        "                    df_chunk[\"run\"] = run\n",
        "\n",
        "                    # Calcular métricas adicionales\n",
        "                    df_chunk[\"correct\"] = (df_chunk[\"label\"] == df_chunk[\"pred\"]).astype(int)\n",
        "\n",
        "                    # Actualizar estadísticas\n",
        "                    family_stats['total_domains'] += len(df_chunk)\n",
        "                    family_stats['total_time'] += batch_total_time\n",
        "                    family_stats['runs_completed'] += 1\n",
        "\n",
        "                    # Guardar resultados\n",
        "                    output_file = os.path.join(\n",
        "                        results_path,\n",
        "                        f\"results_RandomForest_{family.replace('.gz', '')}_{run}.csv.gz\"\n",
        "                    )\n",
        "\n",
        "                    df_chunk.to_csv(\n",
        "                        output_file,\n",
        "                        index=False,\n",
        "                        compression=\"gzip\"\n",
        "                    )\n",
        "\n",
        "                except StopIteration:\n",
        "                    print(f\"\\n⚠️ No hay más datos disponibles para {family} en run {run+1}\")\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    print(f\"\\n❌ Error en run {run+1} para {family}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            # Calcular estadísticas finales para la familia\n",
        "            if family_stats['runs_completed'] > 0:\n",
        "                family_stats['avg_time_per_domain'] = family_stats['total_time'] / family_stats['total_domains']\n",
        "\n",
        "                print(f\"\\n✅ {family} completado:\")\n",
        "                print(f\"   Runs completados: {family_stats['runs_completed']}/{runs}\")\n",
        "                print(f\"   Total dominios procesados: {family_stats['total_domains']}\")\n",
        "                print(f\"   Tiempo total: {family_stats['total_time']:.4f}s\")\n",
        "                print(f\"   Tiempo promedio por dominio: {family_stats['avg_time_per_domain']:.6f}s\")\n",
        "                print(f\"   Dominios por segundo: {family_stats['total_domains']/family_stats['total_time']:.2f}\")\n",
        "\n",
        "                # Guardar estadísticas de la familia\n",
        "                stats_df = pd.DataFrame([family_stats])\n",
        "                stats_df['family'] = family\n",
        "                stats_file = os.path.join(results_path, f\"stats_{family.replace('.gz', '')}.csv\")\n",
        "                stats_df.to_csv(stats_file, index=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ Error procesando familia {family}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n\" + \"=\"*50)\n",
        "\n",
        "def analyze_results(results_path='/content/drive/My Drive/results/'):\n",
        "    \"\"\"\n",
        "    Analiza los resultados guardados y genera un resumen\n",
        "    \"\"\"\n",
        "    print(\"📊 Analizando resultados...\")\n",
        "\n",
        "    results_files = [f for f in os.listdir(results_path) if f.startswith('results_RandomForest_')]\n",
        "\n",
        "    if not results_files:\n",
        "        print(\"❌ No se encontraron archivos de resultados\")\n",
        "        return\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for file in results_files:\n",
        "        try:\n",
        "            df = pd.read_csv(os.path.join(results_path, file))\n",
        "            family = file.split('_')[2]  # Extraer nombre de familia\n",
        "            run = file.split('_')[3].replace('.csv.gz', '')\n",
        "\n",
        "            # Calcular métricas\n",
        "            accuracy = df['correct'].mean()\n",
        "            avg_time = df['query_time'].mean()\n",
        "\n",
        "            all_results.append({\n",
        "                'family': family,\n",
        "                'run': run,\n",
        "                'accuracy': accuracy,\n",
        "                'avg_query_time': avg_time,\n",
        "                'total_domains': len(df),\n",
        "                'dga_domains': len(df[df['label'] == 'dga']),\n",
        "                'legit_domains': len(df[df['label'] == 'notdga'])\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error procesando {file}: {str(e)}\")\n",
        "\n",
        "    if all_results:\n",
        "        summary_df = pd.DataFrame(all_results)\n",
        "\n",
        "        # Resumen por familia\n",
        "        family_summary = summary_df.groupby('family').agg({\n",
        "            'accuracy': ['mean', 'std'],\n",
        "            'avg_query_time': ['mean', 'std'],\n",
        "            'total_domains': 'sum'\n",
        "        }).round(4)\n",
        "\n",
        "        print(\"\\n📈 Resumen por familia:\")\n",
        "        print(family_summary)\n",
        "\n",
        "        # Guardar resumen\n",
        "        summary_file = os.path.join(results_path, 'evaluation_summary.csv')\n",
        "        family_summary.to_csv(summary_file)\n",
        "\n",
        "        print(f\"\\n💾 Resumen guardado en: {summary_file}\")\n",
        "\n",
        "        return summary_df\n",
        "\n",
        "    return None\n",
        "\n",
        "# === EJEMPLO DE USO ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Asume que ya tienes el modelo entrenado y los diccionarios\n",
        "    # model, dictionaries = train_dga_classifier(your_training_data)\n",
        "\n",
        "    print(\"🏃‍♂️ Iniciando evaluación de familias DGA...\")\n",
        "    print(\"📋 Parámetros:\")\n",
        "    print(f\"   - Familias: 8\")\n",
        "    print(f\"   - Runs por familia: 30\")\n",
        "    print(f\"   - Chunk size: 50\")\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "    # Ejecutar evaluación\n",
        "    evaluate_dga_families(model, dictionaries)\n",
        "\n",
        "    # Analizar resultados\n",
        "    results_summary = analyze_results()\n",
        "\n",
        "    print(\"\\n✅ Evaluación completada!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSvWzmcpgHCs",
        "outputId": "9fbae472-01ed-41b8-f4aa-f39346203962"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏃‍♂️ Iniciando evaluación de familias DGA...\n",
            "📋 Parámetros:\n",
            "   - Familias: 8\n",
            "   - Runs por familia: 30\n",
            "   - Chunk size: 50\n",
            "\n",
            "==================================================\n",
            "🔍 Procesando familia: matsnu.gz\n",
            "\n",
            "✅ matsnu.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Total dominios procesados: 3000\n",
            "   Tiempo total: 137.7776s\n",
            "   Tiempo promedio por dominio: 0.045926s\n",
            "   Dominios por segundo: 21.77\n",
            "\n",
            "==================================================\n",
            "🔍 Procesando familia: suppobox.gz\n",
            "\n",
            "✅ suppobox.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Total dominios procesados: 3000\n",
            "   Tiempo total: 138.4538s\n",
            "   Tiempo promedio por dominio: 0.046151s\n",
            "   Dominios por segundo: 21.67\n",
            "\n",
            "==================================================\n",
            "🔍 Procesando familia: charbot.gz\n",
            "\n",
            "✅ charbot.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Total dominios procesados: 3000\n",
            "   Tiempo total: 138.0810s\n",
            "   Tiempo promedio por dominio: 0.046027s\n",
            "   Dominios por segundo: 21.73\n",
            "\n",
            "==================================================\n",
            "🔍 Procesando familia: gozi.gz\n",
            "\n",
            "✅ gozi.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Total dominios procesados: 3000\n",
            "   Tiempo total: 138.6897s\n",
            "   Tiempo promedio por dominio: 0.046230s\n",
            "   Dominios por segundo: 21.63\n",
            "\n",
            "==================================================\n",
            "🔍 Procesando familia: manuelita.gz\n",
            "\n",
            "✅ manuelita.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Total dominios procesados: 3000\n",
            "   Tiempo total: 139.0064s\n",
            "   Tiempo promedio por dominio: 0.046335s\n",
            "   Dominios por segundo: 21.58\n",
            "\n",
            "==================================================\n",
            "🔍 Procesando familia: rovnix.gz\n",
            "\n",
            "✅ rovnix.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Total dominios procesados: 3000\n",
            "   Tiempo total: 139.7754s\n",
            "   Tiempo promedio por dominio: 0.046592s\n",
            "   Dominios por segundo: 21.46\n",
            "\n",
            "==================================================\n",
            "🔍 Procesando familia: deception.gz\n",
            "\n",
            "✅ deception.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Total dominios procesados: 3000\n",
            "   Tiempo total: 142.4067s\n",
            "   Tiempo promedio por dominio: 0.047469s\n",
            "   Dominios por segundo: 21.07\n",
            "\n",
            "==================================================\n",
            "🔍 Procesando familia: nymaim.gz\n",
            "\n",
            "✅ nymaim.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Total dominios procesados: 3000\n",
            "   Tiempo total: 139.9440s\n",
            "   Tiempo promedio por dominio: 0.046648s\n",
            "   Dominios por segundo: 21.44\n",
            "\n",
            "==================================================\n",
            "📊 Analizando resultados...\n",
            "\n",
            "📈 Resumen por familia:\n",
            "          accuracy         avg_query_time         total_domains\n",
            "              mean     std           mean     std           sum\n",
            "family                                                         \n",
            "charbot     0.4707  0.0025         0.0460  0.0006          3000\n",
            "deception   0.9177  0.0199         0.0475  0.0045          3000\n",
            "gozi        0.4700  0.0000         0.0462  0.0010          3000\n",
            "manuelita   0.4817  0.0075         0.0463  0.0019          3000\n",
            "matsnu      0.7593  0.0326         0.0459  0.0004          3000\n",
            "nymaim      0.5487  0.0257         0.0466  0.0020          3000\n",
            "rovnix      0.4700  0.0000         0.0466  0.0026          3000\n",
            "suppobox    0.5163  0.0277         0.0461  0.0016          3000\n",
            "\n",
            "💾 Resumen guardado en: /content/drive/My Drive/results/evaluation_summary.csv\n",
            "\n",
            "✅ Evaluación completada!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = f'/content/drive/My Drive/results/results_RandomForest_matsnu_20.csv.gz'\n",
        "df1 = pd.read_csv(path)\n",
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "5sX8n_4uiEx_",
        "outputId": "87d90453-1522-4bb2-8999-f60748d26355"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0                    domain  family subfamily   label    pred  \\\n",
              "0      1049306      smokeform-camera.com  matsnu    matsnu     dga  notdga   \n",
              "1      1049307  duty-differ-shoulder.com  matsnu    matsnu     dga     dga   \n",
              "2      1049308      clerkbottle-head.com  matsnu    matsnu     dga  notdga   \n",
              "3      1049309        dog-black-back.com  matsnu    matsnu     dga     dga   \n",
              "4      1049310    key-string-project.com  matsnu    matsnu     dga     dga   \n",
              "..         ...                       ...     ...       ...     ...     ...   \n",
              "95     3218513        airbus-carpool.com   legit    tranco  notdga  notdga   \n",
              "96     3218514      xn--80aa9bg.xn--p1ai   legit    tranco  notdga  notdga   \n",
              "97     3218515              ultraval.net   legit    tranco  notdga  notdga   \n",
              "98     3218516       essen-nutrition.com   legit    tranco  notdga  notdga   \n",
              "99     3218517                  6017.com   legit    tranco  notdga  notdga   \n",
              "\n",
              "    prob_dga  prob_notdga  query_time  batch_time  run  correct  \n",
              "0   0.169708     0.830292    0.045187    4.562825   20        0  \n",
              "1   0.977685     0.022315    0.044914    4.562825   20        1  \n",
              "2   0.200283     0.799717    0.045159    4.562825   20        0  \n",
              "3   0.976948     0.023052    0.044837    4.562825   20        1  \n",
              "4   0.986510     0.013490    0.045016    4.562825   20        1  \n",
              "..       ...          ...         ...         ...  ...      ...  \n",
              "95  0.000518     0.999482    0.044965    4.562825   20        1  \n",
              "96  0.192380     0.807620    0.046172    4.562825   20        1  \n",
              "97  0.000311     0.999689    0.044628    4.562825   20        1  \n",
              "98  0.001977     0.998023    0.044798    4.562825   20        1  \n",
              "99  0.004237     0.995763    0.044789    4.562825   20        1  \n",
              "\n",
              "[100 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae06370f-7937-488b-8de6-212b96d5b969\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>domain</th>\n",
              "      <th>family</th>\n",
              "      <th>subfamily</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "      <th>prob_dga</th>\n",
              "      <th>prob_notdga</th>\n",
              "      <th>query_time</th>\n",
              "      <th>batch_time</th>\n",
              "      <th>run</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1049306</td>\n",
              "      <td>smokeform-camera.com</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>dga</td>\n",
              "      <td>notdga</td>\n",
              "      <td>0.169708</td>\n",
              "      <td>0.830292</td>\n",
              "      <td>0.045187</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1049307</td>\n",
              "      <td>duty-differ-shoulder.com</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>dga</td>\n",
              "      <td>dga</td>\n",
              "      <td>0.977685</td>\n",
              "      <td>0.022315</td>\n",
              "      <td>0.044914</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1049308</td>\n",
              "      <td>clerkbottle-head.com</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>dga</td>\n",
              "      <td>notdga</td>\n",
              "      <td>0.200283</td>\n",
              "      <td>0.799717</td>\n",
              "      <td>0.045159</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1049309</td>\n",
              "      <td>dog-black-back.com</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>dga</td>\n",
              "      <td>dga</td>\n",
              "      <td>0.976948</td>\n",
              "      <td>0.023052</td>\n",
              "      <td>0.044837</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1049310</td>\n",
              "      <td>key-string-project.com</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>dga</td>\n",
              "      <td>dga</td>\n",
              "      <td>0.986510</td>\n",
              "      <td>0.013490</td>\n",
              "      <td>0.045016</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>3218513</td>\n",
              "      <td>airbus-carpool.com</td>\n",
              "      <td>legit</td>\n",
              "      <td>tranco</td>\n",
              "      <td>notdga</td>\n",
              "      <td>notdga</td>\n",
              "      <td>0.000518</td>\n",
              "      <td>0.999482</td>\n",
              "      <td>0.044965</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>3218514</td>\n",
              "      <td>xn--80aa9bg.xn--p1ai</td>\n",
              "      <td>legit</td>\n",
              "      <td>tranco</td>\n",
              "      <td>notdga</td>\n",
              "      <td>notdga</td>\n",
              "      <td>0.192380</td>\n",
              "      <td>0.807620</td>\n",
              "      <td>0.046172</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>3218515</td>\n",
              "      <td>ultraval.net</td>\n",
              "      <td>legit</td>\n",
              "      <td>tranco</td>\n",
              "      <td>notdga</td>\n",
              "      <td>notdga</td>\n",
              "      <td>0.000311</td>\n",
              "      <td>0.999689</td>\n",
              "      <td>0.044628</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>3218516</td>\n",
              "      <td>essen-nutrition.com</td>\n",
              "      <td>legit</td>\n",
              "      <td>tranco</td>\n",
              "      <td>notdga</td>\n",
              "      <td>notdga</td>\n",
              "      <td>0.001977</td>\n",
              "      <td>0.998023</td>\n",
              "      <td>0.044798</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>3218517</td>\n",
              "      <td>6017.com</td>\n",
              "      <td>legit</td>\n",
              "      <td>tranco</td>\n",
              "      <td>notdga</td>\n",
              "      <td>notdga</td>\n",
              "      <td>0.004237</td>\n",
              "      <td>0.995763</td>\n",
              "      <td>0.044789</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae06370f-7937-488b-8de6-212b96d5b969')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae06370f-7937-488b-8de6-212b96d5b969 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae06370f-7937-488b-8de6-212b96d5b969');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8a03d9e4-c1f7-495f-ada6-7b957dbbf19f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a03d9e4-c1f7-495f-ada6-7b957dbbf19f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8a03d9e4-c1f7-495f-ada6-7b957dbbf19f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c6d74af0-7c33-44d6-a89d-96fdd79a75da\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df1')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c6d74af0-7c33-44d6-a89d-96fdd79a75da button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df1');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1",
              "summary": "{\n  \"name\": \"df1\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1090044,\n        \"min\": 1049306,\n        \"max\": 3218517,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          3218501,\n          3218471,\n          3218488\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"ihatesalliemae.net\",\n          \"pdprojects.cf\",\n          \"nedbankcinemaprive.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"family\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"legit\",\n          \"matsnu\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subfamily\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"tranco\",\n          \"matsnu\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"notdga\",\n          \"dga\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"dga\",\n          \"notdga\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prob_dga\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.40500474246974805,\n        \"min\": 2.780462610187112e-06,\n        \"max\": 0.9911777041345512,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          0.9888084045721076,\n          0.1697081377386175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prob_notdga\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.40500474246974805,\n        \"min\": 0.0088222958654485,\n        \"max\": 0.9999972195373898,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          0.0111915954278922,\n          0.8302918622613824\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0022933504470657117,\n        \"min\": 0.0442574024200439,\n        \"max\": 0.0572774410247802,\n        \"num_unique_values\": 99,\n        \"samples\": [\n          0.0444936752319335,\n          0.0450546741485595\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 4.562824964523315,\n        \"max\": 4.562824964523315,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.562824964523315\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "import gzip\n",
        "\n",
        "def evaluate_new_dga_families(model, dictionaries,\n",
        "                             new_families_path='/content/drive/My Drive/New_Families/',\n",
        "                             legit_file_path='/content/drive/My Drive/Familias_Test/legit.gz',\n",
        "                             results_path='/content/drive/My Drive/results/',\n",
        "                             runs=30, chunk_size=50, skip_legit_chunks=30):\n",
        "    \"\"\"\n",
        "    Evalúa nuevas familias DGA con el modelo entrenado\n",
        "\n",
        "    Args:\n",
        "        model: Modelo DGA cargado\n",
        "        dictionaries: Diccionarios del modelo\n",
        "        new_families_path: Ruta de las nuevas familias\n",
        "        legit_file_path: Ruta del archivo de dominios legítimos\n",
        "        results_path: Ruta donde guardar resultados\n",
        "        runs: Número de ejecuciones por familia\n",
        "        chunk_size: Tamaño del chunk\n",
        "        skip_legit_chunks: Cuántos chunks de legit saltar (para continuar donde se quedó)\n",
        "    \"\"\"\n",
        "\n",
        "    # Nuevas familias a evaluar\n",
        "    families = [\n",
        "        'bigviktor.gz',\n",
        "        'pizd.gz',\n",
        "        'ngioweb.gz'\n",
        "    ]\n",
        "\n",
        "    # Crear directorio de resultados si no existe\n",
        "    Path(results_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Verificar que el archivo legit existe\n",
        "    if not os.path.exists(legit_file_path):\n",
        "        raise FileNotFoundError(f\"Archivo legit no encontrado: {legit_file_path}\")\n",
        "\n",
        "    print(f\"🆕 Evaluando nuevas familias DGA...\")\n",
        "    print(f\"📂 Ruta familias: {new_families_path}\")\n",
        "    print(f\"📂 Archivo legit: {legit_file_path}\")\n",
        "    print(f\"⏭️ Saltando {skip_legit_chunks} chunks de legit\")\n",
        "    print(f\"🎯 Runs por familia: {runs}\")\n",
        "    print(f\"📦 Chunk size: {chunk_size}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Procesar cada nueva familia\n",
        "    for family in families:\n",
        "        print(f\"\\n🔍 Procesando familia: {family}\")\n",
        "\n",
        "        family_file = os.path.join(new_families_path, family)\n",
        "        if not os.path.exists(family_file):\n",
        "            print(f\"❌ Archivo no encontrado: {family_file}\")\n",
        "            continue\n",
        "\n",
        "        # Estadísticas para la familia\n",
        "        family_stats = {\n",
        "            'family': family.replace('.gz', ''),\n",
        "            'total_domains': 0,\n",
        "            'total_time': 0,\n",
        "            'avg_time_per_domain': 0,\n",
        "            'runs_completed': 0,\n",
        "            'runs_failed': 0,\n",
        "            'total_accuracy': 0,\n",
        "            'avg_accuracy': 0\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Crear lector de chunks para DGA\n",
        "            dga_reader = pd.read_csv(family_file, chunksize=chunk_size)\n",
        "\n",
        "            # Preparar lector de legit y saltar chunks especificados\n",
        "            legit_reader = pd.read_csv(legit_file_path, chunksize=chunk_size)\n",
        "\n",
        "            print(f\"⏭️ Saltando {skip_legit_chunks} chunks de dominios legítimos...\")\n",
        "            try:\n",
        "                for i in range(skip_legit_chunks):\n",
        "                    next(legit_reader)\n",
        "                    if (i + 1) % 10 == 0:\n",
        "                        print(f\"   Saltados {i + 1}/{skip_legit_chunks} chunks\", end='\\r')\n",
        "            except StopIteration:\n",
        "                print(f\"\\n⚠️ Solo se pudieron saltar {i} chunks de legit\")\n",
        "                # Reiniciar el lector si se acabaron los chunks\n",
        "                legit_reader = pd.read_csv(legit_file_path, chunksize=chunk_size)\n",
        "\n",
        "            print(f\"\\n✅ Iniciando evaluación de {family}\")\n",
        "\n",
        "            for run in range(runs):\n",
        "                print(f\" ▶️ Run {run+1}/{runs}\", end=\"\\r\")\n",
        "\n",
        "                try:\n",
        "                    # Leer chunk DGA\n",
        "                    dga_chunk = next(dga_reader)\n",
        "\n",
        "                    # Leer chunk legit\n",
        "                    try:\n",
        "                        legit_chunk = next(legit_reader)\n",
        "                    except StopIteration:\n",
        "                        # Si se acabaron los chunks de legit, reiniciar el lector\n",
        "                        legit_reader = pd.read_csv(legit_file_path, chunksize=chunk_size)\n",
        "                        legit_chunk = next(legit_reader)\n",
        "\n",
        "                    # Preparar datos\n",
        "                    # Asegurar nombres de columnas correctos\n",
        "                    if 'domain' not in dga_chunk.columns:\n",
        "                        dga_chunk.columns = ['domain'] + list(dga_chunk.columns[1:])\n",
        "                    if 'domain' not in legit_chunk.columns:\n",
        "                        legit_chunk.columns = ['domain'] + list(legit_chunk.columns[1:])\n",
        "\n",
        "                    # Agregar etiquetas\n",
        "                    dga_chunk['label'] = 'dga'\n",
        "                    legit_chunk['label'] = 'notdga'\n",
        "\n",
        "                    # Combinar chunks\n",
        "                    df_chunk = pd.concat([dga_chunk, legit_chunk]).reset_index(drop=True)\n",
        "\n",
        "                    # Medir tiempo total para el batch\n",
        "                    batch_start_time = time.time()\n",
        "\n",
        "                    # Obtener predicciones y tiempos\n",
        "                    results = classify_domains_batch(df_chunk[\"domain\"].values, model, dictionaries)\n",
        "\n",
        "                    batch_end_time = time.time()\n",
        "                    batch_total_time = batch_end_time - batch_start_time\n",
        "\n",
        "                    # Agregar resultados al DataFrame\n",
        "                    df_chunk[\"pred\"] = results['predictions']\n",
        "                    df_chunk[\"prob_dga\"] = results['probabilities_dga']\n",
        "                    df_chunk[\"prob_notdga\"] = results['probabilities_notdga']\n",
        "                    df_chunk[\"query_time\"] = results['processing_times']\n",
        "                    df_chunk[\"batch_time\"] = batch_total_time\n",
        "                    df_chunk[\"run\"] = run\n",
        "                    df_chunk[\"family\"] = family.replace('.gz', '')\n",
        "\n",
        "                    # Calcular métricas\n",
        "                    df_chunk[\"correct\"] = (df_chunk[\"label\"] == df_chunk[\"pred\"]).astype(int)\n",
        "                    run_accuracy = df_chunk[\"correct\"].mean()\n",
        "\n",
        "                    # Actualizar estadísticas\n",
        "                    family_stats['total_domains'] += len(df_chunk)\n",
        "                    family_stats['total_time'] += batch_total_time\n",
        "                    family_stats['runs_completed'] += 1\n",
        "                    family_stats['total_accuracy'] += run_accuracy\n",
        "\n",
        "                    # Guardar resultados (con nombre actualizado)\n",
        "                    output_file = os.path.join(\n",
        "                        results_path,\n",
        "                        f\"results_RandomForest_NEW_{family.replace('.gz', '')}_{run}.csv.gz\"\n",
        "                    )\n",
        "\n",
        "                    df_chunk.to_csv(\n",
        "                        output_file,\n",
        "                        index=False,\n",
        "                        compression=\"gzip\"\n",
        "                    )\n",
        "\n",
        "                except StopIteration:\n",
        "                    print(f\"\\n⚠️ No hay más datos DGA disponibles para {family} en run {run+1}\")\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    print(f\"\\n❌ Error en run {run+1} para {family}: {str(e)}\")\n",
        "                    family_stats['runs_failed'] += 1\n",
        "                    continue\n",
        "\n",
        "            # Calcular estadísticas finales para la familia\n",
        "            if family_stats['runs_completed'] > 0:\n",
        "                family_stats['avg_time_per_domain'] = family_stats['total_time'] / family_stats['total_domains']\n",
        "                family_stats['avg_accuracy'] = family_stats['total_accuracy'] / family_stats['runs_completed']\n",
        "\n",
        "                print(f\"\\n✅ {family} completado:\")\n",
        "                print(f\"   Runs completados: {family_stats['runs_completed']}/{runs}\")\n",
        "                print(f\"   Runs fallidos: {family_stats['runs_failed']}\")\n",
        "                print(f\"   Total dominios procesados: {family_stats['total_domains']}\")\n",
        "                print(f\"   Accuracy promedio: {family_stats['avg_accuracy']:.4f}\")\n",
        "                print(f\"   Tiempo total: {family_stats['total_time']:.4f}s\")\n",
        "                print(f\"   Tiempo promedio por dominio: {family_stats['avg_time_per_domain']:.6f}s\")\n",
        "                print(f\"   Dominios por segundo: {family_stats['total_domains']/family_stats['total_time']:.2f}\")\n",
        "\n",
        "                # Guardar estadísticas de la familia\n",
        "                stats_df = pd.DataFrame([family_stats])\n",
        "                stats_file = os.path.join(results_path, f\"stats_NEW_{family.replace('.gz', '')}.csv\")\n",
        "                stats_df.to_csv(stats_file, index=False)\n",
        "\n",
        "            else:\n",
        "                print(f\"\\n❌ No se completó ningún run para {family}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ Error crítico procesando familia {family}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n\" + \"=\"*50)\n",
        "\n",
        "    print(f\"\\n🎉 Evaluación de nuevas familias completada!\")\n",
        "    print(f\"📁 Resultados guardados en: {results_path}\")\n",
        "\n",
        "def classify_domains_batch(domains, model, dictionaries):\n",
        "    \"\"\"\n",
        "    Clasifica múltiples dominios y mide el tiempo de procesamiento\n",
        "    (Copia de la función del código anterior)\n",
        "    \"\"\"\n",
        "    dga_dict, private_dict, english_dict, noun_dict, verb_dict, adj_dict = dictionaries\n",
        "\n",
        "    predictions = []\n",
        "    probabilities_dga = []\n",
        "    probabilities_notdga = []\n",
        "    processing_times = []\n",
        "\n",
        "    for domain in domains:\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Extraer características\n",
        "        features = extract_features(domain, dga_dict, private_dict, english_dict,\n",
        "                                  noun_dict, verb_dict, adj_dict)\n",
        "        features_array = np.array([features])\n",
        "\n",
        "        # Hacer predicción\n",
        "        prediction = model.predict(features_array)[0]\n",
        "        probability = model.predict_proba(features_array)[0]\n",
        "\n",
        "        end_time = time.time()\n",
        "        query_time = end_time - start_time\n",
        "\n",
        "        predictions.append('dga' if prediction == 1 else 'notdga')\n",
        "        probabilities_dga.append(probability[1])\n",
        "        probabilities_notdga.append(probability[0])\n",
        "        processing_times.append(query_time)\n",
        "\n",
        "    return {\n",
        "        'predictions': predictions,\n",
        "        'probabilities_dga': probabilities_dga,\n",
        "        'probabilities_notdga': probabilities_notdga,\n",
        "        'processing_times': processing_times\n",
        "    }\n",
        "\n",
        "def analyze_new_families_results(results_path='/content/drive/My Drive/results/'):\n",
        "    \"\"\"\n",
        "    Analiza específicamente los resultados de las nuevas familias\n",
        "    \"\"\"\n",
        "    print(\"📊 Analizando resultados de nuevas familias...\")\n",
        "\n",
        "    # Buscar archivos de nuevas familias\n",
        "    results_files = [f for f in os.listdir(results_path)\n",
        "                    if f.startswith('results_RandomForest_NEW_')]\n",
        "\n",
        "    if not results_files:\n",
        "        print(\"❌ No se encontraron archivos de resultados de nuevas familias\")\n",
        "        return\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for file in results_files:\n",
        "        try:\n",
        "            df = pd.read_csv(os.path.join(results_path, file))\n",
        "\n",
        "            # Extraer información del nombre del archivo\n",
        "            parts = file.replace('.csv.gz', '').split('_')\n",
        "            family = parts[3]  # NEW_{family}\n",
        "            run = parts[4]\n",
        "\n",
        "            # Calcular métricas\n",
        "            accuracy = df['correct'].mean()\n",
        "            avg_time = df['query_time'].mean()\n",
        "\n",
        "            # Métricas por tipo de dominio\n",
        "            dga_accuracy = df[df['label'] == 'dga']['correct'].mean()\n",
        "            legit_accuracy = df[df['label'] == 'notdga']['correct'].mean()\n",
        "\n",
        "            all_results.append({\n",
        "                'family': family,\n",
        "                'run': run,\n",
        "                'accuracy': accuracy,\n",
        "                'dga_accuracy': dga_accuracy,\n",
        "                'legit_accuracy': legit_accuracy,\n",
        "                'avg_query_time': avg_time,\n",
        "                'total_domains': len(df),\n",
        "                'dga_domains': len(df[df['label'] == 'dga']),\n",
        "                'legit_domains': len(df[df['label'] == 'notdga'])\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error procesando {file}: {str(e)}\")\n",
        "\n",
        "    if all_results:\n",
        "        summary_df = pd.DataFrame(all_results)\n",
        "\n",
        "        # Resumen por familia\n",
        "        family_summary = summary_df.groupby('family').agg({\n",
        "            'accuracy': ['mean', 'std', 'min', 'max'],\n",
        "            'dga_accuracy': ['mean', 'std'],\n",
        "            'legit_accuracy': ['mean', 'std'],\n",
        "            'avg_query_time': ['mean', 'std'],\n",
        "            'total_domains': 'sum'\n",
        "        }).round(4)\n",
        "\n",
        "        print(\"\\n📈 Resumen de nuevas familias:\")\n",
        "        print(family_summary)\n",
        "\n",
        "        # Comparación con familias originales (si hay datos)\n",
        "        print(f\"\\n🆕 Resultados por familia nueva:\")\n",
        "        for family in summary_df['family'].unique():\n",
        "            family_data = summary_df[summary_df['family'] == family]\n",
        "            print(f\"\\n{family.upper()}:\")\n",
        "            print(f\"  📊 Accuracy promedio: {family_data['accuracy'].mean():.4f} ±{family_data['accuracy'].std():.4f}\")\n",
        "            print(f\"  🎯 DGA detection: {family_data['dga_accuracy'].mean():.4f}\")\n",
        "            print(f\"  ✅ Legit detection: {family_data['legit_accuracy'].mean():.4f}\")\n",
        "            print(f\"  ⏱️ Tiempo promedio: {family_data['avg_query_time'].mean():.6f}s\")\n",
        "            print(f\"  📝 Runs completados: {len(family_data)}\")\n",
        "\n",
        "        # Guardar resumen\n",
        "        summary_file = os.path.join(results_path, 'new_families_summary.csv')\n",
        "        family_summary.to_csv(summary_file)\n",
        "\n",
        "        detailed_file = os.path.join(results_path, 'new_families_detailed.csv')\n",
        "        summary_df.to_csv(detailed_file, index=False)\n",
        "\n",
        "        print(f\"\\n💾 Resúmenes guardados:\")\n",
        "        print(f\"  - {summary_file}\")\n",
        "        print(f\"  - {detailed_file}\")\n",
        "\n",
        "        return summary_df\n",
        "\n",
        "    return None\n",
        "\n",
        "# === EJEMPLO DE USO ===\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🆕 Evaluación de Nuevas Familias DGA\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Cargar el modelo previamente entrenado\n",
        "    print(\"📥 Cargando modelo DGA...\")\n",
        "    try:\n",
        "        model, dictionaries, metadata = load_dga_model()\n",
        "        print(\"✅ Modelo cargado exitosamente\")\n",
        "\n",
        "        # Ejecutar evaluación de nuevas familias\n",
        "        print(\"\\n🚀 Iniciando evaluación de nuevas familias...\")\n",
        "        evaluate_new_dga_families(\n",
        "            model=model,\n",
        "            dictionaries=dictionaries,\n",
        "            new_families_path='/content/drive/My Drive/New_Families/',\n",
        "            legit_file_path='/content/drive/My Drive/Familias_Test/legit.gz',\n",
        "            results_path='/content/drive/My Drive/results/',\n",
        "            runs=30,\n",
        "            chunk_size=50,\n",
        "            skip_legit_chunks=30\n",
        "        )\n",
        "\n",
        "        # Analizar resultados\n",
        "        print(\"\\n📊 Analizando resultados...\")\n",
        "        results_summary = analyze_new_families_results()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {str(e)}\")\n",
        "        print(\"💡 Asegúrate de haber entrenado y guardado el modelo primero\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yavn0LP8iE1H",
        "outputId": "fe9bf87e-86fa-4f93-c7fd-056b1f00c9e1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🆕 Evaluación de Nuevas Familias DGA\n",
            "==================================================\n",
            "📥 Cargando modelo DGA...\n",
            "📥 Cargando modelo...\n",
            "✅ Modelo cargado exitosamente\n",
            "📥 Cargando diccionarios...\n",
            "✅ Diccionarios cargados exitosamente\n",
            "📥 Cargando metadatos...\n",
            "✅ Metadatos cargados exitosamente\n",
            "\n",
            "📊 Información del modelo:\n",
            "  Tipo: RandomForestClassifier\n",
            "  N° de árboles: 100\n",
            "  N° de características: 16\n",
            "  Tamaños de diccionarios:\n",
            "    - english_dict: 234,351 palabras\n",
            "    - noun_dict: 100 palabras\n",
            "    - verb_dict: 106 palabras\n",
            "    - adj_dict: 110 palabras\n",
            "    - dga_dict: 77,834 palabras\n",
            "    - private_dict: 74,121 palabras\n",
            "✅ Modelo cargado exitosamente\n",
            "\n",
            "🚀 Iniciando evaluación de nuevas familias...\n",
            "🆕 Evaluando nuevas familias DGA...\n",
            "📂 Ruta familias: /content/drive/My Drive/New_Families/\n",
            "📂 Archivo legit: /content/drive/My Drive/Familias_Test/legit.gz\n",
            "⏭️ Saltando 30 chunks de legit\n",
            "🎯 Runs por familia: 30\n",
            "📦 Chunk size: 50\n",
            "============================================================\n",
            "\n",
            "🔍 Procesando familia: bigviktor.gz\n",
            "⏭️ Saltando 30 chunks de dominios legítimos...\n",
            "   Saltados 30/30 chunks\n",
            "✅ Iniciando evaluación de bigviktor.gz\n",
            "\n",
            "✅ bigviktor.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Runs fallidos: 0\n",
            "   Total dominios procesados: 3000\n",
            "   Accuracy promedio: 0.4963\n",
            "   Tiempo total: 156.5061s\n",
            "   Tiempo promedio por dominio: 0.052169s\n",
            "   Dominios por segundo: 19.17\n",
            "\n",
            "==================================================\n",
            "\n",
            "🔍 Procesando familia: pizd.gz\n",
            "⏭️ Saltando 30 chunks de dominios legítimos...\n",
            "   Saltados 30/30 chunks\n",
            "✅ Iniciando evaluación de pizd.gz\n",
            "\n",
            "✅ pizd.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Runs fallidos: 0\n",
            "   Total dominios procesados: 3000\n",
            "   Accuracy promedio: 0.4903\n",
            "   Tiempo total: 157.0484s\n",
            "   Tiempo promedio por dominio: 0.052349s\n",
            "   Dominios por segundo: 19.10\n",
            "\n",
            "==================================================\n",
            "\n",
            "🔍 Procesando familia: ngioweb.gz\n",
            "⏭️ Saltando 30 chunks de dominios legítimos...\n",
            "   Saltados 30/30 chunks\n",
            "✅ Iniciando evaluación de ngioweb.gz\n",
            "\n",
            "✅ ngioweb.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Runs fallidos: 0\n",
            "   Total dominios procesados: 3000\n",
            "   Accuracy promedio: 0.4850\n",
            "   Tiempo total: 143.6180s\n",
            "   Tiempo promedio por dominio: 0.047873s\n",
            "   Dominios por segundo: 20.89\n",
            "\n",
            "==================================================\n",
            "\n",
            "🎉 Evaluación de nuevas familias completada!\n",
            "📁 Resultados guardados en: /content/drive/My Drive/results/\n",
            "\n",
            "📊 Analizando resultados...\n",
            "📊 Analizando resultados de nuevas familias...\n",
            "\n",
            "📈 Resumen de nuevas familias:\n",
            "          accuracy                     dga_accuracy         legit_accuracy  \\\n",
            "              mean     std   min   max         mean     std           mean   \n",
            "family                                                                       \n",
            "bigviktor   0.4963  0.0145  0.47  0.53       0.0227  0.0227           0.97   \n",
            "ngioweb     0.4850  0.0111  0.46  0.50       0.0000  0.0000           0.97   \n",
            "pizd        0.4903  0.0143  0.46  0.51       0.0107  0.0136           0.97   \n",
            "\n",
            "                  avg_query_time         total_domains  \n",
            "              std           mean     std           sum  \n",
            "family                                                  \n",
            "bigviktor  0.0221         0.0522  0.0080          3000  \n",
            "ngioweb    0.0221         0.0479  0.0019          3000  \n",
            "pizd       0.0221         0.0523  0.0130          3000  \n",
            "\n",
            "🆕 Resultados por familia nueva:\n",
            "\n",
            "BIGVIKTOR:\n",
            "  📊 Accuracy promedio: 0.4963 ±0.0145\n",
            "  🎯 DGA detection: 0.0227\n",
            "  ✅ Legit detection: 0.9700\n",
            "  ⏱️ Tiempo promedio: 0.052163s\n",
            "  📝 Runs completados: 30\n",
            "\n",
            "PIZD:\n",
            "  📊 Accuracy promedio: 0.4903 ±0.0143\n",
            "  🎯 DGA detection: 0.0107\n",
            "  ✅ Legit detection: 0.9700\n",
            "  ⏱️ Tiempo promedio: 0.052344s\n",
            "  📝 Runs completados: 30\n",
            "\n",
            "NGIOWEB:\n",
            "  📊 Accuracy promedio: 0.4850 ±0.0111\n",
            "  🎯 DGA detection: 0.0000\n",
            "  ✅ Legit detection: 0.9700\n",
            "  ⏱️ Tiempo promedio: 0.047867s\n",
            "  📝 Runs completados: 30\n",
            "\n",
            "💾 Resúmenes guardados:\n",
            "  - /content/drive/My Drive/results/new_families_summary.csv\n",
            "  - /content/drive/My Drive/results/new_families_detailed.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wOD05qSUsL3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import joblib\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def save_dga_model(model, dictionaries, model_path='/content/drive/My Drive/models/'):\n",
        "    \"\"\"\n",
        "    Guarda el modelo DGA entrenado y todos sus diccionarios\n",
        "\n",
        "    Args:\n",
        "        model: Modelo RandomForest entrenado\n",
        "        dictionaries: Tupla con todos los diccionarios necesarios\n",
        "        model_path: Ruta donde guardar el modelo\n",
        "    \"\"\"\n",
        "    # Crear directorio si no existe\n",
        "    Path(model_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Guardar el modelo\n",
        "    model_file = os.path.join(model_path, 'dga_random_forest_model.joblib')\n",
        "    joblib.dump(model, model_file)\n",
        "    print(f\"✅ Modelo guardado en: {model_file}\")\n",
        "\n",
        "    # Guardar los diccionarios\n",
        "    dictionaries_file = os.path.join(model_path, 'dga_dictionaries.pkl')\n",
        "    with open(dictionaries_file, 'wb') as f:\n",
        "        pickle.dump(dictionaries, f)\n",
        "    print(f\"✅ Diccionarios guardados en: {dictionaries_file}\")\n",
        "\n",
        "    # Guardar metadatos del modelo\n",
        "    metadata = {\n",
        "        'model_type': 'RandomForestClassifier',\n",
        "        'n_estimators': model.n_estimators,\n",
        "        'max_depth': model.max_depth,\n",
        "        'min_samples_split': model.min_samples_split,\n",
        "        'min_samples_leaf': model.min_samples_leaf,\n",
        "        'random_state': model.random_state,\n",
        "        'n_features': model.n_features_in_,\n",
        "        'feature_names': [\n",
        "            'domain_len', 'ascii_sum', 'vowel_count', 'vowel_dist',\n",
        "            'digit_dash_count', 'digit_dash_dist', 'word_norm', 'word_dga',\n",
        "            'noun_count', 'verb_count', 'adj_count', 'private_count',\n",
        "            'ratio_dga_norm', 'max_len_word', 'min_len_word', 'word_char_ratio'\n",
        "        ],\n",
        "        'dictionary_sizes': {\n",
        "            'english_dict': len(dictionaries[2]),\n",
        "            'noun_dict': len(dictionaries[3]),\n",
        "            'verb_dict': len(dictionaries[4]),\n",
        "            'adj_dict': len(dictionaries[5]),\n",
        "            'dga_dict': len(dictionaries[0]),\n",
        "            'private_dict': len(dictionaries[1])\n",
        "        }\n",
        "    }\n",
        "\n",
        "    metadata_file = os.path.join(model_path, 'model_metadata.pkl')\n",
        "    with open(metadata_file, 'wb') as f:\n",
        "        pickle.dump(metadata, f)\n",
        "    print(f\"✅ Metadatos guardados en: {metadata_file}\")\n",
        "\n",
        "    print(f\"\\n📦 Modelo completo guardado en: {model_path}\")\n",
        "    print(\"Archivos creados:\")\n",
        "    print(f\"  - {os.path.basename(model_file)}\")\n",
        "    print(f\"  - {os.path.basename(dictionaries_file)}\")\n",
        "    print(f\"  - {os.path.basename(metadata_file)}\")\n",
        "\n",
        "def load_dga_model(model_path='/content/drive/My Drive/models/'):\n",
        "    \"\"\"\n",
        "    Carga el modelo DGA y sus diccionarios\n",
        "\n",
        "    Args:\n",
        "        model_path: Ruta donde está guardado el modelo\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, dictionaries, metadata)\n",
        "    \"\"\"\n",
        "    # Verificar que los archivos existen\n",
        "    model_file = os.path.join(model_path, 'dga_random_forest_model.joblib')\n",
        "    dictionaries_file = os.path.join(model_path, 'dga_dictionaries.pkl')\n",
        "    metadata_file = os.path.join(model_path, 'model_metadata.pkl')\n",
        "\n",
        "    if not os.path.exists(model_file):\n",
        "        raise FileNotFoundError(f\"Modelo no encontrado: {model_file}\")\n",
        "    if not os.path.exists(dictionaries_file):\n",
        "        raise FileNotFoundError(f\"Diccionarios no encontrados: {dictionaries_file}\")\n",
        "    if not os.path.exists(metadata_file):\n",
        "        raise FileNotFoundError(f\"Metadatos no encontrados: {metadata_file}\")\n",
        "\n",
        "    # Cargar el modelo\n",
        "    print(\"📥 Cargando modelo...\")\n",
        "    model = joblib.load(model_file)\n",
        "    print(\"✅ Modelo cargado exitosamente\")\n",
        "\n",
        "    # Cargar los diccionarios\n",
        "    print(\"📥 Cargando diccionarios...\")\n",
        "    with open(dictionaries_file, 'rb') as f:\n",
        "        dictionaries = pickle.load(f)\n",
        "    print(\"✅ Diccionarios cargados exitosamente\")\n",
        "\n",
        "    # Cargar metadatos\n",
        "    print(\"📥 Cargando metadatos...\")\n",
        "    with open(metadata_file, 'rb') as f:\n",
        "        metadata = pickle.load(f)\n",
        "    print(\"✅ Metadatos cargados exitosamente\")\n",
        "\n",
        "    # Mostrar información del modelo\n",
        "    print(f\"\\n📊 Información del modelo:\")\n",
        "    print(f\"  Tipo: {metadata['model_type']}\")\n",
        "    print(f\"  N° de árboles: {metadata['n_estimators']}\")\n",
        "    print(f\"  N° de características: {metadata['n_features']}\")\n",
        "    print(f\"  Tamaños de diccionarios:\")\n",
        "    for dict_name, size in metadata['dictionary_sizes'].items():\n",
        "        print(f\"    - {dict_name}: {size:,} palabras\")\n",
        "\n",
        "    return model, dictionaries, metadata\n",
        "\n",
        "def test_loaded_model(model, dictionaries, test_domains=None):\n",
        "    \"\"\"\n",
        "    Prueba el modelo cargado con algunos dominios de ejemplo\n",
        "\n",
        "    Args:\n",
        "        model: Modelo cargado\n",
        "        dictionaries: Diccionarios cargados\n",
        "        test_domains: Lista de dominios para probar (opcional)\n",
        "    \"\"\"\n",
        "    if test_domains is None:\n",
        "        test_domains = [\n",
        "            'google.com',\n",
        "            'facebook.com',\n",
        "            'xkvbpqr.com',\n",
        "            'mnbvcxz.net',\n",
        "            'microsoft.com',\n",
        "            'randomstring123.org'\n",
        "        ]\n",
        "\n",
        "    print(\"\\n🧪 Probando modelo con dominios de ejemplo:\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for domain in test_domains:\n",
        "        result = classify_domain(domain, model, dictionaries)\n",
        "        print(f\"{domain:20} -> {result['prediction']:8} (prob: {result['dga_probability']:.3f})\")\n",
        "\n",
        "# === EJEMPLO DE USO COMPLETO ===\n",
        "\n",
        "def complete_training_and_saving_example():\n",
        "    \"\"\"\n",
        "    Ejemplo completo de entrenamiento, guardado y carga del modelo\n",
        "    \"\"\"\n",
        "    print(\"🚀 Ejemplo completo: Entrenar, Guardar y Cargar modelo DGA\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Paso 1: Crear datos de ejemplo (reemplaza con tus datos reales)\n",
        "    sample_data = {\n",
        "        'domain': [\n",
        "            # Dominios legítimos\n",
        "            'google.com', 'facebook.com', 'microsoft.com', 'amazon.com',\n",
        "            'youtube.com', 'wikipedia.org', 'twitter.com', 'instagram.com',\n",
        "            'linkedin.com', 'github.com', 'stackoverflow.com', 'reddit.com',\n",
        "\n",
        "            # Dominios DGA simulados\n",
        "            'xkvbpqr.com', 'mnbvcxz.net', 'qwertyuiop.org', 'asdfghjkl.info',\n",
        "            'randomstring123.com', 'anotherfakedom.net', 'abcdef.xyz',\n",
        "            'ksdjfhskjh.com', 'pqowieuryt.net', 'zxcvbnm.org', 'hjklqwer.com'\n",
        "        ],\n",
        "        'label': (\n",
        "            ['notdga'] * 12 +  # 12 legítimos\n",
        "            ['dga'] * 11       # 11 DGA\n",
        "        )\n",
        "    }\n",
        "\n",
        "    df_example = pd.DataFrame(sample_data)\n",
        "    print(f\"📊 Dataset de ejemplo: {len(df_example)} dominios\")\n",
        "    print(f\"  - Legítimos: {(df_example['label'] == 'notdga').sum()}\")\n",
        "    print(f\"  - DGA: {(df_example['label'] == 'dga').sum()}\")\n",
        "\n",
        "    # Paso 2: Entrenar el modelo\n",
        "    print(\"\\n🏋️ Entrenando modelo...\")\n",
        "    model, dictionaries = train_dga_model(df_example)\n",
        "\n",
        "    # Paso 3: Guardar el modelo\n",
        "    print(\"\\n💾 Guardando modelo...\")\n",
        "    save_dga_model(model, dictionaries)\n",
        "\n",
        "    # Paso 4: Simular reinicio del programa (cargar modelo)\n",
        "    print(\"\\n🔄 Simulando carga del modelo...\")\n",
        "    loaded_model, loaded_dictionaries, metadata = load_dga_model()\n",
        "\n",
        "    # Paso 5: Probar el modelo cargado\n",
        "    test_loaded_model(loaded_model, loaded_dictionaries)\n",
        "\n",
        "    print(\"\\n✅ Ejemplo completado exitosamente!\")\n",
        "    return loaded_model, loaded_dictionaries\n",
        "\n",
        "# === FUNCIONES AUXILIARES PARA LA CARGA ===\n",
        "\n",
        "def quick_load_and_test():\n",
        "    \"\"\"\n",
        "    Función rápida para cargar y probar el modelo guardado\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(\"⚡ Carga rápida del modelo DGA...\")\n",
        "        model, dictionaries, metadata = load_dga_model()\n",
        "\n",
        "        # Probar con algunos dominios\n",
        "        test_domains = [\n",
        "            'suspicious-domain.com',\n",
        "            'google.com',\n",
        "            'qwerty123.net',\n",
        "            'microsoft.com'\n",
        "        ]\n",
        "\n",
        "        test_loaded_model(model, dictionaries, test_domains)\n",
        "\n",
        "        return model, dictionaries\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error cargando el modelo: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "def verify_model_files(model_path='/content/drive/My Drive/models/'):\n",
        "    \"\"\"\n",
        "    Verifica que todos los archivos del modelo existen\n",
        "    \"\"\"\n",
        "    required_files = [\n",
        "        'dga_random_forest_model.joblib',\n",
        "        'dga_dictionaries.pkl',\n",
        "        'model_metadata.pkl'\n",
        "    ]\n",
        "\n",
        "    print(f\"🔍 Verificando archivos del modelo en: {model_path}\")\n",
        "\n",
        "    all_present = True\n",
        "    for file in required_files:\n",
        "        file_path = os.path.join(model_path, file)\n",
        "        if os.path.exists(file_path):\n",
        "            size = os.path.getsize(file_path)\n",
        "            print(f\"  ✅ {file} ({size:,} bytes)\")\n",
        "        else:\n",
        "            print(f\"  ❌ {file} - NO ENCONTRADO\")\n",
        "            all_present = False\n",
        "\n",
        "    return all_present\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Verificar si el modelo ya existe\n",
        "    save_dga_model(model, dictionaries, model_path='/content/drive/My Drive/models/')\n",
        "    if verify_model_files():\n",
        "        print(\"📂 Modelo encontrado. Cargando...\")\n",
        "        model, dictionaries = quick_load_and_test()\n",
        "    else:\n",
        "        print(\"📂 Modelo no encontrado. Ejecutar entrenamiento completo...\")\n",
        "        # complete_training_and_saving_example()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV_CNO5XsL7m",
        "outputId": "e85f228d-a1c7-4d3d-cd78-76e10851a960"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo guardado en: /content/drive/My Drive/models/dga_random_forest_model.joblib\n",
            "✅ Diccionarios guardados en: /content/drive/My Drive/models/dga_dictionaries.pkl\n",
            "✅ Metadatos guardados en: /content/drive/My Drive/models/model_metadata.pkl\n",
            "\n",
            "📦 Modelo completo guardado en: /content/drive/My Drive/models/\n",
            "Archivos creados:\n",
            "  - dga_random_forest_model.joblib\n",
            "  - dga_dictionaries.pkl\n",
            "  - model_metadata.pkl\n",
            "🔍 Verificando archivos del modelo en: /content/drive/My Drive/models/\n",
            "  ✅ dga_random_forest_model.joblib (4,793,609 bytes)\n",
            "  ✅ dga_dictionaries.pkl (4,560,688 bytes)\n",
            "  ✅ model_metadata.pkl (531 bytes)\n",
            "📂 Modelo encontrado. Cargando...\n",
            "⚡ Carga rápida del modelo DGA...\n",
            "📥 Cargando modelo...\n",
            "✅ Modelo cargado exitosamente\n",
            "📥 Cargando diccionarios...\n",
            "✅ Diccionarios cargados exitosamente\n",
            "📥 Cargando metadatos...\n",
            "✅ Metadatos cargados exitosamente\n",
            "\n",
            "📊 Información del modelo:\n",
            "  Tipo: RandomForestClassifier\n",
            "  N° de árboles: 100\n",
            "  N° de características: 16\n",
            "  Tamaños de diccionarios:\n",
            "    - english_dict: 234,351 palabras\n",
            "    - noun_dict: 100 palabras\n",
            "    - verb_dict: 106 palabras\n",
            "    - adj_dict: 110 palabras\n",
            "    - dga_dict: 77,834 palabras\n",
            "    - private_dict: 74,121 palabras\n",
            "\n",
            "🧪 Probando modelo con dominios de ejemplo:\n",
            "------------------------------------------------------------\n",
            "suspicious-domain.com -> notdga   (prob: 0.019)\n",
            "google.com           -> dga      (prob: 0.989)\n",
            "qwerty123.net        -> notdga   (prob: 0.000)\n",
            "microsoft.com        -> notdga   (prob: 0.000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v019DTUQsL-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KL20_ilKsMBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBCFGqgesMD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T3zHS_RRsMG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8QGUo_okiE3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cl-xPK0AiE62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ltzJa69dgHFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lOX8ZBpfgHIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_hwnK-v2gHKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runs=30\n",
        "families = [\n",
        "    'matsnu.gz',\n",
        "    'suppobox.gz',\n",
        "    'charbot.gz',\n",
        "    'gozi.gz',\n",
        "    'manuelita.gz',\n",
        "    'rovnix.gz',\n",
        "    'deception.gz',\n",
        "    'nymaim.gz',\n",
        "    'bigviktor.gz',\n",
        "    'pizd.gz',\n",
        "    'ngioweb.gz'\n",
        "]\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def fpr_tpr(y, ypred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y, ypred).ravel()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    return fpr, tpr\n",
        "\n",
        "# Listas para métricas globales\n",
        "all_acc, all_pre, all_rec, all_f1 = [], [], [], []\n",
        "all_fpr, all_tpr, all_qt, all_qts = [], [], [], []\n",
        "total_unknowns_global = 0\n",
        "\n",
        "\n",
        "for family in families:\n",
        "    acc = []\n",
        "    pre = []\n",
        "    rec = []\n",
        "    f1 = []\n",
        "    fpr = []\n",
        "    tpr = []\n",
        "    qt = []\n",
        "    qts = []\n",
        "    total_unknowns = 0\n",
        "    for run in range(runs):\n",
        "        path = f'/content/drive/My Drive/results/results_RandomForest_{family}_{run}.csv.gz'\n",
        "        df = pd.read_csv(path)\n",
        "        #print(df)\n",
        "        y_true = (df[\"label\"] == 'dga').astype(int)\n",
        "        y_pred = (df[\"pred\"] == 'dga').astype(int)\n",
        "        #y_pred = df[\"pred\"]\n",
        "\n",
        "                # Métricas\n",
        "        acc.append(accuracy_score(y_true, y_pred))\n",
        "        pre.append(precision_score(y_true, y_pred, zero_division=0))\n",
        "        rec.append(recall_score(y_true, y_pred, zero_division=0))\n",
        "        f1.append(f1_score(y_true, y_pred, zero_division=0))\n",
        "        fpr_val, tpr_val = fpr_tpr(y_true, y_pred)\n",
        "        fpr.append(fpr_val)\n",
        "        tpr.append(tpr_val)\n",
        "\n",
        "        if 'query_time' in df.columns:\n",
        "            qt.append(df['query_time'].mean())\n",
        "            qts.append(df['query_time'].std())\n",
        "\n",
        "    # Promedios por familia\n",
        "    if acc:  # solo si hubo archivos válidos\n",
        "        print(f'{family.split(\".\")[0]:15}: '\n",
        "              f'acc:{np.mean(acc):.2f}±{np.std(acc):.3f} '\n",
        "              f'f1:{np.mean(f1):.2f}±{np.std(f1):.3f} '\n",
        "              f'pre:{np.mean(pre):.2f}±{np.std(pre):.3f} '\n",
        "              f'rec:{np.mean(rec):.2f}±{np.std(rec):.3f} '\n",
        "              f'FPR:{np.mean(fpr):.2f}±{np.std(fpr):.3f} '\n",
        "              f'TPR:{np.mean(tpr):.2f}±{np.std(tpr):.3f} '\n",
        "              f'QT:{np.mean(qt):.5f}±{np.std(qt):.5f} '\n",
        "              f'Unknowns: {total_unknowns}')\n",
        "\n",
        "        all_acc.append(np.mean(acc))\n",
        "        all_pre.append(np.mean(pre))\n",
        "        all_rec.append(np.mean(rec))\n",
        "        all_f1.append(np.mean(f1))\n",
        "        all_fpr.append(np.mean(fpr))\n",
        "        all_tpr.append(np.mean(tpr))\n",
        "        all_qt.append(np.mean(qt))\n",
        "        all_qts.append(np.mean(qts))\n",
        "        total_unknowns_global += total_unknowns\n",
        "\n",
        "# 🔍 Métricas globales\n",
        "print(\"\\n### 📊 Métricas globales ###\")\n",
        "print(f'Accuracy   : {np.mean(all_acc):.2f}')\n",
        "print(f'F1-Score   : {np.mean(all_f1):.2f}')\n",
        "print(f'Precision  : {np.mean(all_pre):.2f}')\n",
        "print(f'Recall     : {np.mean(all_rec):.2f}')\n",
        "print(f'FPR        : {np.mean(all_fpr):.2f}')\n",
        "print(f'TPR        : {np.mean(all_tpr):.2f}')\n",
        "print(f'Query time : {np.mean(all_qt):.5f} ± {np.mean(all_qts):.5f}')\n",
        "print(f'Total unknown classifications: {total_unknowns_global}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta40upzq_H5c",
        "outputId": "663cf44e-d145-4a90-80bc-d8a2a9c1c4f3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matsnu         : acc:0.76±0.032 f1:0.70±0.050 pre:0.91±0.009 rec:0.58±0.064 FPR:0.06±0.000 TPR:0.58±0.064 QT:0.04592±0.00043 Unknowns: 0\n",
            "suppobox       : acc:0.52±0.027 f1:0.16±0.086 pre:0.54±0.202 rec:0.09±0.055 FPR:0.06±0.000 TPR:0.09±0.055 QT:0.04615±0.00155 Unknowns: 0\n",
            "charbot        : acc:0.47±0.002 f1:0.00±0.009 pre:0.02±0.062 rec:0.00±0.005 FPR:0.06±0.000 TPR:0.00±0.005 QT:0.04602±0.00059 Unknowns: 0\n",
            "gozi           : acc:0.47±0.000 f1:0.00±0.000 pre:0.00±0.000 rec:0.00±0.000 FPR:0.06±0.000 TPR:0.00±0.000 QT:0.04623±0.00100 Unknowns: 0\n",
            "manuelita      : acc:0.48±0.007 f1:0.04±0.026 pre:0.26±0.136 rec:0.02±0.015 FPR:0.06±0.000 TPR:0.02±0.015 QT:0.04633±0.00190 Unknowns: 0\n",
            "rovnix         : acc:0.47±0.000 f1:0.00±0.000 pre:0.00±0.000 rec:0.00±0.000 FPR:0.06±0.000 TPR:0.00±0.000 QT:0.04659±0.00258 Unknowns: 0\n",
            "deception      : acc:0.92±0.020 f1:0.92±0.022 pre:0.94±0.003 rec:0.90±0.039 FPR:0.06±0.000 TPR:0.90±0.039 QT:0.04746±0.00439 Unknowns: 0\n",
            "nymaim         : acc:0.55±0.025 f1:0.26±0.074 pre:0.70±0.094 rec:0.16±0.051 FPR:0.06±0.000 TPR:0.16±0.051 QT:0.04664±0.00200 Unknowns: 0\n",
            "bigviktor      : acc:0.50±0.014 f1:0.04±0.041 pre:0.35±0.300 rec:0.02±0.022 FPR:0.03±0.022 TPR:0.02±0.022 QT:0.05216±0.00782 Unknowns: 0\n",
            "pizd           : acc:0.49±0.014 f1:0.02±0.025 pre:0.27±0.341 rec:0.01±0.013 FPR:0.03±0.022 TPR:0.01±0.013 QT:0.05234±0.01281 Unknowns: 0\n",
            "ngioweb        : acc:0.48±0.011 f1:0.00±0.000 pre:0.00±0.000 rec:0.00±0.000 FPR:0.03±0.022 TPR:0.00±0.000 QT:0.04787±0.00190 Unknowns: 0\n",
            "\n",
            "### 📊 Métricas globales ###\n",
            "Accuracy   : 0.56\n",
            "F1-Score   : 0.19\n",
            "Precision  : 0.36\n",
            "Recall     : 0.16\n",
            "FPR        : 0.05\n",
            "TPR        : 0.16\n",
            "Query time : 0.04761 ± 0.00544\n",
            "Total unknown classifications: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "def rename_family_files():\n",
        "    # Mapeo de nombres actuales a nombres nuevos\n",
        "    family_mapping = {\n",
        "        'matsnu': 'matsnu.gz',\n",
        "        'suppobox': 'suppobox.gz',\n",
        "        'charbot': 'charbot.gz',\n",
        "        'gozi': 'gozi.gz',\n",
        "        'manuelita': 'manuelita.gz',\n",
        "        'rovnix': 'rovnix.gz',\n",
        "        'deception': 'deception.gz',\n",
        "        'nymaim': 'nymaim.gz',\n",
        "        'NEW_bigviktor': 'bigviktor.gz',\n",
        "        'NEW_pizd': 'pizd.gz',\n",
        "        'NEW_ngioweb': 'ngioweb.gz'\n",
        "    }\n",
        "\n",
        "    # Cambiar al directorio results\n",
        "    results_dir = '/content/drive/My Drive/results'\n",
        "\n",
        "    if not os.path.exists(results_dir):\n",
        "        print(f\"Error: La carpeta '{results_dir}' no existe\")\n",
        "        return\n",
        "\n",
        "    os.chdir(results_dir)\n",
        "\n",
        "    # Contadores para estadísticas\n",
        "    renamed_count = 0\n",
        "    not_found_count = 0\n",
        "\n",
        "    print(\"Iniciando renombrado de archivos...\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Procesar cada familia\n",
        "    for old_family, new_family in family_mapping.items():\n",
        "        # Buscar archivos que contengan el nombre de la familia actual\n",
        "        pattern = f\"*{old_family}*.csv.gz\"\n",
        "        matching_files = glob.glob(pattern)\n",
        "\n",
        "        print(f\"\\nProcesando familia: {old_family} -> {new_family}\")\n",
        "        print(f\"Archivos encontrados: {len(matching_files)}\")\n",
        "\n",
        "        if not matching_files:\n",
        "            print(f\"  ⚠️  No se encontraron archivos para la familia '{old_family}'\")\n",
        "            not_found_count += 1\n",
        "            continue\n",
        "\n",
        "        # Renombrar cada archivo encontrado\n",
        "        for old_filename in matching_files:\n",
        "            # Reemplazar el nombre de la familia en el nombre del archivo\n",
        "            new_filename = old_filename.replace(old_family, new_family)\n",
        "\n",
        "            try:\n",
        "                os.rename(old_filename, new_filename)\n",
        "                print(f\"  ✅ {old_filename} -> {new_filename}\")\n",
        "                renamed_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"  ❌ Error renombrando {old_filename}: {e}\")\n",
        "\n",
        "    # Mostrar estadísticas finales\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"RESUMEN FINAL:\")\n",
        "    print(f\"Archivos renombrados exitosamente: {renamed_count}\")\n",
        "    print(f\"Familias sin archivos encontrados: {not_found_count}\")\n",
        "    print(\"Proceso completado.\")\n",
        "\n",
        "    # Volver al directorio original\n",
        "    os.chdir('..')\n",
        "\n",
        "# Función alternativa que también muestra una vista previa antes de renombrar\n",
        "def preview_rename_family_files():\n",
        "    \"\"\"Versión que muestra qué cambios se harán antes de ejecutarlos\"\"\"\n",
        "\n",
        "    family_mapping = {\n",
        "        'matsnu': 'matsnu.gz',\n",
        "        'suppobox': 'suppobox.gz',\n",
        "        'charbot': 'charbot.gz',\n",
        "        'gozi': 'gozi.gz',\n",
        "        'manuelita': 'manuelita.gz',\n",
        "        'rovnix': 'rovnix.gz',\n",
        "        'deception': 'deception.gz',\n",
        "        'nymaim': 'nymaim.gz',\n",
        "        'bigviktor': 'bigviktor.gz',\n",
        "        'pizd': 'pizd.gz',\n",
        "        'ngioweb': 'ngioweb.gz'\n",
        "    }\n",
        "\n",
        "    results_dir = 'results'\n",
        "\n",
        "    if not os.path.exists(results_dir):\n",
        "        print(f\"Error: La carpeta '{results_dir}' no existe\")\n",
        "        return\n",
        "\n",
        "    os.chdir(results_dir)\n",
        "\n",
        "    print(\"VISTA PREVIA DE CAMBIOS:\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    changes_to_make = []\n",
        "\n",
        "    # Mostrar vista previa\n",
        "    for old_family, new_family in family_mapping.items():\n",
        "        pattern = f\"*{old_family}*.csv.gz\"\n",
        "        matching_files = glob.glob(pattern)\n",
        "\n",
        "        if matching_files:\n",
        "            print(f\"\\nFamilia: {old_family} -> {new_family} ({len(matching_files)} archivos)\")\n",
        "            for old_filename in matching_files:\n",
        "                new_filename = old_filename.replace(old_family, new_family)\n",
        "                print(f\"  {old_filename} -> {new_filename}\")\n",
        "                changes_to_make.append((old_filename, new_filename))\n",
        "\n",
        "    if not changes_to_make:\n",
        "        print(\"No se encontraron archivos para renombrar.\")\n",
        "        os.chdir('..')\n",
        "        return\n",
        "\n",
        "    # Confirmar cambios\n",
        "    print(f\"\\n¿Proceder con el renombrado de {len(changes_to_make)} archivos? (s/n): \", end=\"\")\n",
        "    confirm = input().lower().strip()\n",
        "\n",
        "    if confirm in ['s', 'si', 'sí', 'y', 'yes']:\n",
        "        print(\"\\nEjecutando cambios...\")\n",
        "        renamed_count = 0\n",
        "\n",
        "        for old_filename, new_filename in changes_to_make:\n",
        "            try:\n",
        "                os.rename(old_filename, new_filename)\n",
        "                print(f\"  ✅ {old_filename} -> {new_filename}\")\n",
        "                renamed_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"  ❌ Error: {e}\")\n",
        "\n",
        "        print(f\"\\nCompletado: {renamed_count} archivos renombrados.\")\n",
        "    else:\n",
        "        print(\"Operación cancelada.\")\n",
        "\n",
        "    os.chdir('..')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Descomenta la función que quieras usar:\n",
        "\n",
        "    # Opción 1: Renombrar directamente\n",
        "    rename_family_files()\n",
        "\n",
        "    # Opción 2: Mostrar vista previa y confirmar (recomendado)\n",
        "    # preview_rename_family_files()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FivH0iDD1FNa",
        "outputId": "f3d2cdd2-c6e5-4cfa-e83a-263adbea79c9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando renombrado de archivos...\n",
            "--------------------------------------------------\n",
            "\n",
            "Procesando familia: matsnu -> matsnu.gz\n",
            "Archivos encontrados: 30\n",
            "  ✅ results_RandomForest_matsnu_0.csv.gz -> results_RandomForest_matsnu.gz_0.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_1.csv.gz -> results_RandomForest_matsnu.gz_1.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_2.csv.gz -> results_RandomForest_matsnu.gz_2.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_3.csv.gz -> results_RandomForest_matsnu.gz_3.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_4.csv.gz -> results_RandomForest_matsnu.gz_4.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_5.csv.gz -> results_RandomForest_matsnu.gz_5.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_6.csv.gz -> results_RandomForest_matsnu.gz_6.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_7.csv.gz -> results_RandomForest_matsnu.gz_7.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_8.csv.gz -> results_RandomForest_matsnu.gz_8.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_9.csv.gz -> results_RandomForest_matsnu.gz_9.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_10.csv.gz -> results_RandomForest_matsnu.gz_10.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_11.csv.gz -> results_RandomForest_matsnu.gz_11.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_12.csv.gz -> results_RandomForest_matsnu.gz_12.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_13.csv.gz -> results_RandomForest_matsnu.gz_13.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_14.csv.gz -> results_RandomForest_matsnu.gz_14.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_15.csv.gz -> results_RandomForest_matsnu.gz_15.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_16.csv.gz -> results_RandomForest_matsnu.gz_16.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_17.csv.gz -> results_RandomForest_matsnu.gz_17.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_18.csv.gz -> results_RandomForest_matsnu.gz_18.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_19.csv.gz -> results_RandomForest_matsnu.gz_19.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_20.csv.gz -> results_RandomForest_matsnu.gz_20.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_21.csv.gz -> results_RandomForest_matsnu.gz_21.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_22.csv.gz -> results_RandomForest_matsnu.gz_22.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_23.csv.gz -> results_RandomForest_matsnu.gz_23.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_24.csv.gz -> results_RandomForest_matsnu.gz_24.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_25.csv.gz -> results_RandomForest_matsnu.gz_25.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_26.csv.gz -> results_RandomForest_matsnu.gz_26.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_27.csv.gz -> results_RandomForest_matsnu.gz_27.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_28.csv.gz -> results_RandomForest_matsnu.gz_28.csv.gz\n",
            "  ✅ results_RandomForest_matsnu_29.csv.gz -> results_RandomForest_matsnu.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: suppobox -> suppobox.gz\n",
            "Archivos encontrados: 30\n",
            "  ✅ results_RandomForest_suppobox_0.csv.gz -> results_RandomForest_suppobox.gz_0.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_1.csv.gz -> results_RandomForest_suppobox.gz_1.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_2.csv.gz -> results_RandomForest_suppobox.gz_2.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_3.csv.gz -> results_RandomForest_suppobox.gz_3.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_4.csv.gz -> results_RandomForest_suppobox.gz_4.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_5.csv.gz -> results_RandomForest_suppobox.gz_5.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_6.csv.gz -> results_RandomForest_suppobox.gz_6.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_7.csv.gz -> results_RandomForest_suppobox.gz_7.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_8.csv.gz -> results_RandomForest_suppobox.gz_8.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_9.csv.gz -> results_RandomForest_suppobox.gz_9.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_10.csv.gz -> results_RandomForest_suppobox.gz_10.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_11.csv.gz -> results_RandomForest_suppobox.gz_11.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_12.csv.gz -> results_RandomForest_suppobox.gz_12.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_13.csv.gz -> results_RandomForest_suppobox.gz_13.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_14.csv.gz -> results_RandomForest_suppobox.gz_14.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_15.csv.gz -> results_RandomForest_suppobox.gz_15.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_16.csv.gz -> results_RandomForest_suppobox.gz_16.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_17.csv.gz -> results_RandomForest_suppobox.gz_17.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_18.csv.gz -> results_RandomForest_suppobox.gz_18.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_19.csv.gz -> results_RandomForest_suppobox.gz_19.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_20.csv.gz -> results_RandomForest_suppobox.gz_20.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_21.csv.gz -> results_RandomForest_suppobox.gz_21.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_22.csv.gz -> results_RandomForest_suppobox.gz_22.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_23.csv.gz -> results_RandomForest_suppobox.gz_23.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_24.csv.gz -> results_RandomForest_suppobox.gz_24.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_25.csv.gz -> results_RandomForest_suppobox.gz_25.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_26.csv.gz -> results_RandomForest_suppobox.gz_26.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_27.csv.gz -> results_RandomForest_suppobox.gz_27.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_28.csv.gz -> results_RandomForest_suppobox.gz_28.csv.gz\n",
            "  ✅ results_RandomForest_suppobox_29.csv.gz -> results_RandomForest_suppobox.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: charbot -> charbot.gz\n",
            "Archivos encontrados: 30\n",
            "  ✅ results_RandomForest_charbot_0.csv.gz -> results_RandomForest_charbot.gz_0.csv.gz\n",
            "  ✅ results_RandomForest_charbot_1.csv.gz -> results_RandomForest_charbot.gz_1.csv.gz\n",
            "  ✅ results_RandomForest_charbot_2.csv.gz -> results_RandomForest_charbot.gz_2.csv.gz\n",
            "  ✅ results_RandomForest_charbot_3.csv.gz -> results_RandomForest_charbot.gz_3.csv.gz\n",
            "  ✅ results_RandomForest_charbot_4.csv.gz -> results_RandomForest_charbot.gz_4.csv.gz\n",
            "  ✅ results_RandomForest_charbot_5.csv.gz -> results_RandomForest_charbot.gz_5.csv.gz\n",
            "  ✅ results_RandomForest_charbot_6.csv.gz -> results_RandomForest_charbot.gz_6.csv.gz\n",
            "  ✅ results_RandomForest_charbot_7.csv.gz -> results_RandomForest_charbot.gz_7.csv.gz\n",
            "  ✅ results_RandomForest_charbot_8.csv.gz -> results_RandomForest_charbot.gz_8.csv.gz\n",
            "  ✅ results_RandomForest_charbot_9.csv.gz -> results_RandomForest_charbot.gz_9.csv.gz\n",
            "  ✅ results_RandomForest_charbot_10.csv.gz -> results_RandomForest_charbot.gz_10.csv.gz\n",
            "  ✅ results_RandomForest_charbot_11.csv.gz -> results_RandomForest_charbot.gz_11.csv.gz\n",
            "  ✅ results_RandomForest_charbot_12.csv.gz -> results_RandomForest_charbot.gz_12.csv.gz\n",
            "  ✅ results_RandomForest_charbot_13.csv.gz -> results_RandomForest_charbot.gz_13.csv.gz\n",
            "  ✅ results_RandomForest_charbot_14.csv.gz -> results_RandomForest_charbot.gz_14.csv.gz\n",
            "  ✅ results_RandomForest_charbot_15.csv.gz -> results_RandomForest_charbot.gz_15.csv.gz\n",
            "  ✅ results_RandomForest_charbot_16.csv.gz -> results_RandomForest_charbot.gz_16.csv.gz\n",
            "  ✅ results_RandomForest_charbot_17.csv.gz -> results_RandomForest_charbot.gz_17.csv.gz\n",
            "  ✅ results_RandomForest_charbot_18.csv.gz -> results_RandomForest_charbot.gz_18.csv.gz\n",
            "  ✅ results_RandomForest_charbot_19.csv.gz -> results_RandomForest_charbot.gz_19.csv.gz\n",
            "  ✅ results_RandomForest_charbot_20.csv.gz -> results_RandomForest_charbot.gz_20.csv.gz\n",
            "  ✅ results_RandomForest_charbot_21.csv.gz -> results_RandomForest_charbot.gz_21.csv.gz\n",
            "  ✅ results_RandomForest_charbot_22.csv.gz -> results_RandomForest_charbot.gz_22.csv.gz\n",
            "  ✅ results_RandomForest_charbot_23.csv.gz -> results_RandomForest_charbot.gz_23.csv.gz\n",
            "  ✅ results_RandomForest_charbot_24.csv.gz -> results_RandomForest_charbot.gz_24.csv.gz\n",
            "  ✅ results_RandomForest_charbot_25.csv.gz -> results_RandomForest_charbot.gz_25.csv.gz\n",
            "  ✅ results_RandomForest_charbot_26.csv.gz -> results_RandomForest_charbot.gz_26.csv.gz\n",
            "  ✅ results_RandomForest_charbot_27.csv.gz -> results_RandomForest_charbot.gz_27.csv.gz\n",
            "  ✅ results_RandomForest_charbot_28.csv.gz -> results_RandomForest_charbot.gz_28.csv.gz\n",
            "  ✅ results_RandomForest_charbot_29.csv.gz -> results_RandomForest_charbot.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: gozi -> gozi.gz\n",
            "Archivos encontrados: 30\n",
            "  ✅ results_RandomForest_gozi_0.csv.gz -> results_RandomForest_gozi.gz_0.csv.gz\n",
            "  ✅ results_RandomForest_gozi_1.csv.gz -> results_RandomForest_gozi.gz_1.csv.gz\n",
            "  ✅ results_RandomForest_gozi_2.csv.gz -> results_RandomForest_gozi.gz_2.csv.gz\n",
            "  ✅ results_RandomForest_gozi_3.csv.gz -> results_RandomForest_gozi.gz_3.csv.gz\n",
            "  ✅ results_RandomForest_gozi_4.csv.gz -> results_RandomForest_gozi.gz_4.csv.gz\n",
            "  ✅ results_RandomForest_gozi_5.csv.gz -> results_RandomForest_gozi.gz_5.csv.gz\n",
            "  ✅ results_RandomForest_gozi_6.csv.gz -> results_RandomForest_gozi.gz_6.csv.gz\n",
            "  ✅ results_RandomForest_gozi_7.csv.gz -> results_RandomForest_gozi.gz_7.csv.gz\n",
            "  ✅ results_RandomForest_gozi_8.csv.gz -> results_RandomForest_gozi.gz_8.csv.gz\n",
            "  ✅ results_RandomForest_gozi_9.csv.gz -> results_RandomForest_gozi.gz_9.csv.gz\n",
            "  ✅ results_RandomForest_gozi_10.csv.gz -> results_RandomForest_gozi.gz_10.csv.gz\n",
            "  ✅ results_RandomForest_gozi_11.csv.gz -> results_RandomForest_gozi.gz_11.csv.gz\n",
            "  ✅ results_RandomForest_gozi_12.csv.gz -> results_RandomForest_gozi.gz_12.csv.gz\n",
            "  ✅ results_RandomForest_gozi_13.csv.gz -> results_RandomForest_gozi.gz_13.csv.gz\n",
            "  ✅ results_RandomForest_gozi_14.csv.gz -> results_RandomForest_gozi.gz_14.csv.gz\n",
            "  ✅ results_RandomForest_gozi_15.csv.gz -> results_RandomForest_gozi.gz_15.csv.gz\n",
            "  ✅ results_RandomForest_gozi_16.csv.gz -> results_RandomForest_gozi.gz_16.csv.gz\n",
            "  ✅ results_RandomForest_gozi_17.csv.gz -> results_RandomForest_gozi.gz_17.csv.gz\n",
            "  ✅ results_RandomForest_gozi_18.csv.gz -> results_RandomForest_gozi.gz_18.csv.gz\n",
            "  ✅ results_RandomForest_gozi_19.csv.gz -> results_RandomForest_gozi.gz_19.csv.gz\n",
            "  ✅ results_RandomForest_gozi_20.csv.gz -> results_RandomForest_gozi.gz_20.csv.gz\n",
            "  ✅ results_RandomForest_gozi_21.csv.gz -> results_RandomForest_gozi.gz_21.csv.gz\n",
            "  ✅ results_RandomForest_gozi_22.csv.gz -> results_RandomForest_gozi.gz_22.csv.gz\n",
            "  ✅ results_RandomForest_gozi_23.csv.gz -> results_RandomForest_gozi.gz_23.csv.gz\n",
            "  ✅ results_RandomForest_gozi_24.csv.gz -> results_RandomForest_gozi.gz_24.csv.gz\n",
            "  ✅ results_RandomForest_gozi_25.csv.gz -> results_RandomForest_gozi.gz_25.csv.gz\n",
            "  ✅ results_RandomForest_gozi_26.csv.gz -> results_RandomForest_gozi.gz_26.csv.gz\n",
            "  ✅ results_RandomForest_gozi_27.csv.gz -> results_RandomForest_gozi.gz_27.csv.gz\n",
            "  ✅ results_RandomForest_gozi_28.csv.gz -> results_RandomForest_gozi.gz_28.csv.gz\n",
            "  ✅ results_RandomForest_gozi_29.csv.gz -> results_RandomForest_gozi.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: manuelita -> manuelita.gz\n",
            "Archivos encontrados: 30\n",
            "  ✅ results_RandomForest_manuelita_0.csv.gz -> results_RandomForest_manuelita.gz_0.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_1.csv.gz -> results_RandomForest_manuelita.gz_1.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_2.csv.gz -> results_RandomForest_manuelita.gz_2.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_3.csv.gz -> results_RandomForest_manuelita.gz_3.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_4.csv.gz -> results_RandomForest_manuelita.gz_4.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_5.csv.gz -> results_RandomForest_manuelita.gz_5.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_6.csv.gz -> results_RandomForest_manuelita.gz_6.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_7.csv.gz -> results_RandomForest_manuelita.gz_7.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_8.csv.gz -> results_RandomForest_manuelita.gz_8.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_9.csv.gz -> results_RandomForest_manuelita.gz_9.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_10.csv.gz -> results_RandomForest_manuelita.gz_10.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_11.csv.gz -> results_RandomForest_manuelita.gz_11.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_12.csv.gz -> results_RandomForest_manuelita.gz_12.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_13.csv.gz -> results_RandomForest_manuelita.gz_13.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_14.csv.gz -> results_RandomForest_manuelita.gz_14.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_15.csv.gz -> results_RandomForest_manuelita.gz_15.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_16.csv.gz -> results_RandomForest_manuelita.gz_16.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_17.csv.gz -> results_RandomForest_manuelita.gz_17.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_18.csv.gz -> results_RandomForest_manuelita.gz_18.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_19.csv.gz -> results_RandomForest_manuelita.gz_19.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_20.csv.gz -> results_RandomForest_manuelita.gz_20.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_21.csv.gz -> results_RandomForest_manuelita.gz_21.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_22.csv.gz -> results_RandomForest_manuelita.gz_22.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_23.csv.gz -> results_RandomForest_manuelita.gz_23.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_24.csv.gz -> results_RandomForest_manuelita.gz_24.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_25.csv.gz -> results_RandomForest_manuelita.gz_25.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_26.csv.gz -> results_RandomForest_manuelita.gz_26.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_27.csv.gz -> results_RandomForest_manuelita.gz_27.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_28.csv.gz -> results_RandomForest_manuelita.gz_28.csv.gz\n",
            "  ✅ results_RandomForest_manuelita_29.csv.gz -> results_RandomForest_manuelita.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: rovnix -> rovnix.gz\n",
            "Archivos encontrados: 30\n",
            "  ✅ results_RandomForest_rovnix_0.csv.gz -> results_RandomForest_rovnix.gz_0.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_1.csv.gz -> results_RandomForest_rovnix.gz_1.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_2.csv.gz -> results_RandomForest_rovnix.gz_2.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_3.csv.gz -> results_RandomForest_rovnix.gz_3.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_4.csv.gz -> results_RandomForest_rovnix.gz_4.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_5.csv.gz -> results_RandomForest_rovnix.gz_5.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_6.csv.gz -> results_RandomForest_rovnix.gz_6.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_7.csv.gz -> results_RandomForest_rovnix.gz_7.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_8.csv.gz -> results_RandomForest_rovnix.gz_8.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_9.csv.gz -> results_RandomForest_rovnix.gz_9.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_10.csv.gz -> results_RandomForest_rovnix.gz_10.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_11.csv.gz -> results_RandomForest_rovnix.gz_11.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_12.csv.gz -> results_RandomForest_rovnix.gz_12.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_13.csv.gz -> results_RandomForest_rovnix.gz_13.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_14.csv.gz -> results_RandomForest_rovnix.gz_14.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_15.csv.gz -> results_RandomForest_rovnix.gz_15.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_16.csv.gz -> results_RandomForest_rovnix.gz_16.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_17.csv.gz -> results_RandomForest_rovnix.gz_17.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_18.csv.gz -> results_RandomForest_rovnix.gz_18.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_19.csv.gz -> results_RandomForest_rovnix.gz_19.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_20.csv.gz -> results_RandomForest_rovnix.gz_20.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_21.csv.gz -> results_RandomForest_rovnix.gz_21.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_22.csv.gz -> results_RandomForest_rovnix.gz_22.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_23.csv.gz -> results_RandomForest_rovnix.gz_23.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_24.csv.gz -> results_RandomForest_rovnix.gz_24.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_25.csv.gz -> results_RandomForest_rovnix.gz_25.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_26.csv.gz -> results_RandomForest_rovnix.gz_26.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_27.csv.gz -> results_RandomForest_rovnix.gz_27.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_28.csv.gz -> results_RandomForest_rovnix.gz_28.csv.gz\n",
            "  ✅ results_RandomForest_rovnix_29.csv.gz -> results_RandomForest_rovnix.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: deception -> deception.gz\n",
            "Archivos encontrados: 30\n",
            "  ✅ results_RandomForest_deception_0.csv.gz -> results_RandomForest_deception.gz_0.csv.gz\n",
            "  ✅ results_RandomForest_deception_1.csv.gz -> results_RandomForest_deception.gz_1.csv.gz\n",
            "  ✅ results_RandomForest_deception_2.csv.gz -> results_RandomForest_deception.gz_2.csv.gz\n",
            "  ✅ results_RandomForest_deception_3.csv.gz -> results_RandomForest_deception.gz_3.csv.gz\n",
            "  ✅ results_RandomForest_deception_4.csv.gz -> results_RandomForest_deception.gz_4.csv.gz\n",
            "  ✅ results_RandomForest_deception_5.csv.gz -> results_RandomForest_deception.gz_5.csv.gz\n",
            "  ✅ results_RandomForest_deception_6.csv.gz -> results_RandomForest_deception.gz_6.csv.gz\n",
            "  ✅ results_RandomForest_deception_7.csv.gz -> results_RandomForest_deception.gz_7.csv.gz\n",
            "  ✅ results_RandomForest_deception_8.csv.gz -> results_RandomForest_deception.gz_8.csv.gz\n",
            "  ✅ results_RandomForest_deception_9.csv.gz -> results_RandomForest_deception.gz_9.csv.gz\n",
            "  ✅ results_RandomForest_deception_10.csv.gz -> results_RandomForest_deception.gz_10.csv.gz\n",
            "  ✅ results_RandomForest_deception_11.csv.gz -> results_RandomForest_deception.gz_11.csv.gz\n",
            "  ✅ results_RandomForest_deception_12.csv.gz -> results_RandomForest_deception.gz_12.csv.gz\n",
            "  ✅ results_RandomForest_deception_13.csv.gz -> results_RandomForest_deception.gz_13.csv.gz\n",
            "  ✅ results_RandomForest_deception_14.csv.gz -> results_RandomForest_deception.gz_14.csv.gz\n",
            "  ✅ results_RandomForest_deception_15.csv.gz -> results_RandomForest_deception.gz_15.csv.gz\n",
            "  ✅ results_RandomForest_deception_16.csv.gz -> results_RandomForest_deception.gz_16.csv.gz\n",
            "  ✅ results_RandomForest_deception_17.csv.gz -> results_RandomForest_deception.gz_17.csv.gz\n",
            "  ✅ results_RandomForest_deception_18.csv.gz -> results_RandomForest_deception.gz_18.csv.gz\n",
            "  ✅ results_RandomForest_deception_19.csv.gz -> results_RandomForest_deception.gz_19.csv.gz\n",
            "  ✅ results_RandomForest_deception_20.csv.gz -> results_RandomForest_deception.gz_20.csv.gz\n",
            "  ✅ results_RandomForest_deception_21.csv.gz -> results_RandomForest_deception.gz_21.csv.gz\n",
            "  ✅ results_RandomForest_deception_22.csv.gz -> results_RandomForest_deception.gz_22.csv.gz\n",
            "  ✅ results_RandomForest_deception_23.csv.gz -> results_RandomForest_deception.gz_23.csv.gz\n",
            "  ✅ results_RandomForest_deception_24.csv.gz -> results_RandomForest_deception.gz_24.csv.gz\n",
            "  ✅ results_RandomForest_deception_25.csv.gz -> results_RandomForest_deception.gz_25.csv.gz\n",
            "  ✅ results_RandomForest_deception_26.csv.gz -> results_RandomForest_deception.gz_26.csv.gz\n",
            "  ✅ results_RandomForest_deception_27.csv.gz -> results_RandomForest_deception.gz_27.csv.gz\n",
            "  ✅ results_RandomForest_deception_28.csv.gz -> results_RandomForest_deception.gz_28.csv.gz\n",
            "  ✅ results_RandomForest_deception_29.csv.gz -> results_RandomForest_deception.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: nymaim -> nymaim.gz\n",
            "Archivos encontrados: 30\n",
            "  ✅ results_RandomForest_nymaim_0.csv.gz -> results_RandomForest_nymaim.gz_0.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_1.csv.gz -> results_RandomForest_nymaim.gz_1.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_2.csv.gz -> results_RandomForest_nymaim.gz_2.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_3.csv.gz -> results_RandomForest_nymaim.gz_3.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_4.csv.gz -> results_RandomForest_nymaim.gz_4.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_5.csv.gz -> results_RandomForest_nymaim.gz_5.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_6.csv.gz -> results_RandomForest_nymaim.gz_6.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_7.csv.gz -> results_RandomForest_nymaim.gz_7.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_8.csv.gz -> results_RandomForest_nymaim.gz_8.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_9.csv.gz -> results_RandomForest_nymaim.gz_9.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_10.csv.gz -> results_RandomForest_nymaim.gz_10.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_11.csv.gz -> results_RandomForest_nymaim.gz_11.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_12.csv.gz -> results_RandomForest_nymaim.gz_12.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_13.csv.gz -> results_RandomForest_nymaim.gz_13.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_14.csv.gz -> results_RandomForest_nymaim.gz_14.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_15.csv.gz -> results_RandomForest_nymaim.gz_15.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_16.csv.gz -> results_RandomForest_nymaim.gz_16.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_17.csv.gz -> results_RandomForest_nymaim.gz_17.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_18.csv.gz -> results_RandomForest_nymaim.gz_18.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_19.csv.gz -> results_RandomForest_nymaim.gz_19.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_20.csv.gz -> results_RandomForest_nymaim.gz_20.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_21.csv.gz -> results_RandomForest_nymaim.gz_21.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_22.csv.gz -> results_RandomForest_nymaim.gz_22.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_23.csv.gz -> results_RandomForest_nymaim.gz_23.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_24.csv.gz -> results_RandomForest_nymaim.gz_24.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_25.csv.gz -> results_RandomForest_nymaim.gz_25.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_26.csv.gz -> results_RandomForest_nymaim.gz_26.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_27.csv.gz -> results_RandomForest_nymaim.gz_27.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_28.csv.gz -> results_RandomForest_nymaim.gz_28.csv.gz\n",
            "  ✅ results_RandomForest_nymaim_29.csv.gz -> results_RandomForest_nymaim.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: NEW_bigviktor -> bigviktor.gz\n",
            "Archivos encontrados: 30\n",
            "  ✅ results_RandomForest_NEW_bigviktor_0.csv.gz -> results_RandomForest_bigviktor.gz_0.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_1.csv.gz -> results_RandomForest_bigviktor.gz_1.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_2.csv.gz -> results_RandomForest_bigviktor.gz_2.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_3.csv.gz -> results_RandomForest_bigviktor.gz_3.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_4.csv.gz -> results_RandomForest_bigviktor.gz_4.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_5.csv.gz -> results_RandomForest_bigviktor.gz_5.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_6.csv.gz -> results_RandomForest_bigviktor.gz_6.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_7.csv.gz -> results_RandomForest_bigviktor.gz_7.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_8.csv.gz -> results_RandomForest_bigviktor.gz_8.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_9.csv.gz -> results_RandomForest_bigviktor.gz_9.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_10.csv.gz -> results_RandomForest_bigviktor.gz_10.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_11.csv.gz -> results_RandomForest_bigviktor.gz_11.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_12.csv.gz -> results_RandomForest_bigviktor.gz_12.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_13.csv.gz -> results_RandomForest_bigviktor.gz_13.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_14.csv.gz -> results_RandomForest_bigviktor.gz_14.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_15.csv.gz -> results_RandomForest_bigviktor.gz_15.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_16.csv.gz -> results_RandomForest_bigviktor.gz_16.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_17.csv.gz -> results_RandomForest_bigviktor.gz_17.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_18.csv.gz -> results_RandomForest_bigviktor.gz_18.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_19.csv.gz -> results_RandomForest_bigviktor.gz_19.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_20.csv.gz -> results_RandomForest_bigviktor.gz_20.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_21.csv.gz -> results_RandomForest_bigviktor.gz_21.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_22.csv.gz -> results_RandomForest_bigviktor.gz_22.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_23.csv.gz -> results_RandomForest_bigviktor.gz_23.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_24.csv.gz -> results_RandomForest_bigviktor.gz_24.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_25.csv.gz -> results_RandomForest_bigviktor.gz_25.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_26.csv.gz -> results_RandomForest_bigviktor.gz_26.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_27.csv.gz -> results_RandomForest_bigviktor.gz_27.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_28.csv.gz -> results_RandomForest_bigviktor.gz_28.csv.gz\n",
            "  ✅ results_RandomForest_NEW_bigviktor_29.csv.gz -> results_RandomForest_bigviktor.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: NEW_pizd -> pizd.gz\n",
            "Archivos encontrados: 30\n",
            "  ✅ results_RandomForest_NEW_pizd_0.csv.gz -> results_RandomForest_pizd.gz_0.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_1.csv.gz -> results_RandomForest_pizd.gz_1.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_2.csv.gz -> results_RandomForest_pizd.gz_2.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_3.csv.gz -> results_RandomForest_pizd.gz_3.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_4.csv.gz -> results_RandomForest_pizd.gz_4.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_5.csv.gz -> results_RandomForest_pizd.gz_5.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_6.csv.gz -> results_RandomForest_pizd.gz_6.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_7.csv.gz -> results_RandomForest_pizd.gz_7.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_8.csv.gz -> results_RandomForest_pizd.gz_8.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_9.csv.gz -> results_RandomForest_pizd.gz_9.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_10.csv.gz -> results_RandomForest_pizd.gz_10.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_11.csv.gz -> results_RandomForest_pizd.gz_11.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_12.csv.gz -> results_RandomForest_pizd.gz_12.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_13.csv.gz -> results_RandomForest_pizd.gz_13.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_14.csv.gz -> results_RandomForest_pizd.gz_14.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_15.csv.gz -> results_RandomForest_pizd.gz_15.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_16.csv.gz -> results_RandomForest_pizd.gz_16.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_17.csv.gz -> results_RandomForest_pizd.gz_17.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_18.csv.gz -> results_RandomForest_pizd.gz_18.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_19.csv.gz -> results_RandomForest_pizd.gz_19.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_20.csv.gz -> results_RandomForest_pizd.gz_20.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_21.csv.gz -> results_RandomForest_pizd.gz_21.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_22.csv.gz -> results_RandomForest_pizd.gz_22.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_23.csv.gz -> results_RandomForest_pizd.gz_23.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_24.csv.gz -> results_RandomForest_pizd.gz_24.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_25.csv.gz -> results_RandomForest_pizd.gz_25.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_26.csv.gz -> results_RandomForest_pizd.gz_26.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_27.csv.gz -> results_RandomForest_pizd.gz_27.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_28.csv.gz -> results_RandomForest_pizd.gz_28.csv.gz\n",
            "  ✅ results_RandomForest_NEW_pizd_29.csv.gz -> results_RandomForest_pizd.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: NEW_ngioweb -> ngioweb.gz\n",
            "Archivos encontrados: 30\n",
            "  ✅ results_RandomForest_NEW_ngioweb_0.csv.gz -> results_RandomForest_ngioweb.gz_0.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_1.csv.gz -> results_RandomForest_ngioweb.gz_1.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_2.csv.gz -> results_RandomForest_ngioweb.gz_2.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_3.csv.gz -> results_RandomForest_ngioweb.gz_3.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_4.csv.gz -> results_RandomForest_ngioweb.gz_4.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_5.csv.gz -> results_RandomForest_ngioweb.gz_5.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_6.csv.gz -> results_RandomForest_ngioweb.gz_6.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_7.csv.gz -> results_RandomForest_ngioweb.gz_7.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_8.csv.gz -> results_RandomForest_ngioweb.gz_8.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_9.csv.gz -> results_RandomForest_ngioweb.gz_9.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_10.csv.gz -> results_RandomForest_ngioweb.gz_10.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_11.csv.gz -> results_RandomForest_ngioweb.gz_11.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_12.csv.gz -> results_RandomForest_ngioweb.gz_12.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_13.csv.gz -> results_RandomForest_ngioweb.gz_13.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_14.csv.gz -> results_RandomForest_ngioweb.gz_14.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_15.csv.gz -> results_RandomForest_ngioweb.gz_15.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_16.csv.gz -> results_RandomForest_ngioweb.gz_16.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_17.csv.gz -> results_RandomForest_ngioweb.gz_17.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_18.csv.gz -> results_RandomForest_ngioweb.gz_18.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_19.csv.gz -> results_RandomForest_ngioweb.gz_19.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_20.csv.gz -> results_RandomForest_ngioweb.gz_20.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_21.csv.gz -> results_RandomForest_ngioweb.gz_21.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_22.csv.gz -> results_RandomForest_ngioweb.gz_22.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_23.csv.gz -> results_RandomForest_ngioweb.gz_23.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_24.csv.gz -> results_RandomForest_ngioweb.gz_24.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_25.csv.gz -> results_RandomForest_ngioweb.gz_25.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_26.csv.gz -> results_RandomForest_ngioweb.gz_26.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_27.csv.gz -> results_RandomForest_ngioweb.gz_27.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_28.csv.gz -> results_RandomForest_ngioweb.gz_28.csv.gz\n",
            "  ✅ results_RandomForest_NEW_ngioweb_29.csv.gz -> results_RandomForest_ngioweb.gz_29.csv.gz\n",
            "\n",
            "==================================================\n",
            "RESUMEN FINAL:\n",
            "Archivos renombrados exitosamente: 330\n",
            "Familias sin archivos encontrados: 0\n",
            "Proceso completado.\n"
          ]
        }
      ]
    }
  ]
}