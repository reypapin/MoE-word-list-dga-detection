{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive  # Importing the library to mount Google Drive\n",
        "drive.mount('/content/drive')  # Mounting Google Drive in Colab environment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71FJxLKc1343",
        "outputId": "9979fce3-6ff2-4360-9d9f-841c4188861d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pandas numpy scikit-learn nltk"
      ],
      "metadata": {
        "id": "6_awAc1Nf_yt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXAm488r1DJw",
        "outputId": "5cea6bbe-0086-44f9-c62d-c36b1d6c56e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       domain    family   label\n",
            "0         nailconsiderable.ru  suppobox     dga\n",
            "1            stilldelight.net  suppobox     dga\n",
            "2       kimberleekatheryn.net  suppobox     dga\n",
            "3                soilbeen.net  suppobox     dga\n",
            "4               visitform.net  suppobox     dga\n",
            "...                       ...       ...     ...\n",
            "159995             dhuhaa.com     legit  notdga\n",
            "159996        sdmetalcrew.org     legit  notdga\n",
            "159997  melbcampcontuligol.ga     legit  notdga\n",
            "159998      pl-enthusiast.net     legit  notdga\n",
            "159999            rd-forum.ru     legit  notdga\n",
            "\n",
            "[160000 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# File paths\n",
        "train_df_file = \"/content/drive/My Drive/MOE_DGA/train_wl.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_df_file)\n",
        "\n",
        "#train_df = train_df.rename(columns={\"label\": \"Label\"})\n",
        "\n",
        "\n",
        "print(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import nltk\n",
        "from nltk.corpus import words, wordnet\n",
        "from collections import defaultdict\n",
        "\n",
        "# Descargar recursos de NLTK si no est√°n disponibles\n",
        "try:\n",
        "    nltk.data.find('corpora/words')\n",
        "except LookupError:\n",
        "    nltk.download('words')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "# Construir diccionarios m√°s completos\n",
        "def build_comprehensive_dictionaries():\n",
        "    \"\"\"\n",
        "    Construye diccionarios m√°s completos basados en NLTK y listas comunes\n",
        "    \"\"\"\n",
        "    # Diccionario ingl√©s completo (equivalente a los 58k palabras mencionadas)\n",
        "    english_words = set(words.words())\n",
        "    english_dict = {word.lower() for word in english_words if len(word) >= 2}\n",
        "\n",
        "    # Palabras comunes m√°s frecuentes para sustantivos, verbos y adjetivos\n",
        "    common_nouns = {\n",
        "        \"time\", \"year\", \"people\", \"way\", \"day\", \"man\", \"thing\", \"woman\", \"life\",\n",
        "        \"child\", \"world\", \"school\", \"state\", \"family\", \"student\", \"group\", \"country\",\n",
        "        \"problem\", \"hand\", \"part\", \"place\", \"case\", \"week\", \"company\", \"system\",\n",
        "        \"program\", \"question\", \"work\", \"government\", \"number\", \"night\", \"point\",\n",
        "        \"home\", \"water\", \"room\", \"mother\", \"area\", \"money\", \"story\", \"fact\",\n",
        "        \"month\", \"lot\", \"right\", \"study\", \"book\", \"eye\", \"job\", \"word\", \"business\",\n",
        "        \"issue\", \"side\", \"kind\", \"head\", \"house\", \"service\", \"friend\", \"father\",\n",
        "        \"power\", \"hour\", \"game\", \"line\", \"end\", \"member\", \"law\", \"car\", \"city\",\n",
        "        \"community\", \"name\", \"president\", \"team\", \"minute\", \"idea\", \"kid\", \"body\",\n",
        "        \"information\", \"back\", \"parent\", \"face\", \"others\", \"level\", \"office\",\n",
        "        \"door\", \"health\", \"person\", \"art\", \"war\", \"history\", \"party\", \"result\",\n",
        "        \"change\", \"morning\", \"reason\", \"research\", \"girl\", \"guy\", \"moment\", \"air\",\n",
        "        \"teacher\", \"force\", \"education\"\n",
        "    }\n",
        "\n",
        "    common_verbs = {\n",
        "        \"be\", \"have\", \"do\", \"say\", \"get\", \"make\", \"go\", \"know\", \"take\", \"see\",\n",
        "        \"come\", \"think\", \"look\", \"want\", \"give\", \"use\", \"find\", \"tell\", \"ask\",\n",
        "        \"work\", \"seem\", \"feel\", \"try\", \"leave\", \"call\", \"need\", \"move\", \"would\",\n",
        "        \"could\", \"should\", \"might\", \"will\", \"can\", \"must\", \"shall\", \"may\",\n",
        "        \"put\", \"mean\", \"keep\", \"let\", \"begin\", \"seem\", \"help\", \"talk\", \"turn\",\n",
        "        \"start\", \"show\", \"hear\", \"play\", \"run\", \"move\", \"like\", \"live\", \"believe\",\n",
        "        \"hold\", \"bring\", \"happen\", \"write\", \"provide\", \"sit\", \"stand\", \"lose\",\n",
        "        \"pay\", \"meet\", \"include\", \"continue\", \"set\", \"learn\", \"change\", \"lead\",\n",
        "        \"understand\", \"watch\", \"follow\", \"stop\", \"create\", \"speak\", \"read\",\n",
        "        \"allow\", \"add\", \"spend\", \"grow\", \"open\", \"walk\", \"win\", \"offer\",\n",
        "        \"remember\", \"love\", \"consider\", \"appear\", \"buy\", \"wait\", \"serve\",\n",
        "        \"die\", \"send\", \"expect\", \"build\", \"stay\", \"fall\", \"cut\", \"reach\", \"kill\",\n",
        "        \"remain\", \"suggest\", \"raise\", \"pass\", \"sell\", \"require\", \"report\"\n",
        "    }\n",
        "\n",
        "    common_adjectives = {\n",
        "        \"good\", \"new\", \"first\", \"last\", \"long\", \"great\", \"little\", \"own\", \"other\",\n",
        "        \"old\", \"right\", \"big\", \"high\", \"different\", \"small\", \"large\", \"next\",\n",
        "        \"early\", \"young\", \"important\", \"few\", \"public\", \"bad\", \"same\", \"able\",\n",
        "        \"local\", \"sure\", \"united\", \"real\", \"best\", \"better\", \"less\", \"far\",\n",
        "        \"much\", \"water\", \"very\", \"social\", \"only\", \"national\", \"political\",\n",
        "        \"special\", \"hard\", \"international\", \"health\", \"human\", \"common\", \"short\",\n",
        "        \"general\", \"strong\", \"particular\", \"community\", \"whole\", \"private\",\n",
        "        \"recent\", \"available\", \"major\", \"personal\", \"current\", \"left\", \"least\",\n",
        "        \"possible\", \"business\", \"economic\", \"white\", \"late\", \"difficult\", \"red\",\n",
        "        \"close\", \"fine\", \"higher\", \"western\", \"financial\", \"certain\", \"free\",\n",
        "        \"military\", \"original\", \"successful\", \"low\", \"activity\", \"critical\",\n",
        "        \"environmental\", \"global\", \"eastern\", \"hard\", \"popular\", \"traditional\",\n",
        "        \"main\", \"simple\", \"physical\", \"medical\", \"full\", \"federal\", \"blue\",\n",
        "        \"democratic\", \"dark\", \"various\", \"entire\", \"close\", \"legal\", \"religious\",\n",
        "        \"cold\", \"final\", \"main\", \"green\", \"nice\", \"huge\", \"popular\", \"serious\",\n",
        "        \"ready\", \"easy\", \"official\", \"foreign\", \"fine\", \"civil\", \"lower\"\n",
        "    }\n",
        "\n",
        "    return english_dict, common_nouns, common_verbs, common_adjectives\n",
        "\n",
        "# Construir diccionarios DGA y privados desde dominios DGA\n",
        "def build_dga_dicts(df, english_dict):\n",
        "    \"\"\"\n",
        "    Construye diccionarios DGA y privados a partir de los dominios DGA del dataset\n",
        "    \"\"\"\n",
        "    if 'label' not in df.columns or 'domain' not in df.columns:\n",
        "        raise ValueError(\"DataFrame debe tener columnas 'label' y 'domain'\")\n",
        "\n",
        "    dga_domains = df[df['label'] == 'dga']['domain']\n",
        "    dga_words = set()\n",
        "    private_words = set()\n",
        "\n",
        "    for domain in dga_domains:\n",
        "        # Separar por puntos y guiones\n",
        "        parts = re.split(r'[-.]', domain.lower())\n",
        "        for word in parts:\n",
        "            if word and len(word) >= 2:  # Ignorar partes muy cortas\n",
        "                dga_words.add(word)\n",
        "                # Si la palabra no est√° en el diccionario ingl√©s, es \"privada\"\n",
        "                if word not in english_dict:\n",
        "                    private_words.add(word)\n",
        "\n",
        "    return dga_words, private_words\n",
        "\n",
        "# Extraer caracter√≠sticas mejoradas del dominio\n",
        "def extract_features(domain, dga_dict, private_dict, english_dict, noun_dict, verb_dict, adj_dict):\n",
        "    \"\"\"\n",
        "    Extrae las 16 caracter√≠sticas mencionadas en el paper\n",
        "    \"\"\"\n",
        "    domain = domain.lower()\n",
        "    vowels = \"aeiou\"\n",
        "    digits_and_dash = string.digits + \"-\"\n",
        "\n",
        "    # f1: Longitud del dominio\n",
        "    domain_len = len(domain)\n",
        "\n",
        "    # f2: Suma ASCII de todos los caracteres\n",
        "    ascii_sum = sum(ord(c) for c in domain)\n",
        "\n",
        "    # f3: N√∫mero de vocales\n",
        "    vowel_count = sum(1 for c in domain if c in vowels)\n",
        "\n",
        "    # f4: Distribuci√≥n de vocales\n",
        "    vowel_dist = vowel_count / domain_len if domain_len > 0 else 0\n",
        "\n",
        "    # f5: N√∫mero de d√≠gitos y guiones\n",
        "    digit_dash_count = sum(1 for c in domain if c in digits_and_dash)\n",
        "\n",
        "    # f6: Distribuci√≥n de d√≠gitos y guiones\n",
        "    digit_dash_dist = digit_dash_count / domain_len if domain_len > 0 else 0\n",
        "\n",
        "    # Extraer palabras del dominio (separadas por . y -)\n",
        "    parts = re.split(r'[-.]', domain)\n",
        "    words = [w for w in parts if w and len(w) >= 2]\n",
        "\n",
        "    # f7: Palabras en diccionario ingl√©s\n",
        "    word_norm = sum(1 for w in words if w in english_dict)\n",
        "\n",
        "    # f8: Palabras en diccionario DGA\n",
        "    word_dga = sum(1 for w in words if w in dga_dict)\n",
        "\n",
        "    # f9: Sustantivos\n",
        "    noun_count = sum(1 for w in words if w in noun_dict)\n",
        "\n",
        "    # f10: Verbos\n",
        "    verb_count = sum(1 for w in words if w in verb_dict)\n",
        "\n",
        "    # f11: Adjetivos\n",
        "    adj_count = sum(1 for w in words if w in adj_dict)\n",
        "\n",
        "    # f12: Palabras privadas (DGA que no est√°n en ingl√©s)\n",
        "    private_count = sum(1 for w in words if w in private_dict)\n",
        "\n",
        "    # f13: Ratio entre palabras DGA y palabras normales\n",
        "    ratio_dga_norm = word_dga / word_norm if word_norm > 0 else (word_dga if word_dga > 0 else 0)\n",
        "\n",
        "    # f14: Longitud de la palabra m√°s larga\n",
        "    word_lengths = [len(w) for w in words]\n",
        "    max_len_word = max(word_lengths) if word_lengths else 0\n",
        "\n",
        "    # f15: Longitud de la palabra m√°s corta\n",
        "    min_len_word = min(word_lengths) if word_lengths else 0\n",
        "\n",
        "    # f16: Ratio entre caracteres de palabras y longitud total\n",
        "    total_word_chars = sum(word_lengths)\n",
        "    word_char_ratio = total_word_chars / domain_len if domain_len > 0 else 0\n",
        "\n",
        "    return [\n",
        "        domain_len, ascii_sum, vowel_count, vowel_dist,\n",
        "        digit_dash_count, digit_dash_dist, word_norm, word_dga,\n",
        "        noun_count, verb_count, adj_count, private_count,\n",
        "        ratio_dga_norm, max_len_word, min_len_word, word_char_ratio\n",
        "    ]\n",
        "\n",
        "def train_dga_classifier(df, test_size=0.01, random_state=42):\n",
        "    \"\"\"\n",
        "    Funci√≥n principal para entrenar el clasificador DGA\n",
        "    \"\"\"\n",
        "    print(\"Construyendo diccionarios...\")\n",
        "    english_dict, noun_dict, verb_dict, adj_dict = build_comprehensive_dictionaries()\n",
        "\n",
        "    print(f\"Diccionario ingl√©s: {len(english_dict)} palabras\")\n",
        "    print(f\"Sustantivos: {len(noun_dict)} palabras\")\n",
        "    print(f\"Verbos: {len(verb_dict)} palabras\")\n",
        "    print(f\"Adjetivos: {len(adj_dict)} palabras\")\n",
        "\n",
        "    print(\"Construyendo diccionarios DGA...\")\n",
        "    dga_dict, private_dict = build_dga_dicts(df, english_dict)\n",
        "\n",
        "    print(f\"Palabras DGA: {len(dga_dict)}\")\n",
        "    print(f\"Palabras privadas: {len(private_dict)}\")\n",
        "\n",
        "    print(\"Extrayendo caracter√≠sticas...\")\n",
        "    # Extraer caracter√≠sticas\n",
        "    features = df['domain'].apply(\n",
        "        lambda d: extract_features(d, dga_dict, private_dict, english_dict,\n",
        "                                 noun_dict, verb_dict, adj_dict)\n",
        "    )\n",
        "\n",
        "    X = np.array(features.tolist())\n",
        "    y = df['label'].map({'notdga': 0, 'dga': 1}).values\n",
        "\n",
        "    print(f\"Forma de X: {X.shape}\")\n",
        "    print(f\"Distribuci√≥n de clases: {np.bincount(y)}\")\n",
        "\n",
        "    # Divisi√≥n train/test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "    )\n",
        "\n",
        "    print(\"Entrenando modelo Random Forest...\")\n",
        "    # Entrenar modelo Random Forest (como en el paper)\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,  # Aumentado para mejor rendimiento\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=random_state,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predicci√≥n y evaluaci√≥n\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "    print(\"\\nReporte de clasificaci√≥n:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=[\"notdga\", \"dga\"]))\n",
        "\n",
        "    print(\"\\nMatriz de confusi√≥n:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # Importancia de caracter√≠sticas\n",
        "    feature_names = [\n",
        "        'domain_len', 'ascii_sum', 'vowel_count', 'vowel_dist',\n",
        "        'digit_dash_count', 'digit_dash_dist', 'word_norm', 'word_dga',\n",
        "        'noun_count', 'verb_count', 'adj_count', 'private_count',\n",
        "        'ratio_dga_norm', 'max_len_word', 'min_len_word', 'word_char_ratio'\n",
        "    ]\n",
        "\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    print(\"\\nImportancia de caracter√≠sticas:\")\n",
        "    print(feature_importance)\n",
        "\n",
        "    return model, (dga_dict, private_dict, english_dict, noun_dict, verb_dict, adj_dict)\n",
        "\n",
        "# Funci√≥n para clasificar nuevos dominios\n",
        "def classify_domain(domain, model, dictionaries):\n",
        "    \"\"\"\n",
        "    Clasifica un dominio individual\n",
        "    \"\"\"\n",
        "    dga_dict, private_dict, english_dict, noun_dict, verb_dict, adj_dict = dictionaries\n",
        "\n",
        "    features = extract_features(domain, dga_dict, private_dict, english_dict,\n",
        "                              noun_dict, verb_dict, adj_dict)\n",
        "    features_array = np.array([features])\n",
        "\n",
        "    prediction = model.predict(features_array)[0]\n",
        "    probability = model.predict_proba(features_array)[0]\n",
        "\n",
        "    return {\n",
        "        'domain': domain,\n",
        "        'prediction': 'dga' if prediction == 1 else 'notdga',\n",
        "        'dga_probability': probability[1],\n",
        "        'notdga_probability': probability[0]\n",
        "    }\n",
        "\n",
        "# === EJEMPLO DE USO ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Ejemplo de c√≥mo usar el c√≥digo\n",
        "    # Asume que tienes un DataFrame 'df' con columnas 'domain' y 'label'\n",
        "\n",
        "    # Crear datos de ejemplo si no tienes un dataset\n",
        "    sample_data = {\n",
        "        'domain': [\n",
        "            'google.com', 'facebook.com', 'microsoft.com', 'amazon.com',\n",
        "            'xkvbpqr.com', 'mnbvcxz.net', 'qwertyuiop.org', 'asdfghjkl.info',\n",
        "            'randomstring123.com', 'anotherfakedom.net'\n",
        "        ],\n",
        "        'label': [\n",
        "            'notdga', 'notdga', 'notdga', 'notdga',\n",
        "            'dga', 'dga', 'dga', 'dga', 'dga', 'dga'\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    df_example = pd.DataFrame(sample_data)\n",
        "\n",
        "    print(\"Ejemplo con datos sint√©ticos:\")\n",
        "    print(\"Para usar con tus datos reales, carga tu DataFrame con columnas 'domain' y 'label'\")\n",
        "    print(\"Donde 'label' contiene 'dga' o 'notdga'\")\n",
        "\n",
        "    model, dictionaries = train_dga_classifier(train_df)\n",
        "\n",
        "    # Ejemplo de clasificaci√≥n de un dominio individual\n",
        "    # result = classify_domain('suspicious-domain.com', model, dictionaries)\n",
        "    # print(f\"\\nResultado para 'suspicious-domain.com': {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0DoyDMKf-cg",
        "outputId": "7af1ea70-c625-4236-fc97-1d6167371d8e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo con datos sint√©ticos:\n",
            "Para usar con tus datos reales, carga tu DataFrame con columnas 'domain' y 'label'\n",
            "Donde 'label' contiene 'dga' o 'notdga'\n",
            "Construyendo diccionarios...\n",
            "Diccionario ingl√©s: 234351 palabras\n",
            "Sustantivos: 100 palabras\n",
            "Verbos: 106 palabras\n",
            "Adjetivos: 110 palabras\n",
            "Construyendo diccionarios DGA...\n",
            "Palabras DGA: 77834\n",
            "Palabras privadas: 74121\n",
            "Extrayendo caracter√≠sticas...\n",
            "Forma de X: (160000, 16)\n",
            "Distribuci√≥n de clases: [80000 80000]\n",
            "Entrenando modelo Random Forest...\n",
            "\n",
            "Accuracy: 0.9900\n",
            "\n",
            "Reporte de clasificaci√≥n:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      notdga       0.99      0.99      0.99       800\n",
            "         dga       0.99      0.99      0.99       800\n",
            "\n",
            "    accuracy                           0.99      1600\n",
            "   macro avg       0.99      0.99      0.99      1600\n",
            "weighted avg       0.99      0.99      0.99      1600\n",
            "\n",
            "\n",
            "Matriz de confusi√≥n:\n",
            "[[790  10]\n",
            " [  6 794]]\n",
            "\n",
            "Importancia de caracter√≠sticas:\n",
            "             feature  importance\n",
            "12    ratio_dga_norm    0.293593\n",
            "7           word_dga    0.216847\n",
            "15   word_char_ratio    0.192850\n",
            "14      min_len_word    0.096504\n",
            "11     private_count    0.069625\n",
            "13      max_len_word    0.031296\n",
            "0         domain_len    0.026095\n",
            "6          word_norm    0.026045\n",
            "1          ascii_sum    0.021799\n",
            "5    digit_dash_dist    0.009823\n",
            "4   digit_dash_count    0.007024\n",
            "2        vowel_count    0.004815\n",
            "3         vowel_dist    0.003124\n",
            "8         noun_count    0.000232\n",
            "10         adj_count    0.000166\n",
            "9         verb_count    0.000162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = classify_domain('suspicious-domain.com', model, dictionaries)\n",
        "print(f\"\\nResultado para 'suspicious-domain.com': {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRARV6zHgG8p",
        "outputId": "9df6e5ce-b727-4f03-eb6a-d929f93d1c3d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resultado para 'suspicious-domain.com': {'domain': 'suspicious-domain.com', 'prediction': 'notdga', 'dga_probability': np.float64(0.019480393789305103), 'notdga_probability': np.float64(0.980519606210695)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['prediction']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wXTk9mqvgG_2",
        "outputId": "b34c6a2b-9a48-4d15-ec59-b00632a961b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'notdga'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "import gzip\n",
        "\n",
        "# Importar las funciones del modelo DGA que creamos anteriormente\n",
        "# (Asume que ya tienes entrenado el modelo y las funciones disponibles)\n",
        "\n",
        "def classify_domains_batch(domains, model, dictionaries):\n",
        "    \"\"\"\n",
        "    Clasifica m√∫ltiples dominios y mide el tiempo de procesamiento\n",
        "\n",
        "    Args:\n",
        "        domains: Lista o array de dominios\n",
        "        model: Modelo entrenado\n",
        "        dictionaries: Tupla con los diccionarios necesarios\n",
        "\n",
        "    Returns:\n",
        "        dict con predicciones, probabilidades y tiempos\n",
        "    \"\"\"\n",
        "    dga_dict, private_dict, english_dict, noun_dict, verb_dict, adj_dict = dictionaries\n",
        "\n",
        "    predictions = []\n",
        "    probabilities_dga = []\n",
        "    probabilities_notdga = []\n",
        "    processing_times = []\n",
        "\n",
        "    for domain in domains:\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Extraer caracter√≠sticas\n",
        "        features = extract_features(domain, dga_dict, private_dict, english_dict,\n",
        "                                  noun_dict, verb_dict, adj_dict)\n",
        "        features_array = np.array([features])\n",
        "\n",
        "        # Hacer predicci√≥n\n",
        "        prediction = model.predict(features_array)[0]\n",
        "        probability = model.predict_proba(features_array)[0]\n",
        "\n",
        "        end_time = time.time()\n",
        "        query_time = end_time - start_time\n",
        "\n",
        "        predictions.append('dga' if prediction == 1 else 'notdga')\n",
        "        probabilities_dga.append(probability[1])\n",
        "        probabilities_notdga.append(probability[0])\n",
        "        processing_times.append(query_time)\n",
        "\n",
        "    return {\n",
        "        'predictions': predictions,\n",
        "        'probabilities_dga': probabilities_dga,\n",
        "        'probabilities_notdga': probabilities_notdga,\n",
        "        'processing_times': processing_times\n",
        "    }\n",
        "\n",
        "def evaluate_dga_families(model, dictionaries, base_path='/content/drive/My Drive/Familias_Test/',\n",
        "                         results_path='/content/drive/My Drive/results/', runs=30, chunk_size=50):\n",
        "    \"\"\"\n",
        "    Eval√∫a el modelo DGA con diferentes familias de malware\n",
        "\n",
        "    Args:\n",
        "        model: Modelo entrenado\n",
        "        dictionaries: Diccionarios del modelo\n",
        "        base_path: Ruta base donde est√°n los archivos de familias\n",
        "        results_path: Ruta donde guardar los resultados\n",
        "        runs: N√∫mero de ejecuciones por familia\n",
        "        chunk_size: Tama√±o del chunk para procesar\n",
        "    \"\"\"\n",
        "\n",
        "    families = [\n",
        "        'matsnu.gz',\n",
        "        'suppobox.gz',\n",
        "        'charbot.gz',\n",
        "        'gozi.gz',\n",
        "        'manuelita.gz',\n",
        "        'rovnix.gz',\n",
        "        'deception.gz',\n",
        "        'nymaim.gz'\n",
        "    ]\n",
        "\n",
        "    # Crear directorio de resultados si no existe\n",
        "    Path(results_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Verificar que el archivo legit existe\n",
        "    legit_file = os.path.join(base_path, 'legit.gz')\n",
        "    if not os.path.exists(legit_file):\n",
        "        raise FileNotFoundError(f\"Archivo legit no encontrado: {legit_file}\")\n",
        "\n",
        "    # Procesar cada familia\n",
        "    for family in families:\n",
        "        print(f\"üîç Procesando familia: {family}\")\n",
        "\n",
        "        family_file = os.path.join(base_path, family)\n",
        "        if not os.path.exists(family_file):\n",
        "            print(f\"‚ùå Archivo no encontrado: {family_file}\")\n",
        "            continue\n",
        "\n",
        "        # Estad√≠sticas para la familia\n",
        "        family_stats = {\n",
        "            'total_domains': 0,\n",
        "            'total_time': 0,\n",
        "            'avg_time_per_domain': 0,\n",
        "            'runs_completed': 0\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Crear lectores de chunks\n",
        "            dga_reader = pd.read_csv(family_file, chunksize=chunk_size)\n",
        "\n",
        "            for run in range(runs):\n",
        "                print(f\" ‚ñ∂Ô∏è Run {run+1}/{runs}\", end=\"\\r\")\n",
        "\n",
        "                try:\n",
        "                    # Leer chunks\n",
        "                    dga_chunk = next(dga_reader)\n",
        "\n",
        "                    # Reiniciar el lector de legit para cada run\n",
        "                    legit_reader = pd.read_csv(legit_file, chunksize=chunk_size)\n",
        "                    legit_chunk = next(legit_reader)\n",
        "\n",
        "                    # Combinar chunks\n",
        "                    df_chunk = pd.concat([dga_chunk, legit_chunk]).reset_index(drop=True)\n",
        "\n",
        "                    # Asegurar que la columna domain existe\n",
        "                    if 'domain' not in df_chunk.columns:\n",
        "                        # Si no existe, asumir que la primera columna son los dominios\n",
        "                        df_chunk.columns = ['domain'] + list(df_chunk.columns[1:])\n",
        "\n",
        "                    # Crear etiquetas si no existen\n",
        "                    if 'label' not in df_chunk.columns:\n",
        "                        # Primeros len(dga_chunk) son DGA, el resto son legit\n",
        "                        labels = ['dga'] * len(dga_chunk) + ['notdga'] * len(legit_chunk)\n",
        "                        df_chunk['label'] = labels\n",
        "\n",
        "                    # Medir tiempo total para el batch\n",
        "                    batch_start_time = time.time()\n",
        "\n",
        "                    # Obtener predicciones y tiempos individuales\n",
        "                    results = classify_domains_batch(df_chunk[\"domain\"].values, model, dictionaries)\n",
        "\n",
        "                    batch_end_time = time.time()\n",
        "                    batch_total_time = batch_end_time - batch_start_time\n",
        "\n",
        "                    # Agregar resultados al DataFrame\n",
        "                    df_chunk[\"pred\"] = results['predictions']\n",
        "                    df_chunk[\"prob_dga\"] = results['probabilities_dga']\n",
        "                    df_chunk[\"prob_notdga\"] = results['probabilities_notdga']\n",
        "                    df_chunk[\"query_time\"] = results['processing_times']\n",
        "                    df_chunk[\"batch_time\"] = batch_total_time\n",
        "                    df_chunk[\"run\"] = run\n",
        "\n",
        "                    # Calcular m√©tricas adicionales\n",
        "                    df_chunk[\"correct\"] = (df_chunk[\"label\"] == df_chunk[\"pred\"]).astype(int)\n",
        "\n",
        "                    # Actualizar estad√≠sticas\n",
        "                    family_stats['total_domains'] += len(df_chunk)\n",
        "                    family_stats['total_time'] += batch_total_time\n",
        "                    family_stats['runs_completed'] += 1\n",
        "\n",
        "                    # Guardar resultados\n",
        "                    output_file = os.path.join(\n",
        "                        results_path,\n",
        "                        f\"results_RandomForest_{family.replace('.gz', '')}_{run}.csv.gz\"\n",
        "                    )\n",
        "\n",
        "                    df_chunk.to_csv(\n",
        "                        output_file,\n",
        "                        index=False,\n",
        "                        compression=\"gzip\"\n",
        "                    )\n",
        "\n",
        "                except StopIteration:\n",
        "                    print(f\"\\n‚ö†Ô∏è No hay m√°s datos disponibles para {family} en run {run+1}\")\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    print(f\"\\n‚ùå Error en run {run+1} para {family}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            # Calcular estad√≠sticas finales para la familia\n",
        "            if family_stats['runs_completed'] > 0:\n",
        "                family_stats['avg_time_per_domain'] = family_stats['total_time'] / family_stats['total_domains']\n",
        "\n",
        "                print(f\"\\n‚úÖ {family} completado:\")\n",
        "                print(f\"   Runs completados: {family_stats['runs_completed']}/{runs}\")\n",
        "                print(f\"   Total dominios procesados: {family_stats['total_domains']}\")\n",
        "                print(f\"   Tiempo total: {family_stats['total_time']:.4f}s\")\n",
        "                print(f\"   Tiempo promedio por dominio: {family_stats['avg_time_per_domain']:.6f}s\")\n",
        "                print(f\"   Dominios por segundo: {family_stats['total_domains']/family_stats['total_time']:.2f}\")\n",
        "\n",
        "                # Guardar estad√≠sticas de la familia\n",
        "                stats_df = pd.DataFrame([family_stats])\n",
        "                stats_df['family'] = family\n",
        "                stats_file = os.path.join(results_path, f\"stats_{family.replace('.gz', '')}.csv\")\n",
        "                stats_df.to_csv(stats_file, index=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Error procesando familia {family}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n\" + \"=\"*50)\n",
        "\n",
        "def analyze_results(results_path='/content/drive/My Drive/results/'):\n",
        "    \"\"\"\n",
        "    Analiza los resultados guardados y genera un resumen\n",
        "    \"\"\"\n",
        "    print(\"üìä Analizando resultados...\")\n",
        "\n",
        "    results_files = [f for f in os.listdir(results_path) if f.startswith('results_RandomForest_')]\n",
        "\n",
        "    if not results_files:\n",
        "        print(\"‚ùå No se encontraron archivos de resultados\")\n",
        "        return\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for file in results_files:\n",
        "        try:\n",
        "            df = pd.read_csv(os.path.join(results_path, file))\n",
        "            family = file.split('_')[2]  # Extraer nombre de familia\n",
        "            run = file.split('_')[3].replace('.csv.gz', '')\n",
        "\n",
        "            # Calcular m√©tricas\n",
        "            accuracy = df['correct'].mean()\n",
        "            avg_time = df['query_time'].mean()\n",
        "\n",
        "            all_results.append({\n",
        "                'family': family,\n",
        "                'run': run,\n",
        "                'accuracy': accuracy,\n",
        "                'avg_query_time': avg_time,\n",
        "                'total_domains': len(df),\n",
        "                'dga_domains': len(df[df['label'] == 'dga']),\n",
        "                'legit_domains': len(df[df['label'] == 'notdga'])\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error procesando {file}: {str(e)}\")\n",
        "\n",
        "    if all_results:\n",
        "        summary_df = pd.DataFrame(all_results)\n",
        "\n",
        "        # Resumen por familia\n",
        "        family_summary = summary_df.groupby('family').agg({\n",
        "            'accuracy': ['mean', 'std'],\n",
        "            'avg_query_time': ['mean', 'std'],\n",
        "            'total_domains': 'sum'\n",
        "        }).round(4)\n",
        "\n",
        "        print(\"\\nüìà Resumen por familia:\")\n",
        "        print(family_summary)\n",
        "\n",
        "        # Guardar resumen\n",
        "        summary_file = os.path.join(results_path, 'evaluation_summary.csv')\n",
        "        family_summary.to_csv(summary_file)\n",
        "\n",
        "        print(f\"\\nüíæ Resumen guardado en: {summary_file}\")\n",
        "\n",
        "        return summary_df\n",
        "\n",
        "    return None\n",
        "\n",
        "# === EJEMPLO DE USO ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Asume que ya tienes el modelo entrenado y los diccionarios\n",
        "    # model, dictionaries = train_dga_classifier(your_training_data)\n",
        "\n",
        "    print(\"üèÉ‚Äç‚ôÇÔ∏è Iniciando evaluaci√≥n de familias DGA...\")\n",
        "    print(\"üìã Par√°metros:\")\n",
        "    print(f\"   - Familias: 8\")\n",
        "    print(f\"   - Runs por familia: 30\")\n",
        "    print(f\"   - Chunk size: 50\")\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "    # Ejecutar evaluaci√≥n\n",
        "    evaluate_dga_families(model, dictionaries)\n",
        "\n",
        "    # Analizar resultados\n",
        "    results_summary = analyze_results()\n",
        "\n",
        "    print(\"\\n‚úÖ Evaluaci√≥n completada!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSvWzmcpgHCs",
        "outputId": "9fbae472-01ed-41b8-f4aa-f39346203962"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ‚Äç‚ôÇÔ∏è Iniciando evaluaci√≥n de familias DGA...\n",
            "üìã Par√°metros:\n",
            "   - Familias: 8\n",
            "   - Runs por familia: 30\n",
            "   - Chunk size: 50\n",
            "\n",
            "==================================================\n",
            "üîç Procesando familia: matsnu.gz\n",
            "\n",
            "‚úÖ matsnu.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Total dominios procesados: 3000\n",
            "   Tiempo total: 137.7776s\n",
            "   Tiempo promedio por dominio: 0.045926s\n",
            "   Dominios por segundo: 21.77\n",
            "\n",
            "==================================================\n",
            "üîç Procesando familia: suppobox.gz\n",
            "\n",
            "‚úÖ suppobox.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Total dominios procesados: 3000\n",
            "   Tiempo total: 138.4538s\n",
            "   Tiempo promedio por dominio: 0.046151s\n",
            "   Dominios por segundo: 21.67\n",
            "\n",
            "==================================================\n",
            "üîç Procesando familia: charbot.gz\n",
            "\n",
            "‚úÖ charbot.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Total dominios procesados: 3000\n",
            "   Tiempo total: 138.0810s\n",
            "   Tiempo promedio por dominio: 0.046027s\n",
            "   Dominios por segundo: 21.73\n",
            "\n",
            "==================================================\n",
            "üîç Procesando familia: gozi.gz\n",
            "\n",
            "‚úÖ gozi.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Total dominios procesados: 3000\n",
            "   Tiempo total: 138.6897s\n",
            "   Tiempo promedio por dominio: 0.046230s\n",
            "   Dominios por segundo: 21.63\n",
            "\n",
            "==================================================\n",
            "üîç Procesando familia: manuelita.gz\n",
            "\n",
            "‚úÖ manuelita.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Total dominios procesados: 3000\n",
            "   Tiempo total: 139.0064s\n",
            "   Tiempo promedio por dominio: 0.046335s\n",
            "   Dominios por segundo: 21.58\n",
            "\n",
            "==================================================\n",
            "üîç Procesando familia: rovnix.gz\n",
            "\n",
            "‚úÖ rovnix.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Total dominios procesados: 3000\n",
            "   Tiempo total: 139.7754s\n",
            "   Tiempo promedio por dominio: 0.046592s\n",
            "   Dominios por segundo: 21.46\n",
            "\n",
            "==================================================\n",
            "üîç Procesando familia: deception.gz\n",
            "\n",
            "‚úÖ deception.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Total dominios procesados: 3000\n",
            "   Tiempo total: 142.4067s\n",
            "   Tiempo promedio por dominio: 0.047469s\n",
            "   Dominios por segundo: 21.07\n",
            "\n",
            "==================================================\n",
            "üîç Procesando familia: nymaim.gz\n",
            "\n",
            "‚úÖ nymaim.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Total dominios procesados: 3000\n",
            "   Tiempo total: 139.9440s\n",
            "   Tiempo promedio por dominio: 0.046648s\n",
            "   Dominios por segundo: 21.44\n",
            "\n",
            "==================================================\n",
            "üìä Analizando resultados...\n",
            "\n",
            "üìà Resumen por familia:\n",
            "          accuracy         avg_query_time         total_domains\n",
            "              mean     std           mean     std           sum\n",
            "family                                                         \n",
            "charbot     0.4707  0.0025         0.0460  0.0006          3000\n",
            "deception   0.9177  0.0199         0.0475  0.0045          3000\n",
            "gozi        0.4700  0.0000         0.0462  0.0010          3000\n",
            "manuelita   0.4817  0.0075         0.0463  0.0019          3000\n",
            "matsnu      0.7593  0.0326         0.0459  0.0004          3000\n",
            "nymaim      0.5487  0.0257         0.0466  0.0020          3000\n",
            "rovnix      0.4700  0.0000         0.0466  0.0026          3000\n",
            "suppobox    0.5163  0.0277         0.0461  0.0016          3000\n",
            "\n",
            "üíæ Resumen guardado en: /content/drive/My Drive/results/evaluation_summary.csv\n",
            "\n",
            "‚úÖ Evaluaci√≥n completada!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = f'/content/drive/My Drive/results/results_RandomForest_matsnu_20.csv.gz'\n",
        "df1 = pd.read_csv(path)\n",
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "5sX8n_4uiEx_",
        "outputId": "87d90453-1522-4bb2-8999-f60748d26355"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0                    domain  family subfamily   label    pred  \\\n",
              "0      1049306      smokeform-camera.com  matsnu    matsnu     dga  notdga   \n",
              "1      1049307  duty-differ-shoulder.com  matsnu    matsnu     dga     dga   \n",
              "2      1049308      clerkbottle-head.com  matsnu    matsnu     dga  notdga   \n",
              "3      1049309        dog-black-back.com  matsnu    matsnu     dga     dga   \n",
              "4      1049310    key-string-project.com  matsnu    matsnu     dga     dga   \n",
              "..         ...                       ...     ...       ...     ...     ...   \n",
              "95     3218513        airbus-carpool.com   legit    tranco  notdga  notdga   \n",
              "96     3218514      xn--80aa9bg.xn--p1ai   legit    tranco  notdga  notdga   \n",
              "97     3218515              ultraval.net   legit    tranco  notdga  notdga   \n",
              "98     3218516       essen-nutrition.com   legit    tranco  notdga  notdga   \n",
              "99     3218517                  6017.com   legit    tranco  notdga  notdga   \n",
              "\n",
              "    prob_dga  prob_notdga  query_time  batch_time  run  correct  \n",
              "0   0.169708     0.830292    0.045187    4.562825   20        0  \n",
              "1   0.977685     0.022315    0.044914    4.562825   20        1  \n",
              "2   0.200283     0.799717    0.045159    4.562825   20        0  \n",
              "3   0.976948     0.023052    0.044837    4.562825   20        1  \n",
              "4   0.986510     0.013490    0.045016    4.562825   20        1  \n",
              "..       ...          ...         ...         ...  ...      ...  \n",
              "95  0.000518     0.999482    0.044965    4.562825   20        1  \n",
              "96  0.192380     0.807620    0.046172    4.562825   20        1  \n",
              "97  0.000311     0.999689    0.044628    4.562825   20        1  \n",
              "98  0.001977     0.998023    0.044798    4.562825   20        1  \n",
              "99  0.004237     0.995763    0.044789    4.562825   20        1  \n",
              "\n",
              "[100 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae06370f-7937-488b-8de6-212b96d5b969\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>domain</th>\n",
              "      <th>family</th>\n",
              "      <th>subfamily</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "      <th>prob_dga</th>\n",
              "      <th>prob_notdga</th>\n",
              "      <th>query_time</th>\n",
              "      <th>batch_time</th>\n",
              "      <th>run</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1049306</td>\n",
              "      <td>smokeform-camera.com</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>dga</td>\n",
              "      <td>notdga</td>\n",
              "      <td>0.169708</td>\n",
              "      <td>0.830292</td>\n",
              "      <td>0.045187</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1049307</td>\n",
              "      <td>duty-differ-shoulder.com</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>dga</td>\n",
              "      <td>dga</td>\n",
              "      <td>0.977685</td>\n",
              "      <td>0.022315</td>\n",
              "      <td>0.044914</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1049308</td>\n",
              "      <td>clerkbottle-head.com</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>dga</td>\n",
              "      <td>notdga</td>\n",
              "      <td>0.200283</td>\n",
              "      <td>0.799717</td>\n",
              "      <td>0.045159</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1049309</td>\n",
              "      <td>dog-black-back.com</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>dga</td>\n",
              "      <td>dga</td>\n",
              "      <td>0.976948</td>\n",
              "      <td>0.023052</td>\n",
              "      <td>0.044837</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1049310</td>\n",
              "      <td>key-string-project.com</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>matsnu</td>\n",
              "      <td>dga</td>\n",
              "      <td>dga</td>\n",
              "      <td>0.986510</td>\n",
              "      <td>0.013490</td>\n",
              "      <td>0.045016</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>3218513</td>\n",
              "      <td>airbus-carpool.com</td>\n",
              "      <td>legit</td>\n",
              "      <td>tranco</td>\n",
              "      <td>notdga</td>\n",
              "      <td>notdga</td>\n",
              "      <td>0.000518</td>\n",
              "      <td>0.999482</td>\n",
              "      <td>0.044965</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>3218514</td>\n",
              "      <td>xn--80aa9bg.xn--p1ai</td>\n",
              "      <td>legit</td>\n",
              "      <td>tranco</td>\n",
              "      <td>notdga</td>\n",
              "      <td>notdga</td>\n",
              "      <td>0.192380</td>\n",
              "      <td>0.807620</td>\n",
              "      <td>0.046172</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>3218515</td>\n",
              "      <td>ultraval.net</td>\n",
              "      <td>legit</td>\n",
              "      <td>tranco</td>\n",
              "      <td>notdga</td>\n",
              "      <td>notdga</td>\n",
              "      <td>0.000311</td>\n",
              "      <td>0.999689</td>\n",
              "      <td>0.044628</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>3218516</td>\n",
              "      <td>essen-nutrition.com</td>\n",
              "      <td>legit</td>\n",
              "      <td>tranco</td>\n",
              "      <td>notdga</td>\n",
              "      <td>notdga</td>\n",
              "      <td>0.001977</td>\n",
              "      <td>0.998023</td>\n",
              "      <td>0.044798</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>3218517</td>\n",
              "      <td>6017.com</td>\n",
              "      <td>legit</td>\n",
              "      <td>tranco</td>\n",
              "      <td>notdga</td>\n",
              "      <td>notdga</td>\n",
              "      <td>0.004237</td>\n",
              "      <td>0.995763</td>\n",
              "      <td>0.044789</td>\n",
              "      <td>4.562825</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows √ó 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae06370f-7937-488b-8de6-212b96d5b969')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae06370f-7937-488b-8de6-212b96d5b969 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae06370f-7937-488b-8de6-212b96d5b969');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8a03d9e4-c1f7-495f-ada6-7b957dbbf19f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a03d9e4-c1f7-495f-ada6-7b957dbbf19f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8a03d9e4-c1f7-495f-ada6-7b957dbbf19f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c6d74af0-7c33-44d6-a89d-96fdd79a75da\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df1')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c6d74af0-7c33-44d6-a89d-96fdd79a75da button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df1');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1",
              "summary": "{\n  \"name\": \"df1\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1090044,\n        \"min\": 1049306,\n        \"max\": 3218517,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          3218501,\n          3218471,\n          3218488\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"ihatesalliemae.net\",\n          \"pdprojects.cf\",\n          \"nedbankcinemaprive.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"family\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"legit\",\n          \"matsnu\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subfamily\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"tranco\",\n          \"matsnu\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"notdga\",\n          \"dga\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"dga\",\n          \"notdga\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prob_dga\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.40500474246974805,\n        \"min\": 2.780462610187112e-06,\n        \"max\": 0.9911777041345512,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          0.9888084045721076,\n          0.1697081377386175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prob_notdga\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.40500474246974805,\n        \"min\": 0.0088222958654485,\n        \"max\": 0.9999972195373898,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          0.0111915954278922,\n          0.8302918622613824\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0022933504470657117,\n        \"min\": 0.0442574024200439,\n        \"max\": 0.0572774410247802,\n        \"num_unique_values\": 99,\n        \"samples\": [\n          0.0444936752319335,\n          0.0450546741485595\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 4.562824964523315,\n        \"max\": 4.562824964523315,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.562824964523315\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "import gzip\n",
        "\n",
        "def evaluate_new_dga_families(model, dictionaries,\n",
        "                             new_families_path='/content/drive/My Drive/New_Families/',\n",
        "                             legit_file_path='/content/drive/My Drive/Familias_Test/legit.gz',\n",
        "                             results_path='/content/drive/My Drive/results/',\n",
        "                             runs=30, chunk_size=50, skip_legit_chunks=30):\n",
        "    \"\"\"\n",
        "    Eval√∫a nuevas familias DGA con el modelo entrenado\n",
        "\n",
        "    Args:\n",
        "        model: Modelo DGA cargado\n",
        "        dictionaries: Diccionarios del modelo\n",
        "        new_families_path: Ruta de las nuevas familias\n",
        "        legit_file_path: Ruta del archivo de dominios leg√≠timos\n",
        "        results_path: Ruta donde guardar resultados\n",
        "        runs: N√∫mero de ejecuciones por familia\n",
        "        chunk_size: Tama√±o del chunk\n",
        "        skip_legit_chunks: Cu√°ntos chunks de legit saltar (para continuar donde se qued√≥)\n",
        "    \"\"\"\n",
        "\n",
        "    # Nuevas familias a evaluar\n",
        "    families = [\n",
        "        'bigviktor.gz',\n",
        "        'pizd.gz',\n",
        "        'ngioweb.gz'\n",
        "    ]\n",
        "\n",
        "    # Crear directorio de resultados si no existe\n",
        "    Path(results_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Verificar que el archivo legit existe\n",
        "    if not os.path.exists(legit_file_path):\n",
        "        raise FileNotFoundError(f\"Archivo legit no encontrado: {legit_file_path}\")\n",
        "\n",
        "    print(f\"üÜï Evaluando nuevas familias DGA...\")\n",
        "    print(f\"üìÇ Ruta familias: {new_families_path}\")\n",
        "    print(f\"üìÇ Archivo legit: {legit_file_path}\")\n",
        "    print(f\"‚è≠Ô∏è Saltando {skip_legit_chunks} chunks de legit\")\n",
        "    print(f\"üéØ Runs por familia: {runs}\")\n",
        "    print(f\"üì¶ Chunk size: {chunk_size}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Procesar cada nueva familia\n",
        "    for family in families:\n",
        "        print(f\"\\nüîç Procesando familia: {family}\")\n",
        "\n",
        "        family_file = os.path.join(new_families_path, family)\n",
        "        if not os.path.exists(family_file):\n",
        "            print(f\"‚ùå Archivo no encontrado: {family_file}\")\n",
        "            continue\n",
        "\n",
        "        # Estad√≠sticas para la familia\n",
        "        family_stats = {\n",
        "            'family': family.replace('.gz', ''),\n",
        "            'total_domains': 0,\n",
        "            'total_time': 0,\n",
        "            'avg_time_per_domain': 0,\n",
        "            'runs_completed': 0,\n",
        "            'runs_failed': 0,\n",
        "            'total_accuracy': 0,\n",
        "            'avg_accuracy': 0\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Crear lector de chunks para DGA\n",
        "            dga_reader = pd.read_csv(family_file, chunksize=chunk_size)\n",
        "\n",
        "            # Preparar lector de legit y saltar chunks especificados\n",
        "            legit_reader = pd.read_csv(legit_file_path, chunksize=chunk_size)\n",
        "\n",
        "            print(f\"‚è≠Ô∏è Saltando {skip_legit_chunks} chunks de dominios leg√≠timos...\")\n",
        "            try:\n",
        "                for i in range(skip_legit_chunks):\n",
        "                    next(legit_reader)\n",
        "                    if (i + 1) % 10 == 0:\n",
        "                        print(f\"   Saltados {i + 1}/{skip_legit_chunks} chunks\", end='\\r')\n",
        "            except StopIteration:\n",
        "                print(f\"\\n‚ö†Ô∏è Solo se pudieron saltar {i} chunks de legit\")\n",
        "                # Reiniciar el lector si se acabaron los chunks\n",
        "                legit_reader = pd.read_csv(legit_file_path, chunksize=chunk_size)\n",
        "\n",
        "            print(f\"\\n‚úÖ Iniciando evaluaci√≥n de {family}\")\n",
        "\n",
        "            for run in range(runs):\n",
        "                print(f\" ‚ñ∂Ô∏è Run {run+1}/{runs}\", end=\"\\r\")\n",
        "\n",
        "                try:\n",
        "                    # Leer chunk DGA\n",
        "                    dga_chunk = next(dga_reader)\n",
        "\n",
        "                    # Leer chunk legit\n",
        "                    try:\n",
        "                        legit_chunk = next(legit_reader)\n",
        "                    except StopIteration:\n",
        "                        # Si se acabaron los chunks de legit, reiniciar el lector\n",
        "                        legit_reader = pd.read_csv(legit_file_path, chunksize=chunk_size)\n",
        "                        legit_chunk = next(legit_reader)\n",
        "\n",
        "                    # Preparar datos\n",
        "                    # Asegurar nombres de columnas correctos\n",
        "                    if 'domain' not in dga_chunk.columns:\n",
        "                        dga_chunk.columns = ['domain'] + list(dga_chunk.columns[1:])\n",
        "                    if 'domain' not in legit_chunk.columns:\n",
        "                        legit_chunk.columns = ['domain'] + list(legit_chunk.columns[1:])\n",
        "\n",
        "                    # Agregar etiquetas\n",
        "                    dga_chunk['label'] = 'dga'\n",
        "                    legit_chunk['label'] = 'notdga'\n",
        "\n",
        "                    # Combinar chunks\n",
        "                    df_chunk = pd.concat([dga_chunk, legit_chunk]).reset_index(drop=True)\n",
        "\n",
        "                    # Medir tiempo total para el batch\n",
        "                    batch_start_time = time.time()\n",
        "\n",
        "                    # Obtener predicciones y tiempos\n",
        "                    results = classify_domains_batch(df_chunk[\"domain\"].values, model, dictionaries)\n",
        "\n",
        "                    batch_end_time = time.time()\n",
        "                    batch_total_time = batch_end_time - batch_start_time\n",
        "\n",
        "                    # Agregar resultados al DataFrame\n",
        "                    df_chunk[\"pred\"] = results['predictions']\n",
        "                    df_chunk[\"prob_dga\"] = results['probabilities_dga']\n",
        "                    df_chunk[\"prob_notdga\"] = results['probabilities_notdga']\n",
        "                    df_chunk[\"query_time\"] = results['processing_times']\n",
        "                    df_chunk[\"batch_time\"] = batch_total_time\n",
        "                    df_chunk[\"run\"] = run\n",
        "                    df_chunk[\"family\"] = family.replace('.gz', '')\n",
        "\n",
        "                    # Calcular m√©tricas\n",
        "                    df_chunk[\"correct\"] = (df_chunk[\"label\"] == df_chunk[\"pred\"]).astype(int)\n",
        "                    run_accuracy = df_chunk[\"correct\"].mean()\n",
        "\n",
        "                    # Actualizar estad√≠sticas\n",
        "                    family_stats['total_domains'] += len(df_chunk)\n",
        "                    family_stats['total_time'] += batch_total_time\n",
        "                    family_stats['runs_completed'] += 1\n",
        "                    family_stats['total_accuracy'] += run_accuracy\n",
        "\n",
        "                    # Guardar resultados (con nombre actualizado)\n",
        "                    output_file = os.path.join(\n",
        "                        results_path,\n",
        "                        f\"results_RandomForest_NEW_{family.replace('.gz', '')}_{run}.csv.gz\"\n",
        "                    )\n",
        "\n",
        "                    df_chunk.to_csv(\n",
        "                        output_file,\n",
        "                        index=False,\n",
        "                        compression=\"gzip\"\n",
        "                    )\n",
        "\n",
        "                except StopIteration:\n",
        "                    print(f\"\\n‚ö†Ô∏è No hay m√°s datos DGA disponibles para {family} en run {run+1}\")\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    print(f\"\\n‚ùå Error en run {run+1} para {family}: {str(e)}\")\n",
        "                    family_stats['runs_failed'] += 1\n",
        "                    continue\n",
        "\n",
        "            # Calcular estad√≠sticas finales para la familia\n",
        "            if family_stats['runs_completed'] > 0:\n",
        "                family_stats['avg_time_per_domain'] = family_stats['total_time'] / family_stats['total_domains']\n",
        "                family_stats['avg_accuracy'] = family_stats['total_accuracy'] / family_stats['runs_completed']\n",
        "\n",
        "                print(f\"\\n‚úÖ {family} completado:\")\n",
        "                print(f\"   Runs completados: {family_stats['runs_completed']}/{runs}\")\n",
        "                print(f\"   Runs fallidos: {family_stats['runs_failed']}\")\n",
        "                print(f\"   Total dominios procesados: {family_stats['total_domains']}\")\n",
        "                print(f\"   Accuracy promedio: {family_stats['avg_accuracy']:.4f}\")\n",
        "                print(f\"   Tiempo total: {family_stats['total_time']:.4f}s\")\n",
        "                print(f\"   Tiempo promedio por dominio: {family_stats['avg_time_per_domain']:.6f}s\")\n",
        "                print(f\"   Dominios por segundo: {family_stats['total_domains']/family_stats['total_time']:.2f}\")\n",
        "\n",
        "                # Guardar estad√≠sticas de la familia\n",
        "                stats_df = pd.DataFrame([family_stats])\n",
        "                stats_file = os.path.join(results_path, f\"stats_NEW_{family.replace('.gz', '')}.csv\")\n",
        "                stats_df.to_csv(stats_file, index=False)\n",
        "\n",
        "            else:\n",
        "                print(f\"\\n‚ùå No se complet√≥ ning√∫n run para {family}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Error cr√≠tico procesando familia {family}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n\" + \"=\"*50)\n",
        "\n",
        "    print(f\"\\nüéâ Evaluaci√≥n de nuevas familias completada!\")\n",
        "    print(f\"üìÅ Resultados guardados en: {results_path}\")\n",
        "\n",
        "def classify_domains_batch(domains, model, dictionaries):\n",
        "    \"\"\"\n",
        "    Clasifica m√∫ltiples dominios y mide el tiempo de procesamiento\n",
        "    (Copia de la funci√≥n del c√≥digo anterior)\n",
        "    \"\"\"\n",
        "    dga_dict, private_dict, english_dict, noun_dict, verb_dict, adj_dict = dictionaries\n",
        "\n",
        "    predictions = []\n",
        "    probabilities_dga = []\n",
        "    probabilities_notdga = []\n",
        "    processing_times = []\n",
        "\n",
        "    for domain in domains:\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Extraer caracter√≠sticas\n",
        "        features = extract_features(domain, dga_dict, private_dict, english_dict,\n",
        "                                  noun_dict, verb_dict, adj_dict)\n",
        "        features_array = np.array([features])\n",
        "\n",
        "        # Hacer predicci√≥n\n",
        "        prediction = model.predict(features_array)[0]\n",
        "        probability = model.predict_proba(features_array)[0]\n",
        "\n",
        "        end_time = time.time()\n",
        "        query_time = end_time - start_time\n",
        "\n",
        "        predictions.append('dga' if prediction == 1 else 'notdga')\n",
        "        probabilities_dga.append(probability[1])\n",
        "        probabilities_notdga.append(probability[0])\n",
        "        processing_times.append(query_time)\n",
        "\n",
        "    return {\n",
        "        'predictions': predictions,\n",
        "        'probabilities_dga': probabilities_dga,\n",
        "        'probabilities_notdga': probabilities_notdga,\n",
        "        'processing_times': processing_times\n",
        "    }\n",
        "\n",
        "def analyze_new_families_results(results_path='/content/drive/My Drive/results/'):\n",
        "    \"\"\"\n",
        "    Analiza espec√≠ficamente los resultados de las nuevas familias\n",
        "    \"\"\"\n",
        "    print(\"üìä Analizando resultados de nuevas familias...\")\n",
        "\n",
        "    # Buscar archivos de nuevas familias\n",
        "    results_files = [f for f in os.listdir(results_path)\n",
        "                    if f.startswith('results_RandomForest_NEW_')]\n",
        "\n",
        "    if not results_files:\n",
        "        print(\"‚ùå No se encontraron archivos de resultados de nuevas familias\")\n",
        "        return\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for file in results_files:\n",
        "        try:\n",
        "            df = pd.read_csv(os.path.join(results_path, file))\n",
        "\n",
        "            # Extraer informaci√≥n del nombre del archivo\n",
        "            parts = file.replace('.csv.gz', '').split('_')\n",
        "            family = parts[3]  # NEW_{family}\n",
        "            run = parts[4]\n",
        "\n",
        "            # Calcular m√©tricas\n",
        "            accuracy = df['correct'].mean()\n",
        "            avg_time = df['query_time'].mean()\n",
        "\n",
        "            # M√©tricas por tipo de dominio\n",
        "            dga_accuracy = df[df['label'] == 'dga']['correct'].mean()\n",
        "            legit_accuracy = df[df['label'] == 'notdga']['correct'].mean()\n",
        "\n",
        "            all_results.append({\n",
        "                'family': family,\n",
        "                'run': run,\n",
        "                'accuracy': accuracy,\n",
        "                'dga_accuracy': dga_accuracy,\n",
        "                'legit_accuracy': legit_accuracy,\n",
        "                'avg_query_time': avg_time,\n",
        "                'total_domains': len(df),\n",
        "                'dga_domains': len(df[df['label'] == 'dga']),\n",
        "                'legit_domains': len(df[df['label'] == 'notdga'])\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error procesando {file}: {str(e)}\")\n",
        "\n",
        "    if all_results:\n",
        "        summary_df = pd.DataFrame(all_results)\n",
        "\n",
        "        # Resumen por familia\n",
        "        family_summary = summary_df.groupby('family').agg({\n",
        "            'accuracy': ['mean', 'std', 'min', 'max'],\n",
        "            'dga_accuracy': ['mean', 'std'],\n",
        "            'legit_accuracy': ['mean', 'std'],\n",
        "            'avg_query_time': ['mean', 'std'],\n",
        "            'total_domains': 'sum'\n",
        "        }).round(4)\n",
        "\n",
        "        print(\"\\nüìà Resumen de nuevas familias:\")\n",
        "        print(family_summary)\n",
        "\n",
        "        # Comparaci√≥n con familias originales (si hay datos)\n",
        "        print(f\"\\nüÜï Resultados por familia nueva:\")\n",
        "        for family in summary_df['family'].unique():\n",
        "            family_data = summary_df[summary_df['family'] == family]\n",
        "            print(f\"\\n{family.upper()}:\")\n",
        "            print(f\"  üìä Accuracy promedio: {family_data['accuracy'].mean():.4f} ¬±{family_data['accuracy'].std():.4f}\")\n",
        "            print(f\"  üéØ DGA detection: {family_data['dga_accuracy'].mean():.4f}\")\n",
        "            print(f\"  ‚úÖ Legit detection: {family_data['legit_accuracy'].mean():.4f}\")\n",
        "            print(f\"  ‚è±Ô∏è Tiempo promedio: {family_data['avg_query_time'].mean():.6f}s\")\n",
        "            print(f\"  üìù Runs completados: {len(family_data)}\")\n",
        "\n",
        "        # Guardar resumen\n",
        "        summary_file = os.path.join(results_path, 'new_families_summary.csv')\n",
        "        family_summary.to_csv(summary_file)\n",
        "\n",
        "        detailed_file = os.path.join(results_path, 'new_families_detailed.csv')\n",
        "        summary_df.to_csv(detailed_file, index=False)\n",
        "\n",
        "        print(f\"\\nüíæ Res√∫menes guardados:\")\n",
        "        print(f\"  - {summary_file}\")\n",
        "        print(f\"  - {detailed_file}\")\n",
        "\n",
        "        return summary_df\n",
        "\n",
        "    return None\n",
        "\n",
        "# === EJEMPLO DE USO ===\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üÜï Evaluaci√≥n de Nuevas Familias DGA\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Cargar el modelo previamente entrenado\n",
        "    print(\"üì• Cargando modelo DGA...\")\n",
        "    try:\n",
        "        model, dictionaries, metadata = load_dga_model()\n",
        "        print(\"‚úÖ Modelo cargado exitosamente\")\n",
        "\n",
        "        # Ejecutar evaluaci√≥n de nuevas familias\n",
        "        print(\"\\nüöÄ Iniciando evaluaci√≥n de nuevas familias...\")\n",
        "        evaluate_new_dga_families(\n",
        "            model=model,\n",
        "            dictionaries=dictionaries,\n",
        "            new_families_path='/content/drive/My Drive/New_Families/',\n",
        "            legit_file_path='/content/drive/My Drive/Familias_Test/legit.gz',\n",
        "            results_path='/content/drive/My Drive/results/',\n",
        "            runs=30,\n",
        "            chunk_size=50,\n",
        "            skip_legit_chunks=30\n",
        "        )\n",
        "\n",
        "        # Analizar resultados\n",
        "        print(\"\\nüìä Analizando resultados...\")\n",
        "        results_summary = analyze_new_families_results()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {str(e)}\")\n",
        "        print(\"üí° Aseg√∫rate de haber entrenado y guardado el modelo primero\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yavn0LP8iE1H",
        "outputId": "fe9bf87e-86fa-4f93-c7fd-056b1f00c9e1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üÜï Evaluaci√≥n de Nuevas Familias DGA\n",
            "==================================================\n",
            "üì• Cargando modelo DGA...\n",
            "üì• Cargando modelo...\n",
            "‚úÖ Modelo cargado exitosamente\n",
            "üì• Cargando diccionarios...\n",
            "‚úÖ Diccionarios cargados exitosamente\n",
            "üì• Cargando metadatos...\n",
            "‚úÖ Metadatos cargados exitosamente\n",
            "\n",
            "üìä Informaci√≥n del modelo:\n",
            "  Tipo: RandomForestClassifier\n",
            "  N¬∞ de √°rboles: 100\n",
            "  N¬∞ de caracter√≠sticas: 16\n",
            "  Tama√±os de diccionarios:\n",
            "    - english_dict: 234,351 palabras\n",
            "    - noun_dict: 100 palabras\n",
            "    - verb_dict: 106 palabras\n",
            "    - adj_dict: 110 palabras\n",
            "    - dga_dict: 77,834 palabras\n",
            "    - private_dict: 74,121 palabras\n",
            "‚úÖ Modelo cargado exitosamente\n",
            "\n",
            "üöÄ Iniciando evaluaci√≥n de nuevas familias...\n",
            "üÜï Evaluando nuevas familias DGA...\n",
            "üìÇ Ruta familias: /content/drive/My Drive/New_Families/\n",
            "üìÇ Archivo legit: /content/drive/My Drive/Familias_Test/legit.gz\n",
            "‚è≠Ô∏è Saltando 30 chunks de legit\n",
            "üéØ Runs por familia: 30\n",
            "üì¶ Chunk size: 50\n",
            "============================================================\n",
            "\n",
            "üîç Procesando familia: bigviktor.gz\n",
            "‚è≠Ô∏è Saltando 30 chunks de dominios leg√≠timos...\n",
            "   Saltados 30/30 chunks\n",
            "‚úÖ Iniciando evaluaci√≥n de bigviktor.gz\n",
            "\n",
            "‚úÖ bigviktor.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Runs fallidos: 0\n",
            "   Total dominios procesados: 3000\n",
            "   Accuracy promedio: 0.4963\n",
            "   Tiempo total: 156.5061s\n",
            "   Tiempo promedio por dominio: 0.052169s\n",
            "   Dominios por segundo: 19.17\n",
            "\n",
            "==================================================\n",
            "\n",
            "üîç Procesando familia: pizd.gz\n",
            "‚è≠Ô∏è Saltando 30 chunks de dominios leg√≠timos...\n",
            "   Saltados 30/30 chunks\n",
            "‚úÖ Iniciando evaluaci√≥n de pizd.gz\n",
            "\n",
            "‚úÖ pizd.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Runs fallidos: 0\n",
            "   Total dominios procesados: 3000\n",
            "   Accuracy promedio: 0.4903\n",
            "   Tiempo total: 157.0484s\n",
            "   Tiempo promedio por dominio: 0.052349s\n",
            "   Dominios por segundo: 19.10\n",
            "\n",
            "==================================================\n",
            "\n",
            "üîç Procesando familia: ngioweb.gz\n",
            "‚è≠Ô∏è Saltando 30 chunks de dominios leg√≠timos...\n",
            "   Saltados 30/30 chunks\n",
            "‚úÖ Iniciando evaluaci√≥n de ngioweb.gz\n",
            "\n",
            "‚úÖ ngioweb.gz completado:\n",
            "   Runs completados: 30/30\n",
            "   Runs fallidos: 0\n",
            "   Total dominios procesados: 3000\n",
            "   Accuracy promedio: 0.4850\n",
            "   Tiempo total: 143.6180s\n",
            "   Tiempo promedio por dominio: 0.047873s\n",
            "   Dominios por segundo: 20.89\n",
            "\n",
            "==================================================\n",
            "\n",
            "üéâ Evaluaci√≥n de nuevas familias completada!\n",
            "üìÅ Resultados guardados en: /content/drive/My Drive/results/\n",
            "\n",
            "üìä Analizando resultados...\n",
            "üìä Analizando resultados de nuevas familias...\n",
            "\n",
            "üìà Resumen de nuevas familias:\n",
            "          accuracy                     dga_accuracy         legit_accuracy  \\\n",
            "              mean     std   min   max         mean     std           mean   \n",
            "family                                                                       \n",
            "bigviktor   0.4963  0.0145  0.47  0.53       0.0227  0.0227           0.97   \n",
            "ngioweb     0.4850  0.0111  0.46  0.50       0.0000  0.0000           0.97   \n",
            "pizd        0.4903  0.0143  0.46  0.51       0.0107  0.0136           0.97   \n",
            "\n",
            "                  avg_query_time         total_domains  \n",
            "              std           mean     std           sum  \n",
            "family                                                  \n",
            "bigviktor  0.0221         0.0522  0.0080          3000  \n",
            "ngioweb    0.0221         0.0479  0.0019          3000  \n",
            "pizd       0.0221         0.0523  0.0130          3000  \n",
            "\n",
            "üÜï Resultados por familia nueva:\n",
            "\n",
            "BIGVIKTOR:\n",
            "  üìä Accuracy promedio: 0.4963 ¬±0.0145\n",
            "  üéØ DGA detection: 0.0227\n",
            "  ‚úÖ Legit detection: 0.9700\n",
            "  ‚è±Ô∏è Tiempo promedio: 0.052163s\n",
            "  üìù Runs completados: 30\n",
            "\n",
            "PIZD:\n",
            "  üìä Accuracy promedio: 0.4903 ¬±0.0143\n",
            "  üéØ DGA detection: 0.0107\n",
            "  ‚úÖ Legit detection: 0.9700\n",
            "  ‚è±Ô∏è Tiempo promedio: 0.052344s\n",
            "  üìù Runs completados: 30\n",
            "\n",
            "NGIOWEB:\n",
            "  üìä Accuracy promedio: 0.4850 ¬±0.0111\n",
            "  üéØ DGA detection: 0.0000\n",
            "  ‚úÖ Legit detection: 0.9700\n",
            "  ‚è±Ô∏è Tiempo promedio: 0.047867s\n",
            "  üìù Runs completados: 30\n",
            "\n",
            "üíæ Res√∫menes guardados:\n",
            "  - /content/drive/My Drive/results/new_families_summary.csv\n",
            "  - /content/drive/My Drive/results/new_families_detailed.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wOD05qSUsL3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import joblib\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def save_dga_model(model, dictionaries, model_path='/content/drive/My Drive/models/'):\n",
        "    \"\"\"\n",
        "    Guarda el modelo DGA entrenado y todos sus diccionarios\n",
        "\n",
        "    Args:\n",
        "        model: Modelo RandomForest entrenado\n",
        "        dictionaries: Tupla con todos los diccionarios necesarios\n",
        "        model_path: Ruta donde guardar el modelo\n",
        "    \"\"\"\n",
        "    # Crear directorio si no existe\n",
        "    Path(model_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Guardar el modelo\n",
        "    model_file = os.path.join(model_path, 'dga_random_forest_model.joblib')\n",
        "    joblib.dump(model, model_file)\n",
        "    print(f\"‚úÖ Modelo guardado en: {model_file}\")\n",
        "\n",
        "    # Guardar los diccionarios\n",
        "    dictionaries_file = os.path.join(model_path, 'dga_dictionaries.pkl')\n",
        "    with open(dictionaries_file, 'wb') as f:\n",
        "        pickle.dump(dictionaries, f)\n",
        "    print(f\"‚úÖ Diccionarios guardados en: {dictionaries_file}\")\n",
        "\n",
        "    # Guardar metadatos del modelo\n",
        "    metadata = {\n",
        "        'model_type': 'RandomForestClassifier',\n",
        "        'n_estimators': model.n_estimators,\n",
        "        'max_depth': model.max_depth,\n",
        "        'min_samples_split': model.min_samples_split,\n",
        "        'min_samples_leaf': model.min_samples_leaf,\n",
        "        'random_state': model.random_state,\n",
        "        'n_features': model.n_features_in_,\n",
        "        'feature_names': [\n",
        "            'domain_len', 'ascii_sum', 'vowel_count', 'vowel_dist',\n",
        "            'digit_dash_count', 'digit_dash_dist', 'word_norm', 'word_dga',\n",
        "            'noun_count', 'verb_count', 'adj_count', 'private_count',\n",
        "            'ratio_dga_norm', 'max_len_word', 'min_len_word', 'word_char_ratio'\n",
        "        ],\n",
        "        'dictionary_sizes': {\n",
        "            'english_dict': len(dictionaries[2]),\n",
        "            'noun_dict': len(dictionaries[3]),\n",
        "            'verb_dict': len(dictionaries[4]),\n",
        "            'adj_dict': len(dictionaries[5]),\n",
        "            'dga_dict': len(dictionaries[0]),\n",
        "            'private_dict': len(dictionaries[1])\n",
        "        }\n",
        "    }\n",
        "\n",
        "    metadata_file = os.path.join(model_path, 'model_metadata.pkl')\n",
        "    with open(metadata_file, 'wb') as f:\n",
        "        pickle.dump(metadata, f)\n",
        "    print(f\"‚úÖ Metadatos guardados en: {metadata_file}\")\n",
        "\n",
        "    print(f\"\\nüì¶ Modelo completo guardado en: {model_path}\")\n",
        "    print(\"Archivos creados:\")\n",
        "    print(f\"  - {os.path.basename(model_file)}\")\n",
        "    print(f\"  - {os.path.basename(dictionaries_file)}\")\n",
        "    print(f\"  - {os.path.basename(metadata_file)}\")\n",
        "\n",
        "def load_dga_model(model_path='/content/drive/My Drive/models/'):\n",
        "    \"\"\"\n",
        "    Carga el modelo DGA y sus diccionarios\n",
        "\n",
        "    Args:\n",
        "        model_path: Ruta donde est√° guardado el modelo\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, dictionaries, metadata)\n",
        "    \"\"\"\n",
        "    # Verificar que los archivos existen\n",
        "    model_file = os.path.join(model_path, 'dga_random_forest_model.joblib')\n",
        "    dictionaries_file = os.path.join(model_path, 'dga_dictionaries.pkl')\n",
        "    metadata_file = os.path.join(model_path, 'model_metadata.pkl')\n",
        "\n",
        "    if not os.path.exists(model_file):\n",
        "        raise FileNotFoundError(f\"Modelo no encontrado: {model_file}\")\n",
        "    if not os.path.exists(dictionaries_file):\n",
        "        raise FileNotFoundError(f\"Diccionarios no encontrados: {dictionaries_file}\")\n",
        "    if not os.path.exists(metadata_file):\n",
        "        raise FileNotFoundError(f\"Metadatos no encontrados: {metadata_file}\")\n",
        "\n",
        "    # Cargar el modelo\n",
        "    print(\"üì• Cargando modelo...\")\n",
        "    model = joblib.load(model_file)\n",
        "    print(\"‚úÖ Modelo cargado exitosamente\")\n",
        "\n",
        "    # Cargar los diccionarios\n",
        "    print(\"üì• Cargando diccionarios...\")\n",
        "    with open(dictionaries_file, 'rb') as f:\n",
        "        dictionaries = pickle.load(f)\n",
        "    print(\"‚úÖ Diccionarios cargados exitosamente\")\n",
        "\n",
        "    # Cargar metadatos\n",
        "    print(\"üì• Cargando metadatos...\")\n",
        "    with open(metadata_file, 'rb') as f:\n",
        "        metadata = pickle.load(f)\n",
        "    print(\"‚úÖ Metadatos cargados exitosamente\")\n",
        "\n",
        "    # Mostrar informaci√≥n del modelo\n",
        "    print(f\"\\nüìä Informaci√≥n del modelo:\")\n",
        "    print(f\"  Tipo: {metadata['model_type']}\")\n",
        "    print(f\"  N¬∞ de √°rboles: {metadata['n_estimators']}\")\n",
        "    print(f\"  N¬∞ de caracter√≠sticas: {metadata['n_features']}\")\n",
        "    print(f\"  Tama√±os de diccionarios:\")\n",
        "    for dict_name, size in metadata['dictionary_sizes'].items():\n",
        "        print(f\"    - {dict_name}: {size:,} palabras\")\n",
        "\n",
        "    return model, dictionaries, metadata\n",
        "\n",
        "def test_loaded_model(model, dictionaries, test_domains=None):\n",
        "    \"\"\"\n",
        "    Prueba el modelo cargado con algunos dominios de ejemplo\n",
        "\n",
        "    Args:\n",
        "        model: Modelo cargado\n",
        "        dictionaries: Diccionarios cargados\n",
        "        test_domains: Lista de dominios para probar (opcional)\n",
        "    \"\"\"\n",
        "    if test_domains is None:\n",
        "        test_domains = [\n",
        "            'google.com',\n",
        "            'facebook.com',\n",
        "            'xkvbpqr.com',\n",
        "            'mnbvcxz.net',\n",
        "            'microsoft.com',\n",
        "            'randomstring123.org'\n",
        "        ]\n",
        "\n",
        "    print(\"\\nüß™ Probando modelo con dominios de ejemplo:\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for domain in test_domains:\n",
        "        result = classify_domain(domain, model, dictionaries)\n",
        "        print(f\"{domain:20} -> {result['prediction']:8} (prob: {result['dga_probability']:.3f})\")\n",
        "\n",
        "# === EJEMPLO DE USO COMPLETO ===\n",
        "\n",
        "def complete_training_and_saving_example():\n",
        "    \"\"\"\n",
        "    Ejemplo completo de entrenamiento, guardado y carga del modelo\n",
        "    \"\"\"\n",
        "    print(\"üöÄ Ejemplo completo: Entrenar, Guardar y Cargar modelo DGA\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Paso 1: Crear datos de ejemplo (reemplaza con tus datos reales)\n",
        "    sample_data = {\n",
        "        'domain': [\n",
        "            # Dominios leg√≠timos\n",
        "            'google.com', 'facebook.com', 'microsoft.com', 'amazon.com',\n",
        "            'youtube.com', 'wikipedia.org', 'twitter.com', 'instagram.com',\n",
        "            'linkedin.com', 'github.com', 'stackoverflow.com', 'reddit.com',\n",
        "\n",
        "            # Dominios DGA simulados\n",
        "            'xkvbpqr.com', 'mnbvcxz.net', 'qwertyuiop.org', 'asdfghjkl.info',\n",
        "            'randomstring123.com', 'anotherfakedom.net', 'abcdef.xyz',\n",
        "            'ksdjfhskjh.com', 'pqowieuryt.net', 'zxcvbnm.org', 'hjklqwer.com'\n",
        "        ],\n",
        "        'label': (\n",
        "            ['notdga'] * 12 +  # 12 leg√≠timos\n",
        "            ['dga'] * 11       # 11 DGA\n",
        "        )\n",
        "    }\n",
        "\n",
        "    df_example = pd.DataFrame(sample_data)\n",
        "    print(f\"üìä Dataset de ejemplo: {len(df_example)} dominios\")\n",
        "    print(f\"  - Leg√≠timos: {(df_example['label'] == 'notdga').sum()}\")\n",
        "    print(f\"  - DGA: {(df_example['label'] == 'dga').sum()}\")\n",
        "\n",
        "    # Paso 2: Entrenar el modelo\n",
        "    print(\"\\nüèãÔ∏è Entrenando modelo...\")\n",
        "    model, dictionaries = train_dga_model(df_example)\n",
        "\n",
        "    # Paso 3: Guardar el modelo\n",
        "    print(\"\\nüíæ Guardando modelo...\")\n",
        "    save_dga_model(model, dictionaries)\n",
        "\n",
        "    # Paso 4: Simular reinicio del programa (cargar modelo)\n",
        "    print(\"\\nüîÑ Simulando carga del modelo...\")\n",
        "    loaded_model, loaded_dictionaries, metadata = load_dga_model()\n",
        "\n",
        "    # Paso 5: Probar el modelo cargado\n",
        "    test_loaded_model(loaded_model, loaded_dictionaries)\n",
        "\n",
        "    print(\"\\n‚úÖ Ejemplo completado exitosamente!\")\n",
        "    return loaded_model, loaded_dictionaries\n",
        "\n",
        "# === FUNCIONES AUXILIARES PARA LA CARGA ===\n",
        "\n",
        "def quick_load_and_test():\n",
        "    \"\"\"\n",
        "    Funci√≥n r√°pida para cargar y probar el modelo guardado\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(\"‚ö° Carga r√°pida del modelo DGA...\")\n",
        "        model, dictionaries, metadata = load_dga_model()\n",
        "\n",
        "        # Probar con algunos dominios\n",
        "        test_domains = [\n",
        "            'suspicious-domain.com',\n",
        "            'google.com',\n",
        "            'qwerty123.net',\n",
        "            'microsoft.com'\n",
        "        ]\n",
        "\n",
        "        test_loaded_model(model, dictionaries, test_domains)\n",
        "\n",
        "        return model, dictionaries\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error cargando el modelo: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "def verify_model_files(model_path='/content/drive/My Drive/models/'):\n",
        "    \"\"\"\n",
        "    Verifica que todos los archivos del modelo existen\n",
        "    \"\"\"\n",
        "    required_files = [\n",
        "        'dga_random_forest_model.joblib',\n",
        "        'dga_dictionaries.pkl',\n",
        "        'model_metadata.pkl'\n",
        "    ]\n",
        "\n",
        "    print(f\"üîç Verificando archivos del modelo en: {model_path}\")\n",
        "\n",
        "    all_present = True\n",
        "    for file in required_files:\n",
        "        file_path = os.path.join(model_path, file)\n",
        "        if os.path.exists(file_path):\n",
        "            size = os.path.getsize(file_path)\n",
        "            print(f\"  ‚úÖ {file} ({size:,} bytes)\")\n",
        "        else:\n",
        "            print(f\"  ‚ùå {file} - NO ENCONTRADO\")\n",
        "            all_present = False\n",
        "\n",
        "    return all_present\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Verificar si el modelo ya existe\n",
        "    save_dga_model(model, dictionaries, model_path='/content/drive/My Drive/models/')\n",
        "    if verify_model_files():\n",
        "        print(\"üìÇ Modelo encontrado. Cargando...\")\n",
        "        model, dictionaries = quick_load_and_test()\n",
        "    else:\n",
        "        print(\"üìÇ Modelo no encontrado. Ejecutar entrenamiento completo...\")\n",
        "        # complete_training_and_saving_example()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV_CNO5XsL7m",
        "outputId": "e85f228d-a1c7-4d3d-cd78-76e10851a960"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo guardado en: /content/drive/My Drive/models/dga_random_forest_model.joblib\n",
            "‚úÖ Diccionarios guardados en: /content/drive/My Drive/models/dga_dictionaries.pkl\n",
            "‚úÖ Metadatos guardados en: /content/drive/My Drive/models/model_metadata.pkl\n",
            "\n",
            "üì¶ Modelo completo guardado en: /content/drive/My Drive/models/\n",
            "Archivos creados:\n",
            "  - dga_random_forest_model.joblib\n",
            "  - dga_dictionaries.pkl\n",
            "  - model_metadata.pkl\n",
            "üîç Verificando archivos del modelo en: /content/drive/My Drive/models/\n",
            "  ‚úÖ dga_random_forest_model.joblib (4,793,609 bytes)\n",
            "  ‚úÖ dga_dictionaries.pkl (4,560,688 bytes)\n",
            "  ‚úÖ model_metadata.pkl (531 bytes)\n",
            "üìÇ Modelo encontrado. Cargando...\n",
            "‚ö° Carga r√°pida del modelo DGA...\n",
            "üì• Cargando modelo...\n",
            "‚úÖ Modelo cargado exitosamente\n",
            "üì• Cargando diccionarios...\n",
            "‚úÖ Diccionarios cargados exitosamente\n",
            "üì• Cargando metadatos...\n",
            "‚úÖ Metadatos cargados exitosamente\n",
            "\n",
            "üìä Informaci√≥n del modelo:\n",
            "  Tipo: RandomForestClassifier\n",
            "  N¬∞ de √°rboles: 100\n",
            "  N¬∞ de caracter√≠sticas: 16\n",
            "  Tama√±os de diccionarios:\n",
            "    - english_dict: 234,351 palabras\n",
            "    - noun_dict: 100 palabras\n",
            "    - verb_dict: 106 palabras\n",
            "    - adj_dict: 110 palabras\n",
            "    - dga_dict: 77,834 palabras\n",
            "    - private_dict: 74,121 palabras\n",
            "\n",
            "üß™ Probando modelo con dominios de ejemplo:\n",
            "------------------------------------------------------------\n",
            "suspicious-domain.com -> notdga   (prob: 0.019)\n",
            "google.com           -> dga      (prob: 0.989)\n",
            "qwerty123.net        -> notdga   (prob: 0.000)\n",
            "microsoft.com        -> notdga   (prob: 0.000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v019DTUQsL-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KL20_ilKsMBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBCFGqgesMD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T3zHS_RRsMG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8QGUo_okiE3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cl-xPK0AiE62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ltzJa69dgHFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lOX8ZBpfgHIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_hwnK-v2gHKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runs=30\n",
        "families = [\n",
        "    'matsnu.gz',\n",
        "    'suppobox.gz',\n",
        "    'charbot.gz',\n",
        "    'gozi.gz',\n",
        "    'manuelita.gz',\n",
        "    'rovnix.gz',\n",
        "    'deception.gz',\n",
        "    'nymaim.gz',\n",
        "    'bigviktor.gz',\n",
        "    'pizd.gz',\n",
        "    'ngioweb.gz'\n",
        "]\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def fpr_tpr(y, ypred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y, ypred).ravel()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    return fpr, tpr\n",
        "\n",
        "# Listas para m√©tricas globales\n",
        "all_acc, all_pre, all_rec, all_f1 = [], [], [], []\n",
        "all_fpr, all_tpr, all_qt, all_qts = [], [], [], []\n",
        "total_unknowns_global = 0\n",
        "\n",
        "\n",
        "for family in families:\n",
        "    acc = []\n",
        "    pre = []\n",
        "    rec = []\n",
        "    f1 = []\n",
        "    fpr = []\n",
        "    tpr = []\n",
        "    qt = []\n",
        "    qts = []\n",
        "    total_unknowns = 0\n",
        "    for run in range(runs):\n",
        "        path = f'/content/drive/My Drive/results/results_RandomForest_{family}_{run}.csv.gz'\n",
        "        df = pd.read_csv(path)\n",
        "        #print(df)\n",
        "        y_true = (df[\"label\"] == 'dga').astype(int)\n",
        "        y_pred = (df[\"pred\"] == 'dga').astype(int)\n",
        "        #y_pred = df[\"pred\"]\n",
        "\n",
        "                # M√©tricas\n",
        "        acc.append(accuracy_score(y_true, y_pred))\n",
        "        pre.append(precision_score(y_true, y_pred, zero_division=0))\n",
        "        rec.append(recall_score(y_true, y_pred, zero_division=0))\n",
        "        f1.append(f1_score(y_true, y_pred, zero_division=0))\n",
        "        fpr_val, tpr_val = fpr_tpr(y_true, y_pred)\n",
        "        fpr.append(fpr_val)\n",
        "        tpr.append(tpr_val)\n",
        "\n",
        "        if 'query_time' in df.columns:\n",
        "            qt.append(df['query_time'].mean())\n",
        "            qts.append(df['query_time'].std())\n",
        "\n",
        "    # Promedios por familia\n",
        "    if acc:  # solo si hubo archivos v√°lidos\n",
        "        print(f'{family.split(\".\")[0]:15}: '\n",
        "              f'acc:{np.mean(acc):.2f}¬±{np.std(acc):.3f} '\n",
        "              f'f1:{np.mean(f1):.2f}¬±{np.std(f1):.3f} '\n",
        "              f'pre:{np.mean(pre):.2f}¬±{np.std(pre):.3f} '\n",
        "              f'rec:{np.mean(rec):.2f}¬±{np.std(rec):.3f} '\n",
        "              f'FPR:{np.mean(fpr):.2f}¬±{np.std(fpr):.3f} '\n",
        "              f'TPR:{np.mean(tpr):.2f}¬±{np.std(tpr):.3f} '\n",
        "              f'QT:{np.mean(qt):.5f}¬±{np.std(qt):.5f} '\n",
        "              f'Unknowns: {total_unknowns}')\n",
        "\n",
        "        all_acc.append(np.mean(acc))\n",
        "        all_pre.append(np.mean(pre))\n",
        "        all_rec.append(np.mean(rec))\n",
        "        all_f1.append(np.mean(f1))\n",
        "        all_fpr.append(np.mean(fpr))\n",
        "        all_tpr.append(np.mean(tpr))\n",
        "        all_qt.append(np.mean(qt))\n",
        "        all_qts.append(np.mean(qts))\n",
        "        total_unknowns_global += total_unknowns\n",
        "\n",
        "# üîç M√©tricas globales\n",
        "print(\"\\n### üìä M√©tricas globales ###\")\n",
        "print(f'Accuracy   : {np.mean(all_acc):.2f}')\n",
        "print(f'F1-Score   : {np.mean(all_f1):.2f}')\n",
        "print(f'Precision  : {np.mean(all_pre):.2f}')\n",
        "print(f'Recall     : {np.mean(all_rec):.2f}')\n",
        "print(f'FPR        : {np.mean(all_fpr):.2f}')\n",
        "print(f'TPR        : {np.mean(all_tpr):.2f}')\n",
        "print(f'Query time : {np.mean(all_qt):.5f} ¬± {np.mean(all_qts):.5f}')\n",
        "print(f'Total unknown classifications: {total_unknowns_global}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta40upzq_H5c",
        "outputId": "663cf44e-d145-4a90-80bc-d8a2a9c1c4f3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matsnu         : acc:0.76¬±0.032 f1:0.70¬±0.050 pre:0.91¬±0.009 rec:0.58¬±0.064 FPR:0.06¬±0.000 TPR:0.58¬±0.064 QT:0.04592¬±0.00043 Unknowns: 0\n",
            "suppobox       : acc:0.52¬±0.027 f1:0.16¬±0.086 pre:0.54¬±0.202 rec:0.09¬±0.055 FPR:0.06¬±0.000 TPR:0.09¬±0.055 QT:0.04615¬±0.00155 Unknowns: 0\n",
            "charbot        : acc:0.47¬±0.002 f1:0.00¬±0.009 pre:0.02¬±0.062 rec:0.00¬±0.005 FPR:0.06¬±0.000 TPR:0.00¬±0.005 QT:0.04602¬±0.00059 Unknowns: 0\n",
            "gozi           : acc:0.47¬±0.000 f1:0.00¬±0.000 pre:0.00¬±0.000 rec:0.00¬±0.000 FPR:0.06¬±0.000 TPR:0.00¬±0.000 QT:0.04623¬±0.00100 Unknowns: 0\n",
            "manuelita      : acc:0.48¬±0.007 f1:0.04¬±0.026 pre:0.26¬±0.136 rec:0.02¬±0.015 FPR:0.06¬±0.000 TPR:0.02¬±0.015 QT:0.04633¬±0.00190 Unknowns: 0\n",
            "rovnix         : acc:0.47¬±0.000 f1:0.00¬±0.000 pre:0.00¬±0.000 rec:0.00¬±0.000 FPR:0.06¬±0.000 TPR:0.00¬±0.000 QT:0.04659¬±0.00258 Unknowns: 0\n",
            "deception      : acc:0.92¬±0.020 f1:0.92¬±0.022 pre:0.94¬±0.003 rec:0.90¬±0.039 FPR:0.06¬±0.000 TPR:0.90¬±0.039 QT:0.04746¬±0.00439 Unknowns: 0\n",
            "nymaim         : acc:0.55¬±0.025 f1:0.26¬±0.074 pre:0.70¬±0.094 rec:0.16¬±0.051 FPR:0.06¬±0.000 TPR:0.16¬±0.051 QT:0.04664¬±0.00200 Unknowns: 0\n",
            "bigviktor      : acc:0.50¬±0.014 f1:0.04¬±0.041 pre:0.35¬±0.300 rec:0.02¬±0.022 FPR:0.03¬±0.022 TPR:0.02¬±0.022 QT:0.05216¬±0.00782 Unknowns: 0\n",
            "pizd           : acc:0.49¬±0.014 f1:0.02¬±0.025 pre:0.27¬±0.341 rec:0.01¬±0.013 FPR:0.03¬±0.022 TPR:0.01¬±0.013 QT:0.05234¬±0.01281 Unknowns: 0\n",
            "ngioweb        : acc:0.48¬±0.011 f1:0.00¬±0.000 pre:0.00¬±0.000 rec:0.00¬±0.000 FPR:0.03¬±0.022 TPR:0.00¬±0.000 QT:0.04787¬±0.00190 Unknowns: 0\n",
            "\n",
            "### üìä M√©tricas globales ###\n",
            "Accuracy   : 0.56\n",
            "F1-Score   : 0.19\n",
            "Precision  : 0.36\n",
            "Recall     : 0.16\n",
            "FPR        : 0.05\n",
            "TPR        : 0.16\n",
            "Query time : 0.04761 ¬± 0.00544\n",
            "Total unknown classifications: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "def rename_family_files():\n",
        "    # Mapeo de nombres actuales a nombres nuevos\n",
        "    family_mapping = {\n",
        "        'matsnu': 'matsnu.gz',\n",
        "        'suppobox': 'suppobox.gz',\n",
        "        'charbot': 'charbot.gz',\n",
        "        'gozi': 'gozi.gz',\n",
        "        'manuelita': 'manuelita.gz',\n",
        "        'rovnix': 'rovnix.gz',\n",
        "        'deception': 'deception.gz',\n",
        "        'nymaim': 'nymaim.gz',\n",
        "        'NEW_bigviktor': 'bigviktor.gz',\n",
        "        'NEW_pizd': 'pizd.gz',\n",
        "        'NEW_ngioweb': 'ngioweb.gz'\n",
        "    }\n",
        "\n",
        "    # Cambiar al directorio results\n",
        "    results_dir = '/content/drive/My Drive/results'\n",
        "\n",
        "    if not os.path.exists(results_dir):\n",
        "        print(f\"Error: La carpeta '{results_dir}' no existe\")\n",
        "        return\n",
        "\n",
        "    os.chdir(results_dir)\n",
        "\n",
        "    # Contadores para estad√≠sticas\n",
        "    renamed_count = 0\n",
        "    not_found_count = 0\n",
        "\n",
        "    print(\"Iniciando renombrado de archivos...\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Procesar cada familia\n",
        "    for old_family, new_family in family_mapping.items():\n",
        "        # Buscar archivos que contengan el nombre de la familia actual\n",
        "        pattern = f\"*{old_family}*.csv.gz\"\n",
        "        matching_files = glob.glob(pattern)\n",
        "\n",
        "        print(f\"\\nProcesando familia: {old_family} -> {new_family}\")\n",
        "        print(f\"Archivos encontrados: {len(matching_files)}\")\n",
        "\n",
        "        if not matching_files:\n",
        "            print(f\"  ‚ö†Ô∏è  No se encontraron archivos para la familia '{old_family}'\")\n",
        "            not_found_count += 1\n",
        "            continue\n",
        "\n",
        "        # Renombrar cada archivo encontrado\n",
        "        for old_filename in matching_files:\n",
        "            # Reemplazar el nombre de la familia en el nombre del archivo\n",
        "            new_filename = old_filename.replace(old_family, new_family)\n",
        "\n",
        "            try:\n",
        "                os.rename(old_filename, new_filename)\n",
        "                print(f\"  ‚úÖ {old_filename} -> {new_filename}\")\n",
        "                renamed_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ùå Error renombrando {old_filename}: {e}\")\n",
        "\n",
        "    # Mostrar estad√≠sticas finales\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"RESUMEN FINAL:\")\n",
        "    print(f\"Archivos renombrados exitosamente: {renamed_count}\")\n",
        "    print(f\"Familias sin archivos encontrados: {not_found_count}\")\n",
        "    print(\"Proceso completado.\")\n",
        "\n",
        "    # Volver al directorio original\n",
        "    os.chdir('..')\n",
        "\n",
        "# Funci√≥n alternativa que tambi√©n muestra una vista previa antes de renombrar\n",
        "def preview_rename_family_files():\n",
        "    \"\"\"Versi√≥n que muestra qu√© cambios se har√°n antes de ejecutarlos\"\"\"\n",
        "\n",
        "    family_mapping = {\n",
        "        'matsnu': 'matsnu.gz',\n",
        "        'suppobox': 'suppobox.gz',\n",
        "        'charbot': 'charbot.gz',\n",
        "        'gozi': 'gozi.gz',\n",
        "        'manuelita': 'manuelita.gz',\n",
        "        'rovnix': 'rovnix.gz',\n",
        "        'deception': 'deception.gz',\n",
        "        'nymaim': 'nymaim.gz',\n",
        "        'bigviktor': 'bigviktor.gz',\n",
        "        'pizd': 'pizd.gz',\n",
        "        'ngioweb': 'ngioweb.gz'\n",
        "    }\n",
        "\n",
        "    results_dir = 'results'\n",
        "\n",
        "    if not os.path.exists(results_dir):\n",
        "        print(f\"Error: La carpeta '{results_dir}' no existe\")\n",
        "        return\n",
        "\n",
        "    os.chdir(results_dir)\n",
        "\n",
        "    print(\"VISTA PREVIA DE CAMBIOS:\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    changes_to_make = []\n",
        "\n",
        "    # Mostrar vista previa\n",
        "    for old_family, new_family in family_mapping.items():\n",
        "        pattern = f\"*{old_family}*.csv.gz\"\n",
        "        matching_files = glob.glob(pattern)\n",
        "\n",
        "        if matching_files:\n",
        "            print(f\"\\nFamilia: {old_family} -> {new_family} ({len(matching_files)} archivos)\")\n",
        "            for old_filename in matching_files:\n",
        "                new_filename = old_filename.replace(old_family, new_family)\n",
        "                print(f\"  {old_filename} -> {new_filename}\")\n",
        "                changes_to_make.append((old_filename, new_filename))\n",
        "\n",
        "    if not changes_to_make:\n",
        "        print(\"No se encontraron archivos para renombrar.\")\n",
        "        os.chdir('..')\n",
        "        return\n",
        "\n",
        "    # Confirmar cambios\n",
        "    print(f\"\\n¬øProceder con el renombrado de {len(changes_to_make)} archivos? (s/n): \", end=\"\")\n",
        "    confirm = input().lower().strip()\n",
        "\n",
        "    if confirm in ['s', 'si', 's√≠', 'y', 'yes']:\n",
        "        print(\"\\nEjecutando cambios...\")\n",
        "        renamed_count = 0\n",
        "\n",
        "        for old_filename, new_filename in changes_to_make:\n",
        "            try:\n",
        "                os.rename(old_filename, new_filename)\n",
        "                print(f\"  ‚úÖ {old_filename} -> {new_filename}\")\n",
        "                renamed_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ùå Error: {e}\")\n",
        "\n",
        "        print(f\"\\nCompletado: {renamed_count} archivos renombrados.\")\n",
        "    else:\n",
        "        print(\"Operaci√≥n cancelada.\")\n",
        "\n",
        "    os.chdir('..')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Descomenta la funci√≥n que quieras usar:\n",
        "\n",
        "    # Opci√≥n 1: Renombrar directamente\n",
        "    rename_family_files()\n",
        "\n",
        "    # Opci√≥n 2: Mostrar vista previa y confirmar (recomendado)\n",
        "    # preview_rename_family_files()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FivH0iDD1FNa",
        "outputId": "f3d2cdd2-c6e5-4cfa-e83a-263adbea79c9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando renombrado de archivos...\n",
            "--------------------------------------------------\n",
            "\n",
            "Procesando familia: matsnu -> matsnu.gz\n",
            "Archivos encontrados: 30\n",
            "  ‚úÖ results_RandomForest_matsnu_0.csv.gz -> results_RandomForest_matsnu.gz_0.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_1.csv.gz -> results_RandomForest_matsnu.gz_1.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_2.csv.gz -> results_RandomForest_matsnu.gz_2.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_3.csv.gz -> results_RandomForest_matsnu.gz_3.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_4.csv.gz -> results_RandomForest_matsnu.gz_4.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_5.csv.gz -> results_RandomForest_matsnu.gz_5.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_6.csv.gz -> results_RandomForest_matsnu.gz_6.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_7.csv.gz -> results_RandomForest_matsnu.gz_7.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_8.csv.gz -> results_RandomForest_matsnu.gz_8.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_9.csv.gz -> results_RandomForest_matsnu.gz_9.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_10.csv.gz -> results_RandomForest_matsnu.gz_10.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_11.csv.gz -> results_RandomForest_matsnu.gz_11.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_12.csv.gz -> results_RandomForest_matsnu.gz_12.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_13.csv.gz -> results_RandomForest_matsnu.gz_13.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_14.csv.gz -> results_RandomForest_matsnu.gz_14.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_15.csv.gz -> results_RandomForest_matsnu.gz_15.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_16.csv.gz -> results_RandomForest_matsnu.gz_16.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_17.csv.gz -> results_RandomForest_matsnu.gz_17.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_18.csv.gz -> results_RandomForest_matsnu.gz_18.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_19.csv.gz -> results_RandomForest_matsnu.gz_19.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_20.csv.gz -> results_RandomForest_matsnu.gz_20.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_21.csv.gz -> results_RandomForest_matsnu.gz_21.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_22.csv.gz -> results_RandomForest_matsnu.gz_22.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_23.csv.gz -> results_RandomForest_matsnu.gz_23.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_24.csv.gz -> results_RandomForest_matsnu.gz_24.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_25.csv.gz -> results_RandomForest_matsnu.gz_25.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_26.csv.gz -> results_RandomForest_matsnu.gz_26.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_27.csv.gz -> results_RandomForest_matsnu.gz_27.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_28.csv.gz -> results_RandomForest_matsnu.gz_28.csv.gz\n",
            "  ‚úÖ results_RandomForest_matsnu_29.csv.gz -> results_RandomForest_matsnu.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: suppobox -> suppobox.gz\n",
            "Archivos encontrados: 30\n",
            "  ‚úÖ results_RandomForest_suppobox_0.csv.gz -> results_RandomForest_suppobox.gz_0.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_1.csv.gz -> results_RandomForest_suppobox.gz_1.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_2.csv.gz -> results_RandomForest_suppobox.gz_2.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_3.csv.gz -> results_RandomForest_suppobox.gz_3.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_4.csv.gz -> results_RandomForest_suppobox.gz_4.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_5.csv.gz -> results_RandomForest_suppobox.gz_5.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_6.csv.gz -> results_RandomForest_suppobox.gz_6.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_7.csv.gz -> results_RandomForest_suppobox.gz_7.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_8.csv.gz -> results_RandomForest_suppobox.gz_8.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_9.csv.gz -> results_RandomForest_suppobox.gz_9.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_10.csv.gz -> results_RandomForest_suppobox.gz_10.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_11.csv.gz -> results_RandomForest_suppobox.gz_11.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_12.csv.gz -> results_RandomForest_suppobox.gz_12.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_13.csv.gz -> results_RandomForest_suppobox.gz_13.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_14.csv.gz -> results_RandomForest_suppobox.gz_14.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_15.csv.gz -> results_RandomForest_suppobox.gz_15.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_16.csv.gz -> results_RandomForest_suppobox.gz_16.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_17.csv.gz -> results_RandomForest_suppobox.gz_17.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_18.csv.gz -> results_RandomForest_suppobox.gz_18.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_19.csv.gz -> results_RandomForest_suppobox.gz_19.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_20.csv.gz -> results_RandomForest_suppobox.gz_20.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_21.csv.gz -> results_RandomForest_suppobox.gz_21.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_22.csv.gz -> results_RandomForest_suppobox.gz_22.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_23.csv.gz -> results_RandomForest_suppobox.gz_23.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_24.csv.gz -> results_RandomForest_suppobox.gz_24.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_25.csv.gz -> results_RandomForest_suppobox.gz_25.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_26.csv.gz -> results_RandomForest_suppobox.gz_26.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_27.csv.gz -> results_RandomForest_suppobox.gz_27.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_28.csv.gz -> results_RandomForest_suppobox.gz_28.csv.gz\n",
            "  ‚úÖ results_RandomForest_suppobox_29.csv.gz -> results_RandomForest_suppobox.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: charbot -> charbot.gz\n",
            "Archivos encontrados: 30\n",
            "  ‚úÖ results_RandomForest_charbot_0.csv.gz -> results_RandomForest_charbot.gz_0.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_1.csv.gz -> results_RandomForest_charbot.gz_1.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_2.csv.gz -> results_RandomForest_charbot.gz_2.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_3.csv.gz -> results_RandomForest_charbot.gz_3.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_4.csv.gz -> results_RandomForest_charbot.gz_4.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_5.csv.gz -> results_RandomForest_charbot.gz_5.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_6.csv.gz -> results_RandomForest_charbot.gz_6.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_7.csv.gz -> results_RandomForest_charbot.gz_7.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_8.csv.gz -> results_RandomForest_charbot.gz_8.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_9.csv.gz -> results_RandomForest_charbot.gz_9.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_10.csv.gz -> results_RandomForest_charbot.gz_10.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_11.csv.gz -> results_RandomForest_charbot.gz_11.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_12.csv.gz -> results_RandomForest_charbot.gz_12.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_13.csv.gz -> results_RandomForest_charbot.gz_13.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_14.csv.gz -> results_RandomForest_charbot.gz_14.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_15.csv.gz -> results_RandomForest_charbot.gz_15.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_16.csv.gz -> results_RandomForest_charbot.gz_16.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_17.csv.gz -> results_RandomForest_charbot.gz_17.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_18.csv.gz -> results_RandomForest_charbot.gz_18.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_19.csv.gz -> results_RandomForest_charbot.gz_19.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_20.csv.gz -> results_RandomForest_charbot.gz_20.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_21.csv.gz -> results_RandomForest_charbot.gz_21.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_22.csv.gz -> results_RandomForest_charbot.gz_22.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_23.csv.gz -> results_RandomForest_charbot.gz_23.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_24.csv.gz -> results_RandomForest_charbot.gz_24.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_25.csv.gz -> results_RandomForest_charbot.gz_25.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_26.csv.gz -> results_RandomForest_charbot.gz_26.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_27.csv.gz -> results_RandomForest_charbot.gz_27.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_28.csv.gz -> results_RandomForest_charbot.gz_28.csv.gz\n",
            "  ‚úÖ results_RandomForest_charbot_29.csv.gz -> results_RandomForest_charbot.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: gozi -> gozi.gz\n",
            "Archivos encontrados: 30\n",
            "  ‚úÖ results_RandomForest_gozi_0.csv.gz -> results_RandomForest_gozi.gz_0.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_1.csv.gz -> results_RandomForest_gozi.gz_1.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_2.csv.gz -> results_RandomForest_gozi.gz_2.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_3.csv.gz -> results_RandomForest_gozi.gz_3.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_4.csv.gz -> results_RandomForest_gozi.gz_4.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_5.csv.gz -> results_RandomForest_gozi.gz_5.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_6.csv.gz -> results_RandomForest_gozi.gz_6.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_7.csv.gz -> results_RandomForest_gozi.gz_7.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_8.csv.gz -> results_RandomForest_gozi.gz_8.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_9.csv.gz -> results_RandomForest_gozi.gz_9.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_10.csv.gz -> results_RandomForest_gozi.gz_10.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_11.csv.gz -> results_RandomForest_gozi.gz_11.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_12.csv.gz -> results_RandomForest_gozi.gz_12.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_13.csv.gz -> results_RandomForest_gozi.gz_13.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_14.csv.gz -> results_RandomForest_gozi.gz_14.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_15.csv.gz -> results_RandomForest_gozi.gz_15.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_16.csv.gz -> results_RandomForest_gozi.gz_16.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_17.csv.gz -> results_RandomForest_gozi.gz_17.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_18.csv.gz -> results_RandomForest_gozi.gz_18.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_19.csv.gz -> results_RandomForest_gozi.gz_19.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_20.csv.gz -> results_RandomForest_gozi.gz_20.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_21.csv.gz -> results_RandomForest_gozi.gz_21.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_22.csv.gz -> results_RandomForest_gozi.gz_22.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_23.csv.gz -> results_RandomForest_gozi.gz_23.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_24.csv.gz -> results_RandomForest_gozi.gz_24.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_25.csv.gz -> results_RandomForest_gozi.gz_25.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_26.csv.gz -> results_RandomForest_gozi.gz_26.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_27.csv.gz -> results_RandomForest_gozi.gz_27.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_28.csv.gz -> results_RandomForest_gozi.gz_28.csv.gz\n",
            "  ‚úÖ results_RandomForest_gozi_29.csv.gz -> results_RandomForest_gozi.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: manuelita -> manuelita.gz\n",
            "Archivos encontrados: 30\n",
            "  ‚úÖ results_RandomForest_manuelita_0.csv.gz -> results_RandomForest_manuelita.gz_0.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_1.csv.gz -> results_RandomForest_manuelita.gz_1.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_2.csv.gz -> results_RandomForest_manuelita.gz_2.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_3.csv.gz -> results_RandomForest_manuelita.gz_3.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_4.csv.gz -> results_RandomForest_manuelita.gz_4.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_5.csv.gz -> results_RandomForest_manuelita.gz_5.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_6.csv.gz -> results_RandomForest_manuelita.gz_6.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_7.csv.gz -> results_RandomForest_manuelita.gz_7.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_8.csv.gz -> results_RandomForest_manuelita.gz_8.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_9.csv.gz -> results_RandomForest_manuelita.gz_9.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_10.csv.gz -> results_RandomForest_manuelita.gz_10.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_11.csv.gz -> results_RandomForest_manuelita.gz_11.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_12.csv.gz -> results_RandomForest_manuelita.gz_12.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_13.csv.gz -> results_RandomForest_manuelita.gz_13.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_14.csv.gz -> results_RandomForest_manuelita.gz_14.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_15.csv.gz -> results_RandomForest_manuelita.gz_15.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_16.csv.gz -> results_RandomForest_manuelita.gz_16.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_17.csv.gz -> results_RandomForest_manuelita.gz_17.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_18.csv.gz -> results_RandomForest_manuelita.gz_18.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_19.csv.gz -> results_RandomForest_manuelita.gz_19.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_20.csv.gz -> results_RandomForest_manuelita.gz_20.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_21.csv.gz -> results_RandomForest_manuelita.gz_21.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_22.csv.gz -> results_RandomForest_manuelita.gz_22.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_23.csv.gz -> results_RandomForest_manuelita.gz_23.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_24.csv.gz -> results_RandomForest_manuelita.gz_24.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_25.csv.gz -> results_RandomForest_manuelita.gz_25.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_26.csv.gz -> results_RandomForest_manuelita.gz_26.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_27.csv.gz -> results_RandomForest_manuelita.gz_27.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_28.csv.gz -> results_RandomForest_manuelita.gz_28.csv.gz\n",
            "  ‚úÖ results_RandomForest_manuelita_29.csv.gz -> results_RandomForest_manuelita.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: rovnix -> rovnix.gz\n",
            "Archivos encontrados: 30\n",
            "  ‚úÖ results_RandomForest_rovnix_0.csv.gz -> results_RandomForest_rovnix.gz_0.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_1.csv.gz -> results_RandomForest_rovnix.gz_1.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_2.csv.gz -> results_RandomForest_rovnix.gz_2.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_3.csv.gz -> results_RandomForest_rovnix.gz_3.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_4.csv.gz -> results_RandomForest_rovnix.gz_4.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_5.csv.gz -> results_RandomForest_rovnix.gz_5.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_6.csv.gz -> results_RandomForest_rovnix.gz_6.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_7.csv.gz -> results_RandomForest_rovnix.gz_7.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_8.csv.gz -> results_RandomForest_rovnix.gz_8.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_9.csv.gz -> results_RandomForest_rovnix.gz_9.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_10.csv.gz -> results_RandomForest_rovnix.gz_10.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_11.csv.gz -> results_RandomForest_rovnix.gz_11.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_12.csv.gz -> results_RandomForest_rovnix.gz_12.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_13.csv.gz -> results_RandomForest_rovnix.gz_13.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_14.csv.gz -> results_RandomForest_rovnix.gz_14.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_15.csv.gz -> results_RandomForest_rovnix.gz_15.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_16.csv.gz -> results_RandomForest_rovnix.gz_16.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_17.csv.gz -> results_RandomForest_rovnix.gz_17.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_18.csv.gz -> results_RandomForest_rovnix.gz_18.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_19.csv.gz -> results_RandomForest_rovnix.gz_19.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_20.csv.gz -> results_RandomForest_rovnix.gz_20.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_21.csv.gz -> results_RandomForest_rovnix.gz_21.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_22.csv.gz -> results_RandomForest_rovnix.gz_22.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_23.csv.gz -> results_RandomForest_rovnix.gz_23.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_24.csv.gz -> results_RandomForest_rovnix.gz_24.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_25.csv.gz -> results_RandomForest_rovnix.gz_25.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_26.csv.gz -> results_RandomForest_rovnix.gz_26.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_27.csv.gz -> results_RandomForest_rovnix.gz_27.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_28.csv.gz -> results_RandomForest_rovnix.gz_28.csv.gz\n",
            "  ‚úÖ results_RandomForest_rovnix_29.csv.gz -> results_RandomForest_rovnix.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: deception -> deception.gz\n",
            "Archivos encontrados: 30\n",
            "  ‚úÖ results_RandomForest_deception_0.csv.gz -> results_RandomForest_deception.gz_0.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_1.csv.gz -> results_RandomForest_deception.gz_1.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_2.csv.gz -> results_RandomForest_deception.gz_2.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_3.csv.gz -> results_RandomForest_deception.gz_3.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_4.csv.gz -> results_RandomForest_deception.gz_4.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_5.csv.gz -> results_RandomForest_deception.gz_5.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_6.csv.gz -> results_RandomForest_deception.gz_6.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_7.csv.gz -> results_RandomForest_deception.gz_7.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_8.csv.gz -> results_RandomForest_deception.gz_8.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_9.csv.gz -> results_RandomForest_deception.gz_9.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_10.csv.gz -> results_RandomForest_deception.gz_10.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_11.csv.gz -> results_RandomForest_deception.gz_11.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_12.csv.gz -> results_RandomForest_deception.gz_12.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_13.csv.gz -> results_RandomForest_deception.gz_13.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_14.csv.gz -> results_RandomForest_deception.gz_14.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_15.csv.gz -> results_RandomForest_deception.gz_15.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_16.csv.gz -> results_RandomForest_deception.gz_16.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_17.csv.gz -> results_RandomForest_deception.gz_17.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_18.csv.gz -> results_RandomForest_deception.gz_18.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_19.csv.gz -> results_RandomForest_deception.gz_19.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_20.csv.gz -> results_RandomForest_deception.gz_20.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_21.csv.gz -> results_RandomForest_deception.gz_21.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_22.csv.gz -> results_RandomForest_deception.gz_22.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_23.csv.gz -> results_RandomForest_deception.gz_23.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_24.csv.gz -> results_RandomForest_deception.gz_24.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_25.csv.gz -> results_RandomForest_deception.gz_25.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_26.csv.gz -> results_RandomForest_deception.gz_26.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_27.csv.gz -> results_RandomForest_deception.gz_27.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_28.csv.gz -> results_RandomForest_deception.gz_28.csv.gz\n",
            "  ‚úÖ results_RandomForest_deception_29.csv.gz -> results_RandomForest_deception.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: nymaim -> nymaim.gz\n",
            "Archivos encontrados: 30\n",
            "  ‚úÖ results_RandomForest_nymaim_0.csv.gz -> results_RandomForest_nymaim.gz_0.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_1.csv.gz -> results_RandomForest_nymaim.gz_1.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_2.csv.gz -> results_RandomForest_nymaim.gz_2.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_3.csv.gz -> results_RandomForest_nymaim.gz_3.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_4.csv.gz -> results_RandomForest_nymaim.gz_4.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_5.csv.gz -> results_RandomForest_nymaim.gz_5.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_6.csv.gz -> results_RandomForest_nymaim.gz_6.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_7.csv.gz -> results_RandomForest_nymaim.gz_7.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_8.csv.gz -> results_RandomForest_nymaim.gz_8.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_9.csv.gz -> results_RandomForest_nymaim.gz_9.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_10.csv.gz -> results_RandomForest_nymaim.gz_10.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_11.csv.gz -> results_RandomForest_nymaim.gz_11.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_12.csv.gz -> results_RandomForest_nymaim.gz_12.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_13.csv.gz -> results_RandomForest_nymaim.gz_13.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_14.csv.gz -> results_RandomForest_nymaim.gz_14.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_15.csv.gz -> results_RandomForest_nymaim.gz_15.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_16.csv.gz -> results_RandomForest_nymaim.gz_16.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_17.csv.gz -> results_RandomForest_nymaim.gz_17.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_18.csv.gz -> results_RandomForest_nymaim.gz_18.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_19.csv.gz -> results_RandomForest_nymaim.gz_19.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_20.csv.gz -> results_RandomForest_nymaim.gz_20.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_21.csv.gz -> results_RandomForest_nymaim.gz_21.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_22.csv.gz -> results_RandomForest_nymaim.gz_22.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_23.csv.gz -> results_RandomForest_nymaim.gz_23.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_24.csv.gz -> results_RandomForest_nymaim.gz_24.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_25.csv.gz -> results_RandomForest_nymaim.gz_25.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_26.csv.gz -> results_RandomForest_nymaim.gz_26.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_27.csv.gz -> results_RandomForest_nymaim.gz_27.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_28.csv.gz -> results_RandomForest_nymaim.gz_28.csv.gz\n",
            "  ‚úÖ results_RandomForest_nymaim_29.csv.gz -> results_RandomForest_nymaim.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: NEW_bigviktor -> bigviktor.gz\n",
            "Archivos encontrados: 30\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_0.csv.gz -> results_RandomForest_bigviktor.gz_0.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_1.csv.gz -> results_RandomForest_bigviktor.gz_1.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_2.csv.gz -> results_RandomForest_bigviktor.gz_2.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_3.csv.gz -> results_RandomForest_bigviktor.gz_3.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_4.csv.gz -> results_RandomForest_bigviktor.gz_4.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_5.csv.gz -> results_RandomForest_bigviktor.gz_5.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_6.csv.gz -> results_RandomForest_bigviktor.gz_6.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_7.csv.gz -> results_RandomForest_bigviktor.gz_7.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_8.csv.gz -> results_RandomForest_bigviktor.gz_8.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_9.csv.gz -> results_RandomForest_bigviktor.gz_9.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_10.csv.gz -> results_RandomForest_bigviktor.gz_10.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_11.csv.gz -> results_RandomForest_bigviktor.gz_11.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_12.csv.gz -> results_RandomForest_bigviktor.gz_12.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_13.csv.gz -> results_RandomForest_bigviktor.gz_13.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_14.csv.gz -> results_RandomForest_bigviktor.gz_14.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_15.csv.gz -> results_RandomForest_bigviktor.gz_15.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_16.csv.gz -> results_RandomForest_bigviktor.gz_16.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_17.csv.gz -> results_RandomForest_bigviktor.gz_17.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_18.csv.gz -> results_RandomForest_bigviktor.gz_18.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_19.csv.gz -> results_RandomForest_bigviktor.gz_19.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_20.csv.gz -> results_RandomForest_bigviktor.gz_20.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_21.csv.gz -> results_RandomForest_bigviktor.gz_21.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_22.csv.gz -> results_RandomForest_bigviktor.gz_22.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_23.csv.gz -> results_RandomForest_bigviktor.gz_23.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_24.csv.gz -> results_RandomForest_bigviktor.gz_24.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_25.csv.gz -> results_RandomForest_bigviktor.gz_25.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_26.csv.gz -> results_RandomForest_bigviktor.gz_26.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_27.csv.gz -> results_RandomForest_bigviktor.gz_27.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_28.csv.gz -> results_RandomForest_bigviktor.gz_28.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_bigviktor_29.csv.gz -> results_RandomForest_bigviktor.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: NEW_pizd -> pizd.gz\n",
            "Archivos encontrados: 30\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_0.csv.gz -> results_RandomForest_pizd.gz_0.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_1.csv.gz -> results_RandomForest_pizd.gz_1.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_2.csv.gz -> results_RandomForest_pizd.gz_2.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_3.csv.gz -> results_RandomForest_pizd.gz_3.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_4.csv.gz -> results_RandomForest_pizd.gz_4.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_5.csv.gz -> results_RandomForest_pizd.gz_5.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_6.csv.gz -> results_RandomForest_pizd.gz_6.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_7.csv.gz -> results_RandomForest_pizd.gz_7.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_8.csv.gz -> results_RandomForest_pizd.gz_8.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_9.csv.gz -> results_RandomForest_pizd.gz_9.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_10.csv.gz -> results_RandomForest_pizd.gz_10.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_11.csv.gz -> results_RandomForest_pizd.gz_11.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_12.csv.gz -> results_RandomForest_pizd.gz_12.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_13.csv.gz -> results_RandomForest_pizd.gz_13.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_14.csv.gz -> results_RandomForest_pizd.gz_14.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_15.csv.gz -> results_RandomForest_pizd.gz_15.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_16.csv.gz -> results_RandomForest_pizd.gz_16.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_17.csv.gz -> results_RandomForest_pizd.gz_17.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_18.csv.gz -> results_RandomForest_pizd.gz_18.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_19.csv.gz -> results_RandomForest_pizd.gz_19.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_20.csv.gz -> results_RandomForest_pizd.gz_20.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_21.csv.gz -> results_RandomForest_pizd.gz_21.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_22.csv.gz -> results_RandomForest_pizd.gz_22.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_23.csv.gz -> results_RandomForest_pizd.gz_23.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_24.csv.gz -> results_RandomForest_pizd.gz_24.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_25.csv.gz -> results_RandomForest_pizd.gz_25.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_26.csv.gz -> results_RandomForest_pizd.gz_26.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_27.csv.gz -> results_RandomForest_pizd.gz_27.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_28.csv.gz -> results_RandomForest_pizd.gz_28.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_pizd_29.csv.gz -> results_RandomForest_pizd.gz_29.csv.gz\n",
            "\n",
            "Procesando familia: NEW_ngioweb -> ngioweb.gz\n",
            "Archivos encontrados: 30\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_0.csv.gz -> results_RandomForest_ngioweb.gz_0.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_1.csv.gz -> results_RandomForest_ngioweb.gz_1.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_2.csv.gz -> results_RandomForest_ngioweb.gz_2.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_3.csv.gz -> results_RandomForest_ngioweb.gz_3.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_4.csv.gz -> results_RandomForest_ngioweb.gz_4.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_5.csv.gz -> results_RandomForest_ngioweb.gz_5.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_6.csv.gz -> results_RandomForest_ngioweb.gz_6.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_7.csv.gz -> results_RandomForest_ngioweb.gz_7.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_8.csv.gz -> results_RandomForest_ngioweb.gz_8.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_9.csv.gz -> results_RandomForest_ngioweb.gz_9.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_10.csv.gz -> results_RandomForest_ngioweb.gz_10.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_11.csv.gz -> results_RandomForest_ngioweb.gz_11.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_12.csv.gz -> results_RandomForest_ngioweb.gz_12.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_13.csv.gz -> results_RandomForest_ngioweb.gz_13.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_14.csv.gz -> results_RandomForest_ngioweb.gz_14.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_15.csv.gz -> results_RandomForest_ngioweb.gz_15.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_16.csv.gz -> results_RandomForest_ngioweb.gz_16.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_17.csv.gz -> results_RandomForest_ngioweb.gz_17.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_18.csv.gz -> results_RandomForest_ngioweb.gz_18.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_19.csv.gz -> results_RandomForest_ngioweb.gz_19.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_20.csv.gz -> results_RandomForest_ngioweb.gz_20.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_21.csv.gz -> results_RandomForest_ngioweb.gz_21.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_22.csv.gz -> results_RandomForest_ngioweb.gz_22.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_23.csv.gz -> results_RandomForest_ngioweb.gz_23.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_24.csv.gz -> results_RandomForest_ngioweb.gz_24.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_25.csv.gz -> results_RandomForest_ngioweb.gz_25.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_26.csv.gz -> results_RandomForest_ngioweb.gz_26.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_27.csv.gz -> results_RandomForest_ngioweb.gz_27.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_28.csv.gz -> results_RandomForest_ngioweb.gz_28.csv.gz\n",
            "  ‚úÖ results_RandomForest_NEW_ngioweb_29.csv.gz -> results_RandomForest_ngioweb.gz_29.csv.gz\n",
            "\n",
            "==================================================\n",
            "RESUMEN FINAL:\n",
            "Archivos renombrados exitosamente: 330\n",
            "Familias sin archivos encontrados: 0\n",
            "Proceso completado.\n"
          ]
        }
      ]
    }
  ]
}