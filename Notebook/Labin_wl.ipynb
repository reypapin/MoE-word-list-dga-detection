{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive  # Importing the library to mount Google Drive\n",
        "drive.mount('/content/drive')  # Mounting Google Drive in Colab environment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71FJxLKc1343",
        "outputId": "656465ff-fbd4-42d4-ebfe-bba89e051db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install keras_self_attention"
      ],
      "metadata": {
        "id": "p6_ioHiTyN37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXAm488r1DJw",
        "outputId": "14641690-2b73-48ac-90b3-3417d02571f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       domain    family   label\n",
            "0         nailconsiderable.ru  suppobox     dga\n",
            "1            stilldelight.net  suppobox     dga\n",
            "2       kimberleekatheryn.net  suppobox     dga\n",
            "3                soilbeen.net  suppobox     dga\n",
            "4               visitform.net  suppobox     dga\n",
            "...                       ...       ...     ...\n",
            "159995             dhuhaa.com     legit  notdga\n",
            "159996        sdmetalcrew.org     legit  notdga\n",
            "159997  melbcampcontuligol.ga     legit  notdga\n",
            "159998      pl-enthusiast.net     legit  notdga\n",
            "159999            rd-forum.ru     legit  notdga\n",
            "\n",
            "[160000 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# File paths\n",
        "train_df_file = \"/content/drive/My Drive/MOE_DGA/train_wl.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_df_file)\n",
        "\n",
        "#train_df = train_df.rename(columns={\"label\": \"Label\"})\n",
        "\n",
        "\n",
        "print(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, History\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional, LSTM, Dense, Dropout, Embedding\n",
        "from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n",
        "\n",
        "## Charset and encoding/decoding functions\n",
        "def encode(domain):\n",
        "    # Convertir a minúsculas y filtrar caracteres no válidos\n",
        "    domain = domain.lower()\n",
        "    encoded = []\n",
        "    for d in domain:\n",
        "        if d in stoi:\n",
        "            encoded.append(stoi[d])\n",
        "        else:\n",
        "            # Si el carácter no está en el charset, usar '*' como carácter desconocido\n",
        "            encoded.append(stoi['*'])\n",
        "    return encoded\n",
        "\n",
        "def pad(l, amount=0, where='right', value=0):\n",
        "    llen = len(l)\n",
        "    if where == 'left':\n",
        "        padded = [value]*(amount - llen) + l[:amount]\n",
        "    if where == 'right':\n",
        "        padded = l[:amount] + [value]*(amount - llen)\n",
        "    return padded\n",
        "\n",
        "# Charset expandido: incluye números, letras minúsculas, y caracteres comunes en dominios\n",
        "charset = ['*'] + [chr(x) for x in range(0x30, 0x30+10)] + [chr(x) for x in range(0x61, 0x61+26)] + ['-', '_' ,'.']\n",
        "stoi = {k:charset.index(k) for k in charset}\n",
        "itos = {charset.index(k):k for k in charset}\n",
        "\n",
        "print(f\"Charset disponible: {''.join(charset)}\")\n",
        "print(f\"Tamaño del vocabulario: {len(charset)}\")\n",
        "\n",
        "## Main parameters of the model\n",
        "vocab_size = len(charset)\n",
        "batch_size = 64\n",
        "max_len = 64  # Maximum length for the domain names\n",
        "embd_size = 128\n",
        "lstm_size = 128\n",
        "dense_size = 64\n",
        "dropout = 0.5\n",
        "\n",
        "## Data preparation function\n",
        "def prepare_data(train_df):\n",
        "    \"\"\"\n",
        "    Prepara los datos del dataframe para el entrenamiento\n",
        "    train_df debe tener columnas 'domain' y 'label' (con valores 'dga' y 'notdga')\n",
        "    \"\"\"\n",
        "    # Crear etiquetas binarias (1 para dga, 0 para notdga)\n",
        "    df = train_df.copy()\n",
        "    df['y'] = (df.label == 'dga').astype(int)\n",
        "\n",
        "    # Codificar dominios\n",
        "    df['encoded'] = df.domain.apply(encode)\n",
        "    df['padded'] = df.encoded.apply(lambda x: pad(x, max_len, 'left'))\n",
        "\n",
        "    # Convertir a arrays numpy\n",
        "    X = np.array(list(df.padded.values))\n",
        "    y = df['y'].values\n",
        "\n",
        "    return X, y\n",
        "\n",
        "## Callbacks para guardar el modelo y su historial de entrenamiento\n",
        "def build_callbacks(save_path, monitor):\n",
        "    checkpoint = ModelCheckpoint(filepath=save_path, monitor=monitor, verbose=1, save_best_only=True)\n",
        "    history = History()\n",
        "    callbacks = [checkpoint, history]\n",
        "    return callbacks\n",
        "\n",
        "# Crear callbacks\n",
        "timestamp = str(datetime.datetime.now()).split(\".\")[0].replace(\" \", \"_\")\n",
        "labin_callbacks = build_callbacks(f'LABin_best_model_{timestamp}.keras', 'val_loss')\n",
        "\n",
        "## LABin model definition - Binary classifier\n",
        "LABin = Sequential()\n",
        "LABin.add(Embedding(input_dim=vocab_size, output_dim=embd_size, input_length=max_len))\n",
        "LABin.add(Bidirectional(LSTM(lstm_size, return_sequences=True), name=\"bilstm1\"))\n",
        "LABin.add(SeqSelfAttention(name=\"seqselfatt\"))\n",
        "LABin.add(Dropout(rate=dropout, name=\"drop1\"))\n",
        "LABin.add(Bidirectional(LSTM(lstm_size, return_sequences=True), name=\"bilstm2\"))\n",
        "LABin.add(SeqWeightedAttention(name=\"seqweigatt\"))\n",
        "LABin.add(Dropout(rate=dropout, name=\"drop2\"))\n",
        "LABin.add(Dense(dense_size, activation='relu', name=\"linear\"))\n",
        "LABin.add(Dropout(rate=dropout, name=\"drop3\"))\n",
        "LABin.add(Dense(1, activation='sigmoid', name=\"sigmoid\"))\n",
        "LABin.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "# Mostrar resumen del modelo\n",
        "LABin.summary()\n",
        "\n",
        "## Función de entrenamiento\n",
        "def train_labin(train_df, epochs=50, validation_split=0.2):\n",
        "    \"\"\"\n",
        "    Entrena el modelo LABin con el dataframe proporcionado\n",
        "    \"\"\"\n",
        "    print(\"Preparando datos...\")\n",
        "    X, y = prepare_data(train_df)\n",
        "\n",
        "    print(f\"Datos preparados: {X.shape[0]} muestras\")\n",
        "    print(f\"Distribución de clases: DGA={np.sum(y)}, NotDGA={len(y)-np.sum(y)}\")\n",
        "\n",
        "    print(\"Iniciando entrenamiento...\")\n",
        "    history = LABin.fit(\n",
        "        X, y,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        callbacks=labin_callbacks,\n",
        "        validation_split=validation_split,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return history\n",
        "\n",
        "# Ejemplo de uso:\n",
        "# Asumiendo que tienes tu dataframe 'train_df' con columnas 'domain' y 'label'\n",
        "# history = train_labin(train_df, epochs=50)\n",
        "\n",
        "## Función para visualizar resultados (opcional)\n",
        "def plot_training_history(history):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('LABin Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('LABin Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'LABin_training_history_{timestamp}.png')\n",
        "    plt.show()\n",
        "\n",
        "# Para usar después del entrenamiento:\n",
        "# plot_training_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "kEk4Sbxf1_8n",
        "outputId": "25aa17af-d000-4228-e371-ce4528daecaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charset disponible: *0123456789abcdefghijklmnopqrstuvwxyz-_.\n",
            "Tamaño del vocabulario: 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bilstm1 (\u001b[38;5;33mBidirectional\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ seqselfatt (\u001b[38;5;33mSeqSelfAttention\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop1 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bilstm2 (\u001b[38;5;33mBidirectional\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ seqweigatt                      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mSeqWeightedAttention\u001b[0m)          │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop2 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ linear (\u001b[38;5;33mDense\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop3 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sigmoid (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bilstm1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ seqselfatt (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeqSelfAttention</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bilstm2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ seqweigatt                      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeqWeightedAttention</span>)          │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ linear (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sigmoid (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de uso:\n",
        "# Asumiendo que tienes tu dataframe 'train_df' con columnas 'domain' y 'label'\n",
        "history = train_labin(train_df, epochs=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jpJtyL9x_Va",
        "outputId": "96cf6c7b-e4b2-4939-dddb-acd83977b6fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparando datos...\n",
            "Datos preparados: 160000 muestras\n",
            "Distribución de clases: DGA=80000, NotDGA=80000\n",
            "Iniciando entrenamiento...\n",
            "Epoch 1/50\n",
            "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7264 - loss: 0.5377\n",
            "Epoch 1: val_loss improved from inf to 0.59806, saving model to LABin_best_model_2025-05-30_15:26:47.keras\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 25ms/step - accuracy: 0.7264 - loss: 0.5376 - val_accuracy: 0.7864 - val_loss: 0.5981\n",
            "Epoch 2/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7948 - loss: 0.4331\n",
            "Epoch 2: val_loss improved from 0.59806 to 0.53677, saving model to LABin_best_model_2025-05-30_15:26:47.keras\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.7948 - loss: 0.4331 - val_accuracy: 0.7870 - val_loss: 0.5368\n",
            "Epoch 3/50\n",
            "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8145 - loss: 0.4002\n",
            "Epoch 3: val_loss did not improve from 0.53677\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8145 - loss: 0.4002 - val_accuracy: 0.7098 - val_loss: 0.6577\n",
            "Epoch 4/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8285 - loss: 0.3788\n",
            "Epoch 4: val_loss did not improve from 0.53677\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 25ms/step - accuracy: 0.8285 - loss: 0.3788 - val_accuracy: 0.7905 - val_loss: 0.5763\n",
            "Epoch 5/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8370 - loss: 0.3608\n",
            "Epoch 5: val_loss improved from 0.53677 to 0.47977, saving model to LABin_best_model_2025-05-30_15:26:47.keras\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 25ms/step - accuracy: 0.8370 - loss: 0.3608 - val_accuracy: 0.8449 - val_loss: 0.4798\n",
            "Epoch 6/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8460 - loss: 0.3459\n",
            "Epoch 6: val_loss did not improve from 0.47977\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25ms/step - accuracy: 0.8460 - loss: 0.3459 - val_accuracy: 0.8472 - val_loss: 0.5106\n",
            "Epoch 7/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8547 - loss: 0.3301\n",
            "Epoch 7: val_loss improved from 0.47977 to 0.45215, saving model to LABin_best_model_2025-05-30_15:26:47.keras\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8547 - loss: 0.3301 - val_accuracy: 0.8692 - val_loss: 0.4522\n",
            "Epoch 8/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8657 - loss: 0.3114\n",
            "Epoch 8: val_loss improved from 0.45215 to 0.40643, saving model to LABin_best_model_2025-05-30_15:26:47.keras\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.8657 - loss: 0.3114 - val_accuracy: 0.8890 - val_loss: 0.4064\n",
            "Epoch 9/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8737 - loss: 0.2941\n",
            "Epoch 9: val_loss did not improve from 0.40643\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 25ms/step - accuracy: 0.8737 - loss: 0.2941 - val_accuracy: 0.8893 - val_loss: 0.4190\n",
            "Epoch 10/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8819 - loss: 0.2749\n",
            "Epoch 10: val_loss improved from 0.40643 to 0.39025, saving model to LABin_best_model_2025-05-30_15:26:47.keras\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25ms/step - accuracy: 0.8819 - loss: 0.2749 - val_accuracy: 0.8953 - val_loss: 0.3903\n",
            "Epoch 11/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8927 - loss: 0.2557\n",
            "Epoch 11: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8926 - loss: 0.2557 - val_accuracy: 0.8741 - val_loss: 0.4587\n",
            "Epoch 12/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8987 - loss: 0.2432\n",
            "Epoch 12: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 24ms/step - accuracy: 0.8987 - loss: 0.2432 - val_accuracy: 0.8831 - val_loss: 0.4264\n",
            "Epoch 13/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9071 - loss: 0.2258\n",
            "Epoch 13: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 24ms/step - accuracy: 0.9071 - loss: 0.2258 - val_accuracy: 0.8494 - val_loss: 0.6522\n",
            "Epoch 14/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9128 - loss: 0.2150\n",
            "Epoch 14: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 24ms/step - accuracy: 0.9128 - loss: 0.2150 - val_accuracy: 0.8538 - val_loss: 0.5587\n",
            "Epoch 15/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9164 - loss: 0.2053\n",
            "Epoch 15: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 25ms/step - accuracy: 0.9164 - loss: 0.2053 - val_accuracy: 0.8673 - val_loss: 0.5919\n",
            "Epoch 16/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9216 - loss: 0.1902\n",
            "Epoch 16: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 24ms/step - accuracy: 0.9216 - loss: 0.1902 - val_accuracy: 0.8490 - val_loss: 0.6060\n",
            "Epoch 17/50\n",
            "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9284 - loss: 0.1769\n",
            "Epoch 17: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 24ms/step - accuracy: 0.9284 - loss: 0.1769 - val_accuracy: 0.8280 - val_loss: 0.7875\n",
            "Epoch 18/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9321 - loss: 0.1672\n",
            "Epoch 18: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 24ms/step - accuracy: 0.9321 - loss: 0.1672 - val_accuracy: 0.8326 - val_loss: 0.8456\n",
            "Epoch 19/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9351 - loss: 0.1574\n",
            "Epoch 19: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 27ms/step - accuracy: 0.9351 - loss: 0.1574 - val_accuracy: 0.7985 - val_loss: 0.8885\n",
            "Epoch 20/50\n",
            "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9393 - loss: 0.1488\n",
            "Epoch 20: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 27ms/step - accuracy: 0.9393 - loss: 0.1488 - val_accuracy: 0.8516 - val_loss: 0.6725\n",
            "Epoch 21/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9417 - loss: 0.1415\n",
            "Epoch 21: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 25ms/step - accuracy: 0.9417 - loss: 0.1415 - val_accuracy: 0.8191 - val_loss: 0.8281\n",
            "Epoch 22/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9450 - loss: 0.1340\n",
            "Epoch 22: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 25ms/step - accuracy: 0.9450 - loss: 0.1340 - val_accuracy: 0.8337 - val_loss: 0.7363\n",
            "Epoch 23/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9476 - loss: 0.1274\n",
            "Epoch 23: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 24ms/step - accuracy: 0.9476 - loss: 0.1274 - val_accuracy: 0.7985 - val_loss: 1.1026\n",
            "Epoch 24/50\n",
            "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9506 - loss: 0.1206\n",
            "Epoch 24: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 25ms/step - accuracy: 0.9506 - loss: 0.1206 - val_accuracy: 0.8056 - val_loss: 0.8602\n",
            "Epoch 25/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9530 - loss: 0.1130\n",
            "Epoch 25: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 26ms/step - accuracy: 0.9530 - loss: 0.1130 - val_accuracy: 0.8264 - val_loss: 0.8605\n",
            "Epoch 26/50\n",
            "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9531 - loss: 0.1139\n",
            "Epoch 26: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.9531 - loss: 0.1139 - val_accuracy: 0.8080 - val_loss: 0.8498\n",
            "Epoch 27/50\n",
            "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9574 - loss: 0.1024\n",
            "Epoch 27: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.9574 - loss: 0.1024 - val_accuracy: 0.8100 - val_loss: 0.8863\n",
            "Epoch 28/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9588 - loss: 0.0972\n",
            "Epoch 28: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 27ms/step - accuracy: 0.9588 - loss: 0.0972 - val_accuracy: 0.7785 - val_loss: 0.9076\n",
            "Epoch 29/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9622 - loss: 0.0938\n",
            "Epoch 29: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 27ms/step - accuracy: 0.9622 - loss: 0.0938 - val_accuracy: 0.7402 - val_loss: 1.1227\n",
            "Epoch 30/50\n",
            "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9634 - loss: 0.0901\n",
            "Epoch 30: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.9634 - loss: 0.0901 - val_accuracy: 0.7887 - val_loss: 0.9364\n",
            "Epoch 31/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9662 - loss: 0.0838\n",
            "Epoch 31: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 27ms/step - accuracy: 0.9662 - loss: 0.0838 - val_accuracy: 0.7540 - val_loss: 1.1325\n",
            "Epoch 32/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9675 - loss: 0.0821\n",
            "Epoch 32: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.9675 - loss: 0.0821 - val_accuracy: 0.7806 - val_loss: 0.8558\n",
            "Epoch 33/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9690 - loss: 0.0801\n",
            "Epoch 33: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.9690 - loss: 0.0801 - val_accuracy: 0.7749 - val_loss: 0.9175\n",
            "Epoch 34/50\n",
            "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9720 - loss: 0.0710\n",
            "Epoch 34: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25ms/step - accuracy: 0.9720 - loss: 0.0710 - val_accuracy: 0.7702 - val_loss: 0.9847\n",
            "Epoch 35/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9722 - loss: 0.0718\n",
            "Epoch 35: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.9722 - loss: 0.0718 - val_accuracy: 0.7346 - val_loss: 1.0676\n",
            "Epoch 36/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9726 - loss: 0.0715\n",
            "Epoch 36: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 25ms/step - accuracy: 0.9725 - loss: 0.0716 - val_accuracy: 0.7491 - val_loss: 0.9360\n",
            "Epoch 37/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9767 - loss: 0.0600\n",
            "Epoch 37: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25ms/step - accuracy: 0.9767 - loss: 0.0600 - val_accuracy: 0.7389 - val_loss: 1.1465\n",
            "Epoch 38/50\n",
            "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9782 - loss: 0.0596\n",
            "Epoch 38: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 25ms/step - accuracy: 0.9782 - loss: 0.0596 - val_accuracy: 0.7706 - val_loss: 0.9810\n",
            "Epoch 39/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9781 - loss: 0.0583\n",
            "Epoch 39: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.9781 - loss: 0.0584 - val_accuracy: 0.7287 - val_loss: 1.0654\n",
            "Epoch 40/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9787 - loss: 0.0576\n",
            "Epoch 40: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.9787 - loss: 0.0576 - val_accuracy: 0.7186 - val_loss: 1.1190\n",
            "Epoch 41/50\n",
            "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9792 - loss: 0.0576\n",
            "Epoch 41: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.9791 - loss: 0.0576 - val_accuracy: 0.7548 - val_loss: 1.0554\n",
            "Epoch 42/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9804 - loss: 0.0537\n",
            "Epoch 42: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 25ms/step - accuracy: 0.9804 - loss: 0.0537 - val_accuracy: 0.7732 - val_loss: 0.9237\n",
            "Epoch 43/50\n",
            "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9801 - loss: 0.0550\n",
            "Epoch 43: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 25ms/step - accuracy: 0.9801 - loss: 0.0550 - val_accuracy: 0.7821 - val_loss: 0.9783\n",
            "Epoch 44/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9813 - loss: 0.0522\n",
            "Epoch 44: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.9813 - loss: 0.0522 - val_accuracy: 0.7368 - val_loss: 1.3491\n",
            "Epoch 45/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9827 - loss: 0.0495\n",
            "Epoch 45: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 25ms/step - accuracy: 0.9827 - loss: 0.0495 - val_accuracy: 0.7447 - val_loss: 1.2059\n",
            "Epoch 46/50\n",
            "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9818 - loss: 0.0506\n",
            "Epoch 46: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 26ms/step - accuracy: 0.9818 - loss: 0.0506 - val_accuracy: 0.7544 - val_loss: 1.1131\n",
            "Epoch 47/50\n",
            "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9820 - loss: 0.0505\n",
            "Epoch 47: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 25ms/step - accuracy: 0.9820 - loss: 0.0505 - val_accuracy: 0.7353 - val_loss: 1.0976\n",
            "Epoch 48/50\n",
            "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9843 - loss: 0.0461\n",
            "Epoch 48: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.9843 - loss: 0.0461 - val_accuracy: 0.7104 - val_loss: 1.2959\n",
            "Epoch 49/50\n",
            "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9829 - loss: 0.0493\n",
            "Epoch 49: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25ms/step - accuracy: 0.9829 - loss: 0.0493 - val_accuracy: 0.7662 - val_loss: 0.8865\n",
            "Epoch 50/50\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9842 - loss: 0.0441\n",
            "Epoch 50: val_loss did not improve from 0.39025\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 26ms/step - accuracy: 0.9842 - loss: 0.0441 - val_accuracy: 0.7740 - val_loss: 1.0445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-flqDZcRx_Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## FUNCIONES PARA CARGAR EL MODELO Y HACER PREDICCIONES\n",
        "\n",
        "def load_trained_model(model_path):\n",
        "    \"\"\"\n",
        "    Carga el modelo entrenado desde un archivo\n",
        "    \"\"\"\n",
        "    from keras.models import load_model\n",
        "    from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n",
        "\n",
        "    # Cargar el modelo con las capas personalizadas\n",
        "    custom_objects = {\n",
        "        'SeqSelfAttention': SeqSelfAttention,\n",
        "        'SeqWeightedAttention': SeqWeightedAttention\n",
        "    }\n",
        "\n",
        "    model = load_model(model_path, custom_objects=custom_objects)\n",
        "    print(f\"Modelo cargado desde: {model_path}\")\n",
        "    return model\n",
        "\n",
        "def predict_single_domain(model, domain):\n",
        "    \"\"\"\n",
        "    Predice si un dominio individual es DGA o no\n",
        "    \"\"\"\n",
        "    # Preparar el dominio\n",
        "    encoded = encode(domain)\n",
        "    padded = pad(encoded, max_len, 'left')\n",
        "    X = np.array([padded])  # Agregar dimensión batch\n",
        "\n",
        "    # Hacer predicción\n",
        "    prediction = model.predict(X, verbose=0)[0][0]\n",
        "\n",
        "    # Interpretar resultado\n",
        "    is_dga = prediction > 0.5\n",
        "    confidence = prediction if is_dga else (1 - prediction)\n",
        "\n",
        "    result = {\n",
        "        'domain': domain,\n",
        "        'prediction': 'DGA' if is_dga else 'LEGIT',\n",
        "        'confidence': confidence,\n",
        "        'raw_score': prediction\n",
        "    }\n",
        "\n",
        "    return result\n",
        "\n",
        "def predict_domains_batch(model, domains_list):\n",
        "    \"\"\"\n",
        "    Predice múltiples dominios a la vez\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Preparar todos los dominios\n",
        "    encoded_domains = [pad(encode(domain), max_len, 'left') for domain in domains_list]\n",
        "    X = np.array(encoded_domains)\n",
        "\n",
        "    # Hacer predicciones en lote\n",
        "    predictions = model.predict(X, verbose=0)\n",
        "\n",
        "    # Procesar resultados\n",
        "    for i, domain in enumerate(domains_list):\n",
        "        pred_score = predictions[i][0]\n",
        "        is_dga = pred_score > 0.5\n",
        "        confidence = pred_score if is_dga else (1 - pred_score)\n",
        "\n",
        "        result = {\n",
        "            'domain': domain,\n",
        "            'prediction': 'DGA' if is_dga else 'LEGIT',\n",
        "            'confidence': confidence,\n",
        "            'raw_score': pred_score\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "def evaluate_model_on_test(model, test_df):\n",
        "    \"\"\"\n",
        "    Evalúa el modelo en un conjunto de test\n",
        "    test_df debe tener columnas 'domain' y 'label'\n",
        "    \"\"\"\n",
        "    print(\"Evaluando modelo en datos de test...\")\n",
        "\n",
        "    # Preparar datos de test\n",
        "    X_test, y_test = prepare_data(test_df)\n",
        "\n",
        "    # Hacer predicciones\n",
        "    predictions = model.predict(X_test, verbose=0)\n",
        "    y_pred = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "    # Calcular métricas\n",
        "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'confusion_matrix': cm\n",
        "    }\n",
        "\n",
        "## EJEMPLOS DE USO:\n",
        "\n",
        "\"\"\"\n",
        "# 1. ENTRENAR EL MODELO\n",
        "history = train_labin(train_df, epochs=50)\n",
        "\n",
        "# 2. CARGAR UN MODELO YA ENTRENADO\n",
        "# Cambia 'ruta_del_modelo.keras' por la ruta real donde guardaste tu modelo\n",
        "loaded_model = load_trained_model('LABin_best_model_2025-05-30_15:22:09.keras')\n",
        "\n",
        "# 3. PROBAR UN DOMINIO INDIVIDUAL\n",
        "result = predict_single_domain(loaded_model, 'google.com')\n",
        "print(f\"Dominio: {result['domain']}\")\n",
        "print(f\"Predicción: {result['prediction']}\")\n",
        "print(f\"Confianza: {result['confidence']:.4f}\")\n",
        "\n",
        "# 4. PROBAR MÚLTIPLES DOMINIOS\n",
        "test_domains = [\n",
        "    'google.com',\n",
        "    'facebook.com',\n",
        "    'xkjhsdkjfhlksdjf.com',\n",
        "    'qwerty123456.net',\n",
        "    'amazon.com'\n",
        "]\n",
        "\n",
        "results = predict_domains_batch(loaded_model, test_domains)\n",
        "for result in results:\n",
        "    print(f\"{result['domain']:<30} -> {result['prediction']:<5} (confianza: {result['confidence']:.4f})\")\n",
        "\n",
        "# 5. EVALUAR EN CONJUNTO DE TEST (si tienes un test_df)\n",
        "# metrics = evaluate_model_on_test(loaded_model, test_df)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "18quATrOx_bi",
        "outputId": "bb272cd6-0d89-4de1-e131-e67b4cc69ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# 1. ENTRENAR EL MODELO\\nhistory = train_labin(train_df, epochs=50)\\n\\n# 2. CARGAR UN MODELO YA ENTRENADO\\n# Cambia \\'ruta_del_modelo.keras\\' por la ruta real donde guardaste tu modelo\\nloaded_model = load_trained_model(\\'LABin_best_model_2025-05-30_15:22:09.keras\\')\\n\\n# 3. PROBAR UN DOMINIO INDIVIDUAL\\nresult = predict_single_domain(loaded_model, \\'google.com\\')\\nprint(f\"Dominio: {result[\\'domain\\']}\")\\nprint(f\"Predicción: {result[\\'prediction\\']}\")\\nprint(f\"Confianza: {result[\\'confidence\\']:.4f}\")\\n\\n# 4. PROBAR MÚLTIPLES DOMINIOS\\ntest_domains = [\\n    \\'google.com\\',\\n    \\'facebook.com\\', \\n    \\'xkjhsdkjfhlksdjf.com\\',\\n    \\'qwerty123456.net\\',\\n    \\'amazon.com\\'\\n]\\n\\nresults = predict_domains_batch(loaded_model, test_domains)\\nfor result in results:\\n    print(f\"{result[\\'domain\\']:<30} -> {result[\\'prediction\\']:<5} (confianza: {result[\\'confidence\\']:.4f})\")\\n\\n# 5. EVALUAR EN CONJUNTO DE TEST (si tienes un test_df)\\n# metrics = evaluate_model_on_test(loaded_model, test_df)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. CARGAR UN MODELO YA ENTRENADO\n",
        "# Cambia 'ruta_del_modelo.keras' por la ruta real donde guardaste tu modelo\n",
        "loaded_model = load_trained_model('/content/LABin_best_model_2025-05-30_15:26:47.keras')\n",
        "\n",
        "# 3. PROBAR UN DOMINIO INDIVIDUAL\n",
        "result = predict_single_domain(loaded_model, 'sadfdfdsfasds.com')\n",
        "print(f\"Dominio: {result['domain']}\")\n",
        "print(f\"Predicción: {result['prediction']}\")\n",
        "print(f\"Confianza: {result['confidence']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpXsx39qx_ef",
        "outputId": "fcecb761-1bbe-498b-ddd5-e67ef3bb6e2a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado desde: /content/LABin_best_model_2025-05-30_15:26:47.keras\n",
            "Dominio: sadfdfdsfasds.com\n",
            "Predicción: DGA\n",
            "Confianza: 0.9111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "import sys\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import re\n",
        "\n",
        "families = [\n",
        "    'matsnu.gz',\n",
        "    'suppobox.gz',\n",
        "    'charbot.gz',\n",
        "    'gozi.gz',\n",
        "    'manuelita.gz',\n",
        "    'rovnix.gz',\n",
        "    'deception.gz',\n",
        "    'nymaim.gz'\n",
        "]\n",
        "\n",
        "runs = 30\n",
        "\n",
        "for family in families:\n",
        "    print(family)\n",
        "    dga = pd.read_csv(f'/content/drive/My Drive/Familias_Test/{family}', chunksize=50)\n",
        "    legit = pd.read_csv('/content/drive/My Drive/Familias_Test/legit.gz', chunksize=50)\n",
        "    dfs = []\n",
        "    for run in range(runs):\n",
        "        print(f'{run:2}/{runs}', end='\\r')\n",
        "        dfw = pd.concat([dga.get_chunk(), legit.get_chunk()])\n",
        "        pred = []\n",
        "        prob = []\n",
        "        query_time = []\n",
        "        results = []\n",
        "\n",
        "        for domain_to_check in dfw.domain.values:\n",
        "            st = time.time()\n",
        "\n",
        "            result = predict_single_domain(loaded_model, domain_to_check)\n",
        "            if result['prediction'] == \"DGA\":\n",
        "                label_value = 1\n",
        "            else:\n",
        "                label_value = 0\n",
        "\n",
        "            pred.append(label_value)\n",
        "            query_time.append(time.time() - st)\n",
        "\n",
        "        dfw['pred'] = pred\n",
        "        # dfw['prob'] = prob  # Si tienes probabilidades, descomenta esta línea\n",
        "        dfw['query_time'] = query_time\n",
        "        dfw.to_csv(f'/content/drive/My Drive/results/results_Labin_{family}_{run}.csv.gz', index=False)\n"
      ],
      "metadata": {
        "id": "Gg50xzhLIx85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39467198-b736-4d6a-a303-3bc09077d35e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matsnu.gz\n",
            "suppobox.gz\n",
            "charbot.gz\n",
            "gozi.gz\n",
            "manuelita.gz\n",
            "rovnix.gz\n",
            "deception.gz\n",
            "nymaim.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "import sys\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import re\n",
        "\n",
        "families = ['bigviktor.gz',\n",
        "            'pizd.gz',\n",
        "            'ngioweb.gz'\n",
        "\n",
        "           ]\n",
        "\n",
        "runs = 30\n",
        "\n",
        "for family in families:\n",
        "    print(family)\n",
        "    dga = pd.read_csv(f'/content/drive/My Drive/New_Families/{family}', chunksize=50)\n",
        "    legit = pd.read_csv('/content/drive/My Drive/Familias_Test/legit.gz', chunksize=50)\n",
        "    dfs = []\n",
        "\n",
        "    # Saltar los primeros 30 chunks de legit\n",
        "    for _ in range(30):\n",
        "        legit.get_chunk()\n",
        "\n",
        "\n",
        "\n",
        "    for run in range(runs):\n",
        "        print(f'{run:2}/{runs}', end='\\r')\n",
        "        dfw = pd.concat([dga.get_chunk(), legit.get_chunk()])\n",
        "        pred = []\n",
        "        prob = []\n",
        "        query_time = []\n",
        "        results = []\n",
        "\n",
        "        for domain_to_check in dfw.domain.values:\n",
        "            st = time.time()\n",
        "            result = predict_single_domain(loaded_model, domain_to_check)\n",
        "            if result['prediction'] == \"DGA\":\n",
        "                label_value = 1\n",
        "            else:\n",
        "                label_value = 0\n",
        "\n",
        "            pred.append(label_value)\n",
        "            query_time.append(time.time() - st)\n",
        "\n",
        "        dfw['pred'] = pred\n",
        "        # dfw['prob'] = prob  # Si tienes probabilidades, descomenta esta línea\n",
        "        dfw['query_time'] = query_time\n",
        "        dfw.to_csv(f'/content/drive/My Drive/results/results_Labin_{family}_{run}.csv.gz', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1g1s0WHKi5X",
        "outputId": "c2d6a2fe-728c-42cc-b5ee-925c1242e7c1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigviktor.gz\n",
            "pizd.gz\n",
            "ngioweb.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\"\"\"\n",
        "families = [\n",
        "    'matsnu.gz',\n",
        "    'suppobox.gz',\n",
        "    'charbot.gz',\n",
        "    'gozi.gz',\n",
        "    'manuelita.gz',\n",
        "    'rovnix.gz',\n",
        "    'deception.gz',\n",
        "    'nymaim.gz',\n",
        "    'bigviktor.gz',\n",
        "    'pizd.gz',\n",
        "    'ngioweb.gz'\n",
        "]\n",
        "#\"\"\"\n",
        "def fpr_tpr(y, ypred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y, ypred).ravel()\n",
        "    fpr = fp / (fp + tn)  # False Positive Rate\n",
        "    tpr = tp / (tp + fn)  # True Positive Rate (Recall)\n",
        "    return fpr, tpr\n",
        "\n",
        "for family in families:\n",
        "    acc = []\n",
        "    pre = []\n",
        "    rec = []\n",
        "    f1 = []\n",
        "    fpr = []\n",
        "    tpr = []\n",
        "    qt = []\n",
        "    qts = []\n",
        "    for run in range(runs):\n",
        "        df = pd.read_csv(f'/content/drive/My Drive/results/results_Labin_{family}_{run}.csv.gz')\n",
        "        y = (df.label == 'dga').astype(int)\n",
        "        ypred = df.pred\n",
        "        acc.append(accuracy_score(y, ypred))\n",
        "        pre.append(precision_score(y, ypred))\n",
        "        rec.append(recall_score(y, ypred))\n",
        "        f1.append(f1_score(y, ypred))\n",
        "        fpr_value, tpr_value = fpr_tpr(y, ypred)\n",
        "        fpr.append(fpr_value)\n",
        "        tpr.append(tpr_value)\n",
        "        qt.append(df.query_time.mean())\n",
        "        qts.append(df.query_time.std())\n",
        "#    print(f'Query time: {np.mean(qt):0.5f}+/-{np.mean(qts)}:0.5f')\n",
        "    print(f'{family.split(\".\")[0]:15}: acc:{np.mean(acc):0.2f}±{np.std(acc):.3f} f1:{np.mean(f1):0.2f}±{np.std(f1):.3f} pre:{np.mean(pre):0.2f}±{np.std(pre):.3f} rec:{np.mean(rec):0.2f}±{np.std(rec):.3f}  FPR:{np.mean(fpr):0.2f}±{np.std(fpr):.3f} TPR:{np.mean(tpr):0.2f}±{np.std(tpr):.3f} Query time: {np.mean(qt):0.5f}±{np.mean(qts):0.5f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaj2PD9NLLAn",
        "outputId": "6aca9e04-06c0-4a50-cd65-7a902b463ad7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matsnu         : acc:0.93±0.032 f1:0.93±0.028 pre:0.89±0.046 rec:0.97±0.018  FPR:0.12±0.059 TPR:0.97±0.018 Query time: 0.08699±0.03077\n",
            "suppobox       : acc:0.94±0.031 f1:0.94±0.027 pre:0.89±0.045 rec:1.00±0.012  FPR:0.12±0.059 TPR:1.00±0.012 Query time: 0.07804±0.02411\n",
            "charbot        : acc:0.84±0.044 f1:0.83±0.046 pre:0.87±0.055 rec:0.79±0.051  FPR:0.12±0.059 TPR:0.79±0.051 Query time: 0.07832±0.02187\n",
            "gozi           : acc:0.85±0.054 f1:0.84±0.056 pre:0.87±0.054 rec:0.81±0.080  FPR:0.12±0.059 TPR:0.81±0.080 Query time: 0.07945±0.02210\n",
            "manuelita      : acc:0.52±0.036 f1:0.24±0.064 pre:0.57±0.131 rec:0.15±0.047  FPR:0.12±0.059 TPR:0.15±0.047 Query time: 0.07936±0.02168\n",
            "rovnix         : acc:0.93±0.029 f1:0.94±0.025 pre:0.89±0.045 rec:0.98±0.017  FPR:0.12±0.059 TPR:0.98±0.017 Query time: 0.07933±0.02181\n",
            "deception      : acc:0.94±0.030 f1:0.94±0.026 pre:0.90±0.045 rec:1.00±0.000  FPR:0.12±0.059 TPR:1.00±0.000 Query time: 0.08005±0.02218\n",
            "nymaim         : acc:0.88±0.036 f1:0.88±0.034 pre:0.88±0.049 rec:0.87±0.040  FPR:0.12±0.059 TPR:0.87±0.040 Query time: 0.08008±0.02256\n",
            "bigviktor      : acc:0.55±0.031 f1:0.36±0.048 pre:0.65±0.101 rec:0.25±0.042  FPR:0.14±0.056 TPR:0.25±0.042 Query time: 0.08002±0.02226\n",
            "pizd           : acc:0.84±0.031 f1:0.83±0.030 pre:0.86±0.051 rec:0.82±0.038  FPR:0.14±0.056 TPR:0.82±0.038 Query time: 0.08062±0.02229\n",
            "ngioweb        : acc:0.58±0.055 f1:0.42±0.094 pre:0.68±0.120 rec:0.31±0.078  FPR:0.14±0.056 TPR:0.31±0.078 Query time: 0.08096±0.02214\n"
          ]
        }
      ]
    }
  ]
}